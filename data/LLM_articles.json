[
    {
        "authors": [
            "Wenyuan Chen",
            "Guangyong Li",
            "Mingwei Li",
            "Wenxue Wang",
            "Peng Li",
            "Xiujuan Xue",
            "Xingang Zhao",
            "Lianqing Liu"
        ],
        "published_in": "Published in: IEEE Transactions on Automation Science and Engineering ( Early Access )",
        "date_of_publication": "02 April 2024",
        "publication_month": "April",
        "publication_year": 2024,
        "doi": "10.1109/TASE.2024.3382679",
        "publisher": "IEEE",
        "abstract": "It remains a formidable challenge to accurately recognize motion intentions of patients thus to control hand exoskeletons according to their volition. Current methods primarily focus on recognition of limited patient’s motion intentions, with the purpose of controlling preconfigured gestures of a hand exoskeleton for grasping objects. These methods exhibit a marked shortfall when encountering scenarios that are unexpected or not designed in advance, such as non-preprogrammed hand movements and object manipulation tasks. To tackle this issue, large language model (LLM) and speech recognition technology are employed in this study to allow the patient to control a hand exoskeleton at will. In particular, two LLMs are tailored to formulate codes of either generating non-preprogrammed gestures or dealing with unencountered objects. Additionally, an incremental learning framework is proposed to enable patients to perform both predefined and non-predefined operation tasks by integrating a natural language parser with the two LLM-based learners. The natural language parser can directly control the hand exoskeleton to perform predefined operations tasks from prestored command set, while the LLM-based learners can incrementally expand the control command set so as to enhance adaptability of the hand exoskeleton to complex activities over daily use. This study is a pioneering work in the field of hand exoskeletons, which will revolutionize the way to control hand exoskeletons. Furthermore, the proposed framework can be easily generalized to any other robots by modifying the prompt of customized LLMs, which provides a new idea to achieve autonomous learning in robotics. Note to Practitioners —The motivation of this article is to tackle the challenge of intention recognition for performing activities of daily living (ADLs) by stroke patients using a multi-degree of freedom hand exoskeleton. Existing methods for intention recognition so far can only be used for several tasks tha...",
        "issn": {
            "Print ISSN": "1545-5955",
            "Electronic ISSN": "1558-3783"
        },
        "keywords": {
            "IEEE Keywords": [
                "Exoskeletons",
                "Task analysis",
                "Thumb",
                "Robots",
                "Automation",
                "Grasping",
                "Control systems"
            ],
            "Author Keywords": [
                "Hand exoskeleton",
                "motion intention recognition",
                "large language model (LLM)",
                "ChatGPT",
                "incremental learning"
            ]
        },
        "universities": "Rehabilitation Center for the Disabled; Faculty of Information Technology; Department of Electrical and Computer Engineering; State Key Laboratory of Robotics; Shenyang Institute of Automation",
        "countries": "USA; China",
        "locations": [
            "State Key Laboratory of Robotics, Shenyang Institute of Automation, and the Institute of Robotics and Intelligent Manufacturing, Chinese Academy of Sciences (CAS), Shenyang, China",
            "Department of Electrical and Computer Engineering, Swanson School of Engineering, University of Pittsburgh, Pittsburgh, PA, USA",
            "Faculty of Information Technology, Beijing University of Technology (BJUT), Beijing, China",
            "Shenyang Institute of Automation, State Key Laboratory of Robotics, Chinese Academy of Sciences (CAS), Shenyang, China",
            "Faculty of Information Technology, Beijing University of Technology (BJUT), Beijing, China",
            "Rehabilitation Center for the Disabled, Shenyang, China",
            "Shenyang Institute of Automation, State Key Laboratory of Robotics, Chinese Academy of Sciences (CAS), Shenyang, China",
            "Shenyang Institute of Automation, State Key Laboratory of Robotics, Chinese Academy of Sciences (CAS), Shenyang, China"
        ],
        "title": "LLM-Enabled Incremental Learning Framework for Hand Exoskeleton Control"
    },
    {
        "authors": [
            "Dmitriy Rivkin",
            "Francois Hogan",
            "Amal Feriani",
            "Abhisek Konar",
            "Adam Sigal",
            "Xue Liu",
            "Gregory Dudek"
        ],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "23 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/JIOT.2024.3471904",
        "publisher": "IEEE",
        "abstract": "The common-sense reasoning abilities and vast general knowledge of Large Language Models (LLMs) make them a natural fit for interpreting user requests in a smart home assistant context. LLMs, however, lack specific knowledge about the user and their home, which limits their potential impact. SAGE (Smart Home Agent with Grounded Execution), overcomes these and other limitations by using a scheme in which a user request triggers an LLM-controlled sequence of discrete actions. These actions can be used to retrieve information, interact with the user, or manipulate device states. SAGE controls this process through a dynamically constructed tree of LLM prompts, which help it decide which action to take next, whether an action was successful, and when to terminate the process. The SAGE action set augments an LLM’s capabilities to support some of the most critical requirements for a smart home assistant. These include: flexible and scalable user preference management (“Is my team playing tonight?”), access to any smart device’s full functionality without device-specific code via API reading (“Turn down the screen brightness on my dryer”), persistent device state monitoring (“Remind me to throw out the milk when I open the fridge”), natural device references using only a photo of the room (“Turn on the lamp on the dresser”), and more. We introduce a benchmark of 50 new and challenging smart home tasks where SAGE achieves a 76% success rate, significantly outperforming existing LLM-enabled baselines (30% success rate).",
        "issn": {
            "Electronic ISSN": "2327-4662"
        },
        "keywords": {
            "IEEE Keywords": [
                "Smart homes",
                "Codes",
                "Performance evaluation",
                "Internet of Things",
                "Benchmark testing",
                "Smart devices",
                "Logic",
                "Process control",
                "Monitoring",
                "Manuals"
            ],
            "Author Keywords": [
                "Autonomous LLM Agents",
                "Smart Home",
                "IoT",
                "Generative AI",
                "Embodied AI",
                "Personalized AI",
                "AI Assistant"
            ]
        },
        "universities": "Samsung AI Center Montréal",
        "countries": "Canada",
        "locations": [
            "Samsung AI Center Montréal, Canada",
            "Samsung AI Center Montréal, Canada",
            "Samsung AI Center Montréal, Canada",
            "Samsung AI Center Montréal, Canada",
            "Samsung AI Center Montréal, Canada",
            "Samsung AI Center Montréal, Canada",
            "Samsung AI Center Montréal, Canada"
        ],
        "title": "AIoT Smart Home via Autonomous LLM Agents"
    },
    {
        "authors": [
            "Xingchi Chen",
            "Xiaoyang Lu",
            "Qing Li",
            "Dazhou Li",
            "Fa Zhu"
        ],
        "published_in": "Published in: IEEE Transactions on Vehicular Technology ( Early Access )",
        "date_of_publication": "16 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/TVT.2024.3434969",
        "publisher": "IEEE",
        "abstract": "Advanced artificial intelligence (AI) solutions deployed in the environment of space-air-ground integrated vehicular networks (SAGVNs) are instrumental in achieving efficient coordination between connected electric vehicles (EVs) and distributed networks. This study addresses this challenge by leveraging a Large Language Model (LLM) based hybrid dispatching framework for formulating dispatching strategies, where the need for commonsense understanding by EV drivers is paramount. This paper proposes a framework LLM-D3PG, LLM-guided dual Deep Deterministic Policy Gradient, which empowers EV drivers to articulate their expectations for AI-generated dispatching strategies using natural language instructions. These instructions serve as guidance for the generation of dispatching strategies within complex distributed network scenarios. According to this strategy, the proposed framework seamlessly integrates the decision-making capabilities of LLM with multiple D3PG models to generate a large number of candidate dispatching strategies and then uses the whale optimization algorithm to optimize these strategies to achieve better dispatching results. Comprehensive experimental results demonstrate the effectiveness of the proposed framework and show outperformance in comparison to some existing methods for power dispatching tasks with the random connection of EVs in SAGVNs.",
        "issn": {
            "Print ISSN": "0018-9545",
            "Electronic ISSN": "1939-9359"
        },
        "keywords": {
            "IEEE Keywords": [
                "Dispatching",
                "Vehicles",
                "Uncertainty",
                "Electric vehicle charging",
                "Vehicle dynamics",
                "Data models",
                "Power distribution",
                "Heuristic algorithms",
                "Costs",
                "Decision making"
            ],
            "Author Keywords": [
                "Connected electric vehicles",
                "large language model (LLM)",
                "deep deterministic policy gradient",
                "space-airground integrated vehicular networks (SAGVNs)",
                "power dispatching"
            ]
        },
        "universities": "College of Information Science and Technology & College of Artificial Intelligence; College of Computer Science and Technology; School of Medical Imaging; Pengcheng Laboratory",
        "countries": "P.R. China; China",
        "locations": [
            "Pengcheng Laboratory, Shenzhen, P.R. China",
            "School of Medical Imaging, Fujian Medical University, Fuzhou, P.R. China",
            "Pengcheng Laboratory, Shenzhen, P.R. China",
            "College of Computer Science and Technology, Shenyang University of Chemical Technology, Shenyang, China",
            "College of Information Science and Technology & College of Artificial Intelligence, Nanjing Forestry University, Nanjing, P.R. China"
        ],
        "title": "Integration of LLM and Human-AI Coordination for Power Dispatching with Connected Electric Vehicles under SAGVNs"
    },
    {
        "authors": [
            "Shijun Ge",
            "Yuanbo Sun",
            "Yin Cui",
            "Dapeng Wei"
        ],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "08 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/ACCESS.2024.3494054",
        "publisher": "IEEE",
        "abstract": "To enhance the application capabilities of large language models (LLMs) in conceptual design, this study explores how to achieve deep integration between LLM-based agents and concept generation methods using the chain-of-thought (CoT) technique and evaluates its feasibility. Using GPT-4 as a case study, we designed two agents: IntelliStorm (based on the unstructured brainstorming method) and EvoluTRIZ (based on the structured TRIZ method). Thirty participants were recruited, and through two experimental phases spaced one month apart, a comparative analysis of the effects of collaboration groups (human-agent vs. human-human) and concept generation methods (brainstorming vs. TRIZ) on participants’ physiological activation and creative thinking performance were conducted. The results show that the involvement of LLM-based agents can effectively reduce participants’ electrodermal activity(EDA )response levels, indicating a reduction in cognitive load. Moreover, these agents preserve the distinct physiological response patterns and performance advantages of the different concept generation methods. For example, IntelliStorm, like brainstorming, evokes stronger responses to information stimuli, demonstrating superior thinking fluency; EvoluTRIZ, like the TRIZ, exhibits a higher frequency of information responses, showcasing enhanced thinking elaboration. However, originality tends to favor human–human collaboration. The findings confirm that integrating LLMs with traditional concept generation methods is an effective strategy made possible by combining CoT and retrieval-augmented generation (RAG) technologies. In the future, LLM-based agents are expected to achieve broader application in the design field by incorporating additional concept generation methods.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Particle swarm optimization",
                "Heuristic algorithms",
                "Brain modeling",
                "Collaboration",
                "Design methodology",
                "Creativity",
                "Training",
                "Knowledge based systems",
                "Computational modeling",
                "Cognitive load",
                "Large language models"
            ],
            "Author Keywords": [
                "LLM-based agent",
                "chain-of-thought fine-tuning",
                "concept generation method",
                "EDA",
                "human-agent collaboration",
                "human-human collaboration"
            ]
        },
        "universities": "School of Design and Innovation; School of Design and Art",
        "countries": "China",
        "locations": [
            "School of Design and Art, Beijing Institute of Technology, Beijing, China",
            "School of Design and Art, Beijing Institute of Technology, Beijing, China",
            "School of Design and Innovation, Shenzhen Technology University, Shenzhen, China",
            "School of Design and Art, Beijing Institute of Technology, Beijing, China"
        ],
        "title": "An Innovative Solution to Design Problems: Applying the Chain-of-Thought Technique to Integrate LLM-based Agents with Concept Generation Methods"
    },
    {
        "authors": [
            "Yong Zhu",
            "Zhenyu Wen",
            "Xiong Li",
            "Xiufang Shi",
            "Xiang Wu",
            "Hui Dong",
            "Jiming Chen"
        ],
        "published_in": "Published in: IEEE Transactions on Circuits and Systems for Video Technology ( Early Access )",
        "date_of_publication": "24 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/TCSVT.2024.3485907",
        "publisher": "IEEE",
        "abstract": "In object goal navigation tasks, the robot’s understanding of semantic relationships in the environment is a key factor in its ability to localize target objects. Previously, learning-based methods trained robots using 3D scene datasets to learn semantic relationships. However, these approaches perform poorly in new environments with unfamiliar semantic contexts. In this paper, we propose ChatNat which leverages the powerful knowledge summarizing and reasoning capabilities of a Large Language Model (LLM) for zero-shot inference of explicit semantic relationships. These relationships are further integrated into the navigation system for efficient localization of target objects. ChatNav employs a spatial object clustering algorithm to collect semantic clues and designs common-sense-based prompts for interacting with LLM. It then uses a gravity-repulsion model to convert inference results into heuristic factors for robust navigation decision-making. Our approach requires no additional training and can consistently obtain accurate semantic relationships from LLM, making it well-suited for navigating unknown environments. Experimental results demonstrate the outstanding navigation performance of our proposed method on the Gibson and HM3D datasets, surpassing the current state-of-the-art object goal navigation methods.",
        "issn": {
            "Print ISSN": "1051-8215",
            "Electronic ISSN": "1558-2205"
        },
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Navigation",
                "Robots",
                "Cognition",
                "TV",
                "Accuracy",
                "Chatbots",
                "Large language models",
                "Decision making",
                "Pipelines"
            ],
            "Author Keywords": [
                "Object goal navigation",
                "LLM",
                "Object clustering",
                "prompt",
                "gravity-repulsion model"
            ]
        },
        "universities": "College of Control Science and Engineering; Institute of Cyberspace Security and College of Information Engineering",
        "countries": "China",
        "locations": [
            "Institute of Cyberspace Security and College of Information Engineering, Zhejiang University of Technology, Hangzhou, China",
            "Institute of Cyberspace Security and College of Information Engineering, Zhejiang University of Technology, Hangzhou, China",
            "Institute of Cyberspace Security and College of Information Engineering, Zhejiang University of Technology, Hangzhou, China",
            "Institute of Cyberspace Security and College of Information Engineering, Zhejiang University of Technology, Hangzhou, China",
            "Institute of Cyberspace Security and College of Information Engineering, Zhejiang University of Technology, Hangzhou, China",
            "Institute of Cyberspace Security and College of Information Engineering, Zhejiang University of Technology, Hangzhou, China",
            "College of Control Science and Engineering, Zhejiang University, Hangzhou, China, and Hangzhou Dianzi University, Hangzhou, China"
        ],
        "title": "ChatNav: Leveraging LLM to Zero-shot Semantic Reasoning in Object Navigation"
    },
    {
        "authors": [
            "Dongyuan Wu",
            "Liming Nie",
            "Rao Asad Mumtaz",
            "Kadambri Agarwal"
        ],
        "published_in": "Published in: IEEE Journal of Biomedical and Health Informatics ( Early Access )",
        "date_of_publication": "16 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/JBHI.2024.3481412",
        "publisher": "IEEE",
        "abstract": "The application of computer vision-powered large language models (LLMs) for medical image diagnosis has significantly advanced healthcare systems. Recent progress in developing symmetrical architectures has greatly impacted various medical imaging tasks. While CNNs or RNNs have demonstrated excellent performance, these architectures often face notable limitations of substantial losses in detailed information, such as requiring to capture global semantic information effectively and relying heavily on deep encoders and aggressive downsampling. This paper introduces a novel LLM-based Hybrid-Transformer Network (HybridTransNet) designed to encode tokenized Big Data patches with the transformer mechanism, which elegantly embeds multimodal data of varying sizes as token sequence inputs of LLMS. Subsequently, the network performs both inter-scale and intra-scale self-attention, processing data features through a transformer-based symmetric architecture with a refining module, which facilitates accurately recovering both local and global context information. Additionally, the output is refined using a novel fuzzy selector. Compared to other existing methods on two distinct datasets, the experimental findings and formal assessment demonstrate that our LLM-based HybridTransNet provides superior performance for brain tumor diagnosis in healthcare informatics.",
        "issn": {
            "Print ISSN": "2168-2194",
            "Electronic ISSN": "2168-2208"
        },
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Image segmentation",
                "Medical diagnostic imaging",
                "Computer architecture",
                "Medical services",
                "Computational modeling",
                "Accuracy",
                "Training",
                "Convolution",
                "Context modeling"
            ],
            "Author Keywords": [
                "Diagnosis",
                "Medical imaging",
                "Transformer",
                "Fuzzy selector",
                "LLM"
            ]
        },
        "universities": "Khyber Medical University; School of Computer and Artificial Intelligence; Shenzhen Technology University; Department of Computer Science and Engineering",
        "countries": "Pakistan; India; China",
        "locations": [
            "School of Computer and Artificial Intelligence, Zhengzhou University, Zhengzhou, China",
            "Shenzhen Technology University, China",
            "Khyber Medical University, Pakistan",
            "Department of Computer Science and Engineering, ABES Engineering College, Ghaziabad, India"
        ],
        "title": "A LLM-Based Hybrid-Transformer Diagnosis System in Healthcare"
    },
    {
        "authors": [
            "Bingbing Xie",
            "Xiaoxiao Ma",
            "Xue Shan",
            "Amin Beheshti",
            "Jian Yang",
            "Hao Fan",
            "Jia Wu"
        ],
        "published_in": "Published in: IEEE Transactions on Computational Social Systems ( Early Access )",
        "date_of_publication": "13 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/TCSS.2024.3488191",
        "publisher": "IEEE",
        "abstract": "The widespread diffusion of fake news has become a critical problem on dynamic social media worldwide, which requires effective strategies for fake news detection to alleviate its hazardous consequences for society. However, most recent efforts only focus on the features of news content and social context without realizing the benefits of large language models (LLMs) and multiple knowledge graphs (KGs), thus failing to improve detection capabilities further. To tackle this issue, we present a multiknowledge and LLM-inspired heterogeneous graph neural network for fake news detection (MiLk-FD), by combining KGs, LLMs, and graph neural networks (GNNs). Specifically, we first model news content as a heterogeneous graph (HG) containing news, entity, and topic nodes and then fuse the knowledge from three KGs to augment the factual basis of news articles. Meanwhile, we leverage TransE to initialize the knowledge features and employ LLaMa2-7B to obtain the initial feature vectors of news articles. After that, we utilize the devised HG transformer to learn news embeddings with specific feature distribution in high-dimensional spaces by aggregating neighborhood information according to metapaths. Finally, a classifier based on multilayer perceptron (MLP) is trained to predict each news article as fake or true. Through experiments, we demonstrate that our proposed framework surpasses ten baselines according to accuracy, precision, F1-score, recall, and ROC in four public real-world benchmarks (i.e., COVID-19, FakeNewsNet, PAN2020, Liar).",
        "issn": {
            "Electronic ISSN": "2329-924X"
        },
        "keywords": {
            "IEEE Keywords": [],
            "Author Keywords": [
                "Deep learning",
                "fake news detection",
                "graph anomaly detection",
                "knowledge graph (KG)",
                "large language model (LLM)"
            ]
        },
        "universities": "School of Information Management; School of Computing",
        "countries": "Australia; China",
        "locations": [
            "School of Information Management, Wuhan University, Wuhan, China",
            "School of Computing, Macquarie University, Sydney, NSW, Australia",
            "School of Computing, Macquarie University, Sydney, NSW, Australia",
            "School of Computing, Macquarie University, Sydney, NSW, Australia",
            "School of Computing, Macquarie University, Sydney, NSW, Australia",
            "School of Information Management, Wuhan University, Wuhan, China",
            "School of Computing, Macquarie University, Sydney, NSW, Australia"
        ],
        "title": "Multiknowledge and LLM-Inspired Heterogeneous Graph Neural Network for Fake News Detection"
    },
    {
        "authors": [
            "Alexander Tobias Neumann",
            "Yue Yin",
            "Sulayman Sowe",
            "Stefan Decker",
            "Matthias Jarke"
        ],
        "published_in": "Published in: IEEE Transactions on Education ( Early Access )",
        "date_of_publication": "07 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/TE.2024.3467912",
        "publisher": "IEEE",
        "abstract": "Contribution: This research explores the benefits and challenges of developing, deploying, and evaluating a large language models (LLMs) chatbot, MoodleBot, in computer science classroom settings. It highlights the potential of integrating LLMs into LMSs like Moodle to support self-regulated learning (SRL) and help-seeking behavior. Background: Computer science educators face immense challenges incorporating novel tools into LMSs to create a supportive and engaging learning environment. MoodleBot addresses this challenge by offering an interactive platform for both students and teachers. Research Questions: Despite issues like bias, hallucinations, and teachers’ and educators’ resistance to embracing new (AI) technologies, this research investigates two questions: (RQ1) To what extent do students accept MoodleBot as a valuable tool for learning support? (RQ2) How accurately does MoodleBot churn out responses, and how congruent are these with the established course content? Methodology: This study reviews pedagogical literature on AI-driven chatbots and adopts the retrieval-augmented generation (RAG) approach for MoodleBot’s design and data processing. The technology acceptance model (TAM) evaluates user acceptance through constructs like perceived usefulness (PU) and Ease of Use. Forty-six students participated, with 30 completing the TAM questionnaire. Findings: LLM-based chatbots like MoodleBot can significantly improve the teaching and learning process. This study revealed a high accuracy rate (88%) in providing course-related assistance. Positive responses from students attest to the efficacy and applicability of AI-driven educational tools. These findings indicate that educational chatbots are suitable for integration into courses to improve personalized learning and reduce teacher administrative burden, although improvements in automated fact-checking are needed.",
        "issn": {
            "Print ISSN": "0018-9359",
            "Electronic ISSN": "1557-9638"
        },
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Education",
                "Computer science",
                "Databases",
                "Accuracy",
                "Mentoring",
                "Information technology",
                "Information systems",
                "Adaptation models",
                "Vectors"
            ],
            "Author Keywords": [
                "Chatbots",
                "higher education",
                "large language model (LLM)",
                "moodle",
                "moodlebot"
            ]
        },
        "universities": "Department of Computer Science5",
        "countries": "Germany",
        "locations": [
            "Department of Computer Science5, RWTH Aachen University, Aachen, Germany",
            "Department of Computer Science5, RWTH Aachen University, Aachen, Germany",
            "Department of Computer Science5, RWTH Aachen University, Aachen, Germany",
            "Department of Computer Science5, RWTH Aachen University, Aachen, Germany",
            "Department of Computer Science5, RWTH Aachen University, Aachen, Germany"
        ],
        "title": "An LLM-Driven Chatbot in Higher Education for Databases and Information Systems"
    },
    {
        "authors": [
            "Hao Zhou",
            "Chengming Hu",
            "Ye Yuan",
            "Yufei Cui",
            "Yili Jin",
            "Can Chen",
            "Haolun Wu",
            "Dun Yuan",
            "Li Jiang",
            "Di Wu",
            "Xue Liu",
            "Charlie Zhang",
            "Xianbin Wang",
            "Jiangchuan Liu"
        ],
        "published_in": "Published in: IEEE Communications Surveys & Tutorials ( Early Access )",
        "date_of_publication": "23 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/COMST.2024.3465447",
        "publisher": "IEEE",
        "abstract": "Large language models (LLMs) have received considerable attention recently due to their outstanding comprehension and reasoning capabilities, leading to great progress in many fields. The advancement of LLM techniques also offers promising opportunities to automate many tasks in the telecommunication (telecom) field. After pre-training and fine-tuning, LLMs can perform diverse downstream tasks based on human instructions, paving the way to artificial general intelligence (AGI)-enabled 6G. Given the great potential of LLM technologies, this work aims to provide a comprehensive overview of LLM-enabled telecom networks. In particular, we first present LLM fundamentals, including model architecture, pre-training, fine-tuning, inference and utilization, model evaluation, and telecom deployment. Then, we introduce LLM-enabled key techniques and telecom applications in terms of generation, classification, optimization, and prediction problems. Specifically, the LLM-enabled generation applications include telecom domain knowledge, code, and network configuration generation. After that, the LLM-based classification applications involve network security, text, image, and traffic classification problems. Moreover, multiple LLM-enabled optimization techniques are introduced, such as automated reward function design for reinforcement learning and verbal reinforcement learning. Furthermore, for LLM-aided prediction problems, we discussed time-series prediction models and multi-modality prediction problems for telecom. Finally, we highlight the challenges and identify the future directions of LLM-enabled telecom networks.",
        "issn": {
            "Electronic ISSN": "1553-877X"
        },
        "keywords": {
            "IEEE Keywords": [
                "Telecommunications",
                "6G mobile communication",
                "Optimization",
                "Surveys",
                "Sensors",
                "Training",
                "Reinforcement learning"
            ],
            "Author Keywords": [
                "Large language model",
                "telecommunications",
                "generation",
                "classification",
                "prediction",
                "optimization"
            ]
        },
        "universities": "Samsung Research America; Department of Electrical and Computer Engineering; School of Computing Science; School of Electrical and Computer Engineering; School of Computer Science",
        "countries": "USA; Canada",
        "locations": [
            "School of Computer Science, McGill University, Montreal, QC, Canada",
            "School of Computer Science, McGill University, Montreal, QC, Canada",
            "School of Computer Science, McGill University, Montreal, QC, Canada",
            "School of Computer Science, McGill University, Montreal, QC, Canada",
            "School of Computer Science, McGill University, Montreal, QC, Canada",
            "School of Computer Science, McGill University, Montreal, QC, Canada",
            "School of Computer Science, McGill University, Montreal, QC, Canada",
            "School of Computer Science, McGill University, Montreal, QC, Canada",
            "School of Computer Science, McGill University, Montreal, QC, Canada",
            "School of Electrical and Computer Engineering, McGill University, Montreal, QC, Canada",
            "School of Computer Science, McGill University, Montreal, QC, Canada",
            "Samsung Research America, Plano, TX, USA",
            "Department of Electrical and Computer Engineering, Western University, London, ON, Canada",
            "School of Computing Science, Simon Fraser University, Burnaby, BC, Canada"
        ],
        "title": "Large Language Model (LLM) for Telecommunications: A Comprehensive Survey on Principles, Key Techniques, and Opportunities"
    },
    {
        "authors": [
            "Cheng Zhang",
            "Minjun Yu",
            "Li Yu",
            "Pengyu Cong",
            "Yan Yuchao",
            "Bao Jie",
            "Jiang Jian",
            "Wang Xiaozheng",
            "Ye Xiaolong",
            "Tang Tao",
            "Xiao Liang"
        ],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "10 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/ACCESS.2024.3456788",
        "publisher": "IEEE",
        "abstract": "Activation checkpointing is a widely-used technique to reduce GPU memory consumption during model training. While it helps to conserve memory, it introduces additional computational load. Existing solutions such as selective activation checkpointing (SAC) and microbatch-based selective recomputation (MSC) are not always available and effective at improving training efficiency. In this paper, we propose a novel method called microbatch-based selective activation checkpointing with recomputation hidden (MSCH). MSCH provides a more flexible and effective utilization of the remaining GPU memory after deployment of all activation checkpointing. This minimizes the need to recalculate activations from a microbatch perspective. In addition, we first discovered the challenging “bottleneck” effect and “misalignment” phenomenon in pipeline parallelism scheduling. To address this, we designed a novel multi-stage micro-batch recalculation schedule that hiding activation recalculation at each stage by the “bottleneck” stage thereby effectively improves model training efficiency. Our code is available by https://github.com/CSlearnerZM/MSCH-DeepSpeed.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Checkpointing",
                "Training",
                "Memory management",
                "Transformers",
                "Partitioning algorithms",
                "Parallel processing",
                "Large language models"
            ],
            "Author Keywords": [
                "Activation checkpointing",
                "Deepspeed",
                "large language model (LLM) training",
                "Megatron",
                "selective checkpointing",
                "1F1B(one forward pass followed by one backward pass)"
            ]
        },
        "universities": "Platform Capability Research and Development Department; Zhejiang Mobile Communications Co.",
        "countries": "China",
        "locations": [
            "Platform Capability Research and Development Department, China Mobile (Zhejiang) Innovation Research Institute Co., Ltd, Hangzhou, ZheJiang, China",
            "Platform Capability Research and Development Department, China Mobile (Zhejiang) Innovation Research Institute Co., Ltd, Hangzhou, ZheJiang, China",
            "Platform Capability Research and Development Department, China Mobile (Zhejiang) Innovation Research Institute Co., Ltd, Hangzhou, ZheJiang, China",
            "Platform Capability Research and Development Department, China Mobile (Zhejiang) Innovation Research Institute Co., Ltd, Hangzhou, ZheJiang, China",
            "Platform Capability Research and Development Department, China Mobile (Zhejiang) Innovation Research Institute Co., Ltd, Hangzhou, ZheJiang, China",
            "Platform Capability Research and Development Department, China Mobile (Zhejiang) Innovation Research Institute Co., Ltd, Hangzhou, ZheJiang, China",
            "Platform Capability Research and Development Department, China Mobile (Zhejiang) Innovation Research Institute Co., Ltd, Hangzhou, ZheJiang, China",
            "Zhejiang Mobile Communications Co., Ltd, HangZhou, ZheJiang, China",
            "Platform Capability Research and Development Department, China Mobile (Zhejiang) Innovation Research Institute Co., Ltd, Hangzhou, ZheJiang, China",
            "Zhejiang Mobile Communications Co., Ltd, HangZhou, ZheJiang, China",
            "Zhejiang Mobile Communications Co., Ltd, HangZhou, ZheJiang, China"
        ],
        "title": "MSCH: Microbatch-based Selective Activation Checkpointing with Recomputation Hidden for Efficient Training of LLM Models"
    },
    {
        "authors": [
            "Jiaying Lu",
            "Bo Pan",
            "Jieyi Chen",
            "Yingchaojie Feng",
            "Jingyuan Hu",
            "Yuchen Peng",
            "Wei Chen"
        ],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "03 May 2024",
        "publication_month": "May",
        "publication_year": 2024,
        "doi": "10.1109/TVCG.2024.3394053",
        "publisher": "IEEE",
        "abstract": "Recently, Large Language Model based Autonomous System (LLMAS) has gained great popularity for its potential to simulate complicated behaviors of human societies. One of its main challenges is to present and analyze the dynamic events evolution of LLMAS. In this work, we present a visualization approach to explore the detailed statuses and agents' behavior within LLMAS. Our approach outlines a general pipeline that organizes raw execution events from LLMAS into a structured behavior model. We leverage a behavior summarization algorithm to create a hierarchical summary of these behaviors, arranged according to their sequence over time. Additionally, we design a cause trace method to mine the causal relationship between agent behaviors. We then develop AgentLens , a visual analysis system that leverages a hierarchical temporal visualization for illustrating the evolution of LLMAS, and supports users to interactively investigate details and causes of agents' behaviors. Two usage scenarios and a user study demonstrate the effectiveness and usability of our AgentLens .",
        "issn": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "keywords": {
            "IEEE Keywords": [
                "Visualization",
                "Task analysis",
                "Autonomous systems",
                "Data visualization",
                "Monitoring",
                "Complexity theory",
                "Collaboration"
            ],
            "Author Keywords": [
                "LLM",
                "autonomous system",
                "agent",
                "visual analysis"
            ]
        },
        "universities": "",
        "countries": "",
        "locations": [],
        "title": "AgentLens: Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems"
    },
    {
        "authors": [
            "Feng Huang",
            "Xia Sun",
            "Aizhu Mei",
            "Yilin Wang",
            "Huimin Ding",
            "Tingshao Zhu"
        ],
        "published_in": "Published in: IEEE Transactions on Computational Social Systems ( Early Access )",
        "date_of_publication": "22 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/TCSS.2024.3475413",
        "publisher": "IEEE",
        "abstract": "This study explores an innovative approach to predicting individual life satisfaction by combining large language models (LLMs) with machine learning (ML) techniques. Traditional life satisfaction assessments rely on self-report questionnaires, which can be time-consuming and resource intensive. To address these limitations, we developed a method that utilizes LLMs for feature extraction from open-ended self-statement texts, followed by ML prediction. We compared this approach with standalone LLM predictions and expert ratings. A sample of 378 participants completed the satisfaction with life scale (SWLS) and wrote self-statements about their current life situation. The LLM-based ML model, using a LightGBM regressor, achieved a correlation of 0.542 with self-reported SWLS scores, outperforming both the standalone LLM ( r = 0.491) and expert ratings ( r = 0.455). Effect size analysis revealed a statistically significant moderate effect size difference between the LLM-based ML model and expert ratings (Cohen’s d = 0.499, 95% CI [0.043, 0.955]). These findings demonstrate the potential of integrating LLM and ML for an efficient and accurate assessment of life satisfaction, challenging conventional methods, and opening new avenues for psychological measurement. The study’s implications extend to research, clinical practice, and policymaking, offering promising advancements in AI-assisted psychological assessment.",
        "issn": {
            "Electronic ISSN": "2329-924X"
        },
        "keywords": {
            "IEEE Keywords": [
                "Predictive models",
                "Psychology",
                "Analytical models",
                "Data models",
                "Regression tree analysis",
                "Machine learning",
                "Correlation",
                "Computational modeling",
                "Feature extraction",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Large language models",
                "life satisfaction",
                "machine learning",
                "natural language processing",
                "psychometrics"
            ]
        },
        "universities": "School of Education; CAS Key Laboratory of Behavioral Science",
        "countries": "China",
        "locations": [
            "CAS Key Laboratory of Behavioral Science, Institute of Psychology, Chinese Academy of Sciences, Beijing, China",
            "CAS Key Laboratory of Behavioral Science, Institute of Psychology, Chinese Academy of Sciences, Beijing, China",
            "CAS Key Laboratory of Behavioral Science, Institute of Psychology, Chinese Academy of Sciences, Beijing, China",
            "CAS Key Laboratory of Behavioral Science, Institute of Psychology, Chinese Academy of Sciences, Beijing, China",
            "School of Education, Renmin University of China, Beijing, China",
            "CAS Key Laboratory of Behavioral Science, Institute of Psychology, Chinese Academy of Sciences, Beijing, China"
        ],
        "title": "LLM Plus Machine Learning Outperform Expert Rating to Predict Life Satisfaction From Self-Statement Text"
    },
    {
        "authors": [
            "Zhengxing Lan",
            "Lingshan Liu",
            "Bo Fan",
            "Yisheng Lv",
            "Yilong Ren",
            "Zhiyong Cui"
        ],
        "published_in": "Published in: IEEE Transactions on Intelligent Vehicles ( Early Access )",
        "date_of_publication": "27 June 2024",
        "publication_month": "June",
        "publication_year": 2024,
        "doi": "10.1109/TIV.2024.3418522",
        "publisher": "IEEE",
        "abstract": "Predicting the future trajectories of dynamic traffic actors is a cornerstone task in autonomous driving. Though existing notable efforts have resulted in impressive performance improvements, a gap persists in scene cognitive and understanding of complex traffic semantics. This paper proposes Traj-LLM, the first to investigate the potential of using pre-trained Large Language Models (LLMs) without explicit prompt engineering to generate future motions from vehicular past trajectories and traffic scene semantics. Traj-LLM starts with sparse context joint encoding to dissect the agent and scene features into a form that LLMs understand. On this basis, we creatively explore LLMs' strong understanding capability to capture a spectrum of high-level scene knowledge and interactive information. To emulate the human-like lane focus cognitive function and enhance Traj-LLM's scene comprehension, we introduce lane-aware probabilistic learning powered by the Mamba module. Finally, a multi-modal Laplace decoder is designed to achieve scene-compliant predictions. Extensive experiments manifest that Traj-LLM, fueled by prior knowledge and understanding prowess of LLMs, together with lane-aware probability learning, transcends the state-of-the-art methods across most evaluation metrics. Moreover, the few-shot analysis serves to substantiate Traj-LLM's performance, as even with merely 50% of the dataset, it surpasses the majority of benchmarks relying on complete data utilization. This study explores endowing the trajectory prediction task with advanced capabilities inherent in LLMs, furnishing a more universal and adaptable solution for forecasting agent movements in a new way.",
        "issn": {
            "Electronic ISSN": "2379-8904",
            "Print ISSN": "2379-8858"
        },
        "keywords": {
            "IEEE Keywords": [
                "Trajectory",
                "Task analysis",
                "Predictive models",
                "Autonomous vehicles",
                "Forecasting",
                "Encoding",
                "Cognition"
            ],
            "Author Keywords": [
                "Autonomous vehicles",
                "large language models (LLMs)",
                "mamba",
                "trajectory prediction"
            ]
        },
        "universities": "School of Transportation Science and Engineering; State Key Laboratory of Multimodal Artificial Intelligence Systems; Beijing Key Laboratory of Traffic Engineering",
        "countries": "China",
        "locations": [
            "School of Transportation Science and Engineering, Beihang University, Beijing, China",
            "School of Transportation Science and Engineering, Beihang University, Beijing, China",
            "Beijing Key Laboratory of Traffic Engineering, College of Metropolitan Transportation, Beijing University of Technology, Beijing, China",
            "State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China",
            "School of Transportation Science and Engineering, State Key Lab of Intelligent Transportation System, Beihang University, Beijing, China",
            "School of Transportation Science and Engineering, State Key Lab of Intelligent Transportation System, Beihang University, Beijing, China"
        ],
        "title": "Traj-LLM: A New Exploration for Empowering Trajectory Prediction With Pre-Trained Large Language Models"
    },
    {
        "authors": [
            "Minsuk Kahng",
            "Ian Tenney",
            "Mahima Pushkarna",
            "Michael Xieyang Liu",
            "James Wexler",
            "Emily Reif",
            "Krystal Kallarackal",
            "Minsuk Chang",
            "Michael Terry",
            "Lucas Dixon"
        ],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "10 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/TVCG.2024.3456354",
        "publisher": "IEEE",
        "abstract": "Evaluating large language models (LLMs) presents unique challenges. While automatic side-by-side evaluation, also known as LLM-as-a-judge, has become a promising solution, model developers and researchers face difficulties with scalability and interpretability when analyzing these evaluation outcomes. To address these challenges, we introduce LLM Comparator, a new visual analytics tool designed for side-by-side evaluations of LLMs. This tool provides analytical workflows that help users understand when and why one LLM outperforms or underperforms another, and how their responses differ. Through close collaboration with practitioners developing LLMs at Google, we have iteratively designed, developed, and refined the tool. Qualitative feedback from these users highlights that the tool facilitates in-depth analysis of individual examples while enabling users to visually overview and flexibly slice data. This empowers users to identify undesirable patterns, formulate hypotheses about model behavior, and gain insights for model improvement. LLM Comparator has been integrated into Google's LLM evaluation platforms and open-sourced",
        "issn": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "keywords": {
            "IEEE Keywords": [
                "Internet",
                "Analytical models",
                "Pipelines",
                "Large language models",
                "Oral communication",
                "Numerical models",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Visual analytics",
                "large language models",
                "model evaluation",
                "responsible AI",
                "machine learning interpretability"
            ]
        },
        "universities": "Google Research",
        "countries": "USA",
        "locations": [
            "Google Research, USA",
            "Google Research, USA",
            "Google Research, USA",
            "Google Research, USA",
            "Google Research, USA",
            "Google Research, USA",
            "Google Research, USA",
            "Google Research, USA",
            "Google Research, USA",
            "Google Research, USA"
        ],
        "title": "LLM Comparator: Interactive Analysis of Side-by-Side Evaluation of Large Language Models"
    },
    {
        "authors": [
            "Hongwei Cui",
            "Yuyang Du",
            "Qun Yang",
            "Yulin Shao",
            "Soung Chang Liew"
        ],
        "published_in": "Published in: IEEE Communications Magazine ( Early Access )",
        "date_of_publication": "27 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/MCOM.002.2400106",
        "publisher": "IEEE",
        "abstract": "Task-oriented communications are an important element in future intelligent IoT systems. Existing IoT systems, however, are limited in their capacity to handle complex tasks, particularly in their interactions with humans to accomplish these tasks. In this article, we present LLMind, a large language model-based (LLM-based), task-oriented AI agent framework that enables effective collaboration among IoT devices, with humans communicating high-level verbal instructions, to perform complex tasks. Inspired by the functional specialization theory of the brain, our framework integrates an LLM with domain-specific AI modules, enhancing its capabilities. Complex tasks, which may involve collaborations of multiple domain-specific AI modules and IoT devices, are executed through a control script generated by the LLM using a Language- Code transformation approach, which first converts language descriptions to an intermediate finite-state machine (FSM) before final precise transformation to code. Furthermore, the framework incorporates a novel experience accumulation mechanism to enhance response speed and effectiveness, allowing the framework to evolve and become progressively sophisticated through continuing user and machine interactions.",
        "issn": {
            "Print ISSN": "0163-6804",
            "Electronic ISSN": "1558-1896"
        },
        "keywords": {
            "IEEE Keywords": [
                "Internet of Things",
                "Artificial intelligence",
                "Codes",
                "Collaboration",
                "Reliability",
                "Performance evaluation",
                "Transforms",
                "Social networking (online)",
                "Process control",
                "Planning"
            ],
            "Author Keywords": []
        },
        "universities": "",
        "countries": "",
        "locations": [],
        "title": "LLMind: Orchestrating AI and IoT with LLM for Complex Task Execution"
    },
    {
        "authors": [
            "Qiang Liu",
            "Junsheng Mu",
            "Da Chen",
            "Ronghui Zhang",
            "Yijian Liu",
            "Tao Hong"
        ],
        "published_in": "Published in: IEEE Transactions on Vehicular Technology ( Early Access )",
        "date_of_publication": "06 May 2024",
        "publication_month": "May",
        "publication_year": 2024,
        "doi": "10.1109/TVT.2024.3395748",
        "publisher": "IEEE",
        "abstract": "This paper develops a new approach of large language model (LLM) enhanced reconfigurable intelligent surface (RIS), in a bid to achieve energy-efficient and reliable communication in 6G Internet of Vehicles (IoV). It is well known that RIS offers an innovative solution to improve signal quality by intelligently adjusting the propagation path of radio waves. However, configuring RIS in the dynamically changing vehicular environment remains a challenge. This study leverages the analytical capabilities of LLM, combined with key IoV data such as channel status, vehicle movement patterns, and quality of service requirements, to model and optimize RIS-based IoV communication systems. The work focuses on constructing a realtime model of the RIS-based IoV wireless transmission system and proposes an optimal strategy for wireless resource allocation. Through comprehensive simulation results, this paper justifies the significant performance advantages of LLM-enhanced RIS, demonstrating a viable technical pathway for the development of 6G IoV.",
        "issn": {
            "Print ISSN": "0018-9545",
            "Electronic ISSN": "1939-9359"
        },
        "keywords": {
            "IEEE Keywords": [
                "Reconfigurable intelligent surfaces",
                "Wireless communication",
                "Wireless sensor networks",
                "Quality of service",
                "Reliability",
                "6G mobile communication",
                "Optimization"
            ],
            "Author Keywords": [
                "reconfigurable intelligent surface",
                "large language model",
                "6G",
                "Internet of Vehicles"
            ]
        },
        "universities": "School of Electronics and Information Engineering; College of Electronic and Information Engineering; School of Information and Communication Engineering",
        "countries": "China",
        "locations": [
            "College of Electronic and Information Engineering, Shandong University of Science and Technology, Qingdao, China",
            "School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China",
            "College of Electronic and Information Engineering, Shandong University of Science and Technology, Qingdao, China",
            "School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China",
            "College of Electronic and Information Engineering, Shandong University of Science and Technology, Qingdao, China",
            "School of Electronics and Information Engineering, Beihang University, Beijing, China"
        ],
        "title": "LLM Enhanced Reconfigurable Intelligent Surface for Energy-Efficient and Reliable 6G IoV"
    },
    {
        "authors": [
            "Yuzhe Zhang",
            "Huan Liu",
            "Yang Xiao",
            "Mohammed Amoon",
            "Dalin Zhang",
            "Di Wang",
            "Shusen Yang",
            "Chai Quek"
        ],
        "published_in": "Published in: IEEE Journal of Biomedical and Health Informatics ( Early Access )",
        "date_of_publication": "30 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/JBHI.2024.3470338",
        "publisher": "IEEE",
        "abstract": "The critical importance of monitoring and recognizing human emotional states in healthcare has led to a surge in proposals for EEG-based multimodal emotion recognition in recent years. However, practical challenges arise in acquiring EEG signals in daily healthcare settings due to stringent data acquisition conditions, resulting in the issue of incomplete modalities. Existing studies have turned to knowledge distillation as a means to mitigate this problem by transferring knowledge from multimodal networks to unimodal ones. However, these methods are constrained by the use of a single teacher model to transfer integrated feature extraction knowledge, particularly concerning spatial and temporal features in EEG data. To address this limitation, we propose a multi-teacher knowledge distillation framework enhanced with a Large Language Model (LLM), aimed at facilitating effective feature learning in the student network by transferring knowledge of extracting integrated features. Specifically, we employ an LLM as the teacher for extracting temporal features and a graph convolutional neural network for extracting spatial features. To further enhance knowledge distillation, we introduce causal masking and a confidence indicator into the LLM to facilitate the transfer of the most discriminative features. Extensive testing on the DEAP and MAHNOB-HCI datasets demonstrates that our model outperforms existing methods in the modality-incomplete scenario. This study underscores the potential application of large models in this field. The code is publicly available at https://github.com/yuzhezhangEEG/LM-KD .",
        "issn": {
            "Print ISSN": "2168-2194",
            "Electronic ISSN": "2168-2208"
        },
        "keywords": {
            "IEEE Keywords": [
                "Brain modeling",
                "Electroencephalography",
                "Emotion recognition",
                "Physiology",
                "Knowledge engineering",
                "Feature extraction",
                "Medical services",
                "Bioinformatics",
                "Biological system modeling",
                "Training"
            ],
            "Author Keywords": [
                "Healthcare",
                "Emotion Recognition",
                "Large Language Model",
                "Multi-teacher Knowledge Distillation"
            ]
        },
        "universities": "Ministry of Education Key Laboratory of Intelligent Networks and Network Security; School of Computer Science and Engineering; Department of Computer Science; School of Cyber Engineering",
        "countries": "Saudi Arabia; Denmark; Singapore; China",
        "locations": [
            "Ministry of Education Key Laboratory of Intelligent Networks and Network Security, School of Computer Science and Technology, Xi'an Jiaotong University, Xi'an, China",
            "Ministry of Education Key Laboratory of Intelligent Networks and Network Security, School of Computer Science and Technology, Xi'an Jiaotong University, Xi'an, China",
            "School of Cyber Engineering, Xidian University, Xi'an, China",
            "Department of Computer Science, Community College, King Saud University, Riyadh, Saudi Arabia",
            "Department of Computer Science, Aalborg University, Aalborg, Denmark",
            "School of Computer Science and Engineering, Nanyang Technological University, Singapore",
            "Ministry of Education Key Laboratory of Intelligent Networks and Network Security, School of Computer Science and Technology, Xi'an Jiaotong University, Xi'an, China",
            "School of Computer Science and Engineering, Nanyang Technological University, Singapore"
        ],
        "title": "LLM-Enhanced Multi-Teacher Knowledge Distillation for Modality-Incomplete Emotion Recognition in Daily Healthcare"
    },
    {
        "authors": [
            "Bin Xiao",
            "Burak Kantarci",
            "Jiawen Kang",
            "Dusit Niyato",
            "Mohsen Guizani"
        ],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "04 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/JIOT.2024.3470210",
        "publisher": "IEEE",
        "abstract": "Large language models (LLMs) have demonstrated remarkable capacities on various tasks, and integrating the capacities of LLMs into the Internet of Things (IoT) applications has drawn much research attention recently. Due to security concerns, many institutions avoid accessing state-of-the-art commercial LLM services, requiring the deployment and utilization of open-source LLMs in a local network setting. However, open-source LLMs usually have more limitations regarding their performance, such as their arithmetic calculation and reasoning capacities, and practical systems of applying LLMs to IoT have yet to be well-explored. Therefore, we propose a LLM-based Generative IoT (GIoT) system deployed in the local network setting in this study. To alleviate the limitations of LLMs and provide service with competitive performance, we apply prompt engineering methods to enhance the capacities of the open-source LLMs, design a Prompt Management Module and a Post-processing Module to manage the tailored prompts for different tasks and process the results generated by the LLMs. To demonstrate the effectiveness of the proposed system, we discuss a challenging Table Question Answering (Table-QA) task as a case study of the proposed system, as tabular data is usually more challenging than plain text because of their complex structures, heterogeneous data types and sometimes huge sizes. We conduct comprehensive experiments on two popular Table-QA datasets, and the results show that our proposal can achieve competitive performance compared with state-of-the-art LLMs, demonstrating that the proposed LLM-based GIoT system can provide competitive performance with tailored prompting methods and is easily extensible to new tasks without training.",
        "issn": {
            "Electronic ISSN": "2327-4662"
        },
        "keywords": {
            "IEEE Keywords": [
                "Internet of Things",
                "Cognition",
                "Python",
                "Artificial intelligence",
                "Structured Query Language",
                "Training",
                "Servers",
                "Question answering (information retrieval)",
                "Security",
                "Performance evaluation"
            ],
            "Author Keywords": [
                "Generative Internet of Things",
                "Table Question Answering",
                "Prompt Engineering",
                "Large Language Model"
            ]
        },
        "universities": "Guandong University of Technology; Mohamed bin Zayed University of Artificial Intelligence (MBZUAI); Nanyang Technological University; School of Electrical Engineering and Computer Science",
        "countries": "UAE; Singapore; Canada; China",
        "locations": [
            "School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada",
            "School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada",
            "Guandong University of Technology, China",
            "Nanyang Technological University, Singapore",
            "Mohamed bin Zayed University of Artificial Intelligence (MBZUAI), Abu Dhabi, UAE"
        ],
        "title": "Efficient Prompting for LLM-Based Generative Internet of Things"
    },
    {
        "authors": [
            "Shang Liu",
            "Wenji Fang",
            "Yao Lu",
            "Jing Wang",
            "Qijun Zhang",
            "Hongce Zhang",
            "Zhiyao Xie"
        ],
        "published_in": "Published in: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems ( Early Access )",
        "date_of_publication": "17 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/TCAD.2024.3483089",
        "publisher": "IEEE",
        "abstract": "The automatic generation of RTL code (e.g., Verilog) using natural language instructions and large language models (LLMs) has attracted significant research interest recently. However, most existing approaches heavily rely on commercial LLMs such as ChatGPT, while open-source LLMs tailored for this specific design generation task exhibit notably inferior performance. The absence of high-quality open-source solutions restricts the flexibility and data privacy of this emerging technique. In this study, we present a new customized LLM solution with a modest parameter count of only 7B, achieving better performance than GPT-3.5 on all representative benchmarks for RTL code generation. Especially, it outperforms GPT-4 in VerilogEval Machine benchmark. This remarkable balance between accuracy and efficiency is made possible by leveraging our new RTL code dataset and a customized LLM algorithm, both of which have been made fully open-source. Furthermore, we have successfully quantized our LLM to 4-bit with a total size of 4GB, enabling it to function on a single laptop with only slight performance degradation. This efficiency allows the RTL generator to serve as a local assistant for engineers, ensuring all design privacy concerns are addressed.",
        "issn": {
            "Print ISSN": "0278-0070",
            "Electronic ISSN": "1937-4151"
        },
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Hardware design languages",
                "Training",
                "Integrated circuit modeling",
                "Data models",
                "Natural languages",
                "Hardware",
                "Data collection",
                "Benchmark testing",
                "Privacy"
            ],
            "Author Keywords": []
        },
        "universities": "Department of Electronic and Computer Engineering",
        "countries": "China",
        "locations": [
            "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology (HKUST), Hong Kong, China",
            "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology (HKUST), Hong Kong, China",
            "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology (HKUST), Hong Kong, China",
            "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology (HKUST), Hong Kong, China",
            "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology (HKUST), Hong Kong, China",
            "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology (HKUST), Hong Kong, China",
            "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology (HKUST), Hong Kong, China"
        ],
        "title": "RTLCoder: Fully Open-Source and Efficient LLM-Assisted RTL Code Generation Technique"
    },
    {
        "authors": [
            "Wentian Cai",
            "Yijiang Li",
            "Yandan Chen",
            "Jing Lin",
            "Zihao Huang",
            "Ping Gao",
            "Thippa Reddy Gadekallu",
            "Wei Wang",
            "Ying Gao"
        ],
        "published_in": "Published in: IEEE Journal of Biomedical and Health Informatics ( Early Access )",
        "date_of_publication": "05 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/JBHI.2024.3450013",
        "publisher": "IEEE",
        "abstract": "Histopathological whole-slide image (WSI) segmentation is essential for precise tissue characterization in medical diagnostics. However, traditional approaches require labor-intensive pixel-level annotations. To this end, we study weakly supervised semantic segmentation (WSSS) which uses patch-level classification labels, reducing annotation efforts significantly. However, the complexity of WSIs and the challenge of sparse classification labels hinder effective dense pixel predictions. Moreover, due to the multi-label nature of WSI, existingapproachesofsingle-labelcontrastivelearningdesignedfortherepresentationofsingle-category, neglecting the presence of other relevant categories and thus fail to adapt to WSI tasks. This paper presents a novel multilabel contrastive learning method for WSSS by incorporating class-specific embedding extraction with LLM features guidance. Specifically, we propose to obtain class-specific embeddings by utilizing classifier weights, followed by a dot-product-based attention fusion method that leverages LLM features to enrich their semantics, facilitating contrastive learning between different classes from single image. Besides, we propose a Robust Learning approach that leverages multi-layer features to evaluate the uncertainty of pseudo-labels, thereby mitigating the impact of noisy pseudo-labels on the learning process of segmentation. Extensive experiments have been conducted on two Histopathological image segmentation datasets, i.e. LUAD dataset and BCSS dataset, demonstrating the effectiveness of our methods with leading performance.",
        "issn": {
            "Print ISSN": "2168-2194",
            "Electronic ISSN": "2168-2208"
        },
        "keywords": {
            "IEEE Keywords": [
                "Contrastive learning",
                "Feature extraction",
                "Semantics",
                "Annotations",
                "Uncertainty",
                "Noise measurement",
                "Semantic segmentation"
            ],
            "Author Keywords": [
                "Weakly supervised learning",
                "medical image segmentation",
                "contrastive learning",
                "LLMs"
            ]
        },
        "universities": "Department of Geriatric Respiratory Medicine; School of Computer Science and Engineering; Johns Hopkins University; Division of Research and Development; Guangdong-HongKong-Macao Joint Laboratory for Emotional Intelligence and Pervasive Computing",
        "countries": "P. R. China; India; USA; China",
        "locations": [
            "School of Computer Science and Engineering, South China University of Technology, Guangzhou, P. R. China",
            "Johns Hopkins University, Baltimore, MD, USA",
            "School of Computer Science and Engineering, South China University of Technology, Guangzhou, P. R. China",
            "School of Computer Science and Engineering, South China University of Technology, Guangzhou, P. R. China",
            "School of Computer Science and Engineering, South China University of Technology, Guangzhou, P. R. China",
            "Department of Geriatric Respiratory Medicine, Guangdong Provincial People's Hospital, Guangdong Academy of Medical Sciences, and the Guangdong Provincial Geriatrics Institute, Guangzhou, Guangdong, China",
            "Division of Research and Development, Lovely Professional University, Phagwara, India",
            "Guangdong-HongKong-Macao Joint Laboratory for Emotional Intelligence and Pervasive Computing, Artificial Intelligence Research Institute, Shenzhen MSU-BIT University, Shenzhen, Guangdong, China",
            "School of Computer Science and Engineering, South China University of Technology, Guangzhou, P. R. China"
        ],
        "title": "Enhancing Weakly Supervised Semantic Segmentation with Multi-label Contrastive Learning and LLM Features Guidance"
    },
    {
        "authors": [
            "Ya Li",
            "Xuecong Zheng",
            "Jiaping Li",
            "Qingyun Dai",
            "Chang-Dong Wang",
            "Min Chen"
        ],
        "published_in": "Published in: IEEE Journal of Biomedical and Health Informatics ( Early Access )",
        "date_of_publication": "11 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/JBHI.2024.3478809",
        "publisher": "IEEE",
        "abstract": "Clinical staging of liver cancer (CSoLC), an important indicator for evaluating the degree of deterioration of primary liver cancer cells (PLCCs), is key in the diagnosis, treatment, and rehabilitation of liver cancer. In China, the current CSoLC adopts the China liver cancer (CNLC) staging, which is usually evaluated by clinicians based on the patient's radiology reports. Therefore, inferring clinical information from unstructured radiology reports can provide auxiliary decision support for clinicians. The key to solving the challenging task is to guide the model to pay attention to the staging-related words or sentences, and the following issues may occur: 1) Imbalanced categories: The symptoms of liver cancer in the early- or mid-stage are not obvious, resulting in more data in the end-stage. 2) Domain sensitivity of liver cancer data: The liver cancer dataset contains a large amount of domain knowledge, and the conventional methods can exacerbate out-of-vocabulary, which greatly affects the accuracy of classification. 3) Free-text and lengthy report: The radiology report of liver cancer sparsely describes various lesions with domain-specific terms, which poses difficulties in mining key information related to staging. To tackle these challenges, this article proposes a large language model (LLM)-based Knowledge-aware Attention Network (LKAN) for CSoLC. First, for maintaining semantic consistency, LLM and a rule-based algorithm are integrated to generate more diverse and reasonable data. Second, unlabeled radiology corpus of liver cancer are pre-trained to introduce domain knowledge for subsequent representation learning. Third, attention is improved by incorporating both global and local features, which can provide professional guidance for the classifier to focus on the important information. Compared with the baseline models, the classification accuracy of LKAN has achieved the best results with 90.3% Accuracy, 90.0% Macro_F1 score, and 90.0% Macro_Recall. The...",
        "issn": {
            "Print ISSN": "2168-2194",
            "Electronic ISSN": "2168-2208"
        },
        "keywords": {
            "IEEE Keywords": [
                "Radiology",
                "Liver cancer",
                "Cancer",
                "Accuracy",
                "Liver",
                "Lesions",
                "Bioinformatics",
                "Sensitivity",
                "Magnetic resonance imaging",
                "Vectors"
            ],
            "Author Keywords": [
                "Clinical staging of liver cancer (CSoLC)",
                "Chinese radiology reports",
                "natural language processing",
                "domain knowledge"
            ]
        },
        "universities": "Department of Interventional Oncology; School of Computer Science and Engineering; School of Electronics and Information",
        "countries": "China",
        "locations": [
            "School of Electronics and Information, Guangdong Polytechnic Normal University, Guangzhou, Guangdong, China",
            "School of Electronics and Information, Guangdong Polytechnic Normal University, Guangzhou, Guangdong, China",
            "Department of Interventional Oncology, the First Affiliated Hospital, Sun Yat-sen University, Guangzhou, China",
            "School of Electronics and Information, Guangdong Polytechnic Normal University, Guangzhou, Guangdong, China",
            "School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China",
            "School of Computer Science and Engineering, South China University of Technology, Guangzhou, China"
        ],
        "title": "LKAN: LLM-Based Knowledge-Aware Attention Network for Clinical Staging of Liver Cancer"
    },
    {
        "authors": [
            "Changshi Zhou",
            "Weiqi Liu",
            "Tao Han",
            "Nirwan Ansari"
        ],
        "published_in": "Published in: IEEE Networking Letters ( Early Access )",
        "date_of_publication": "04 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/LNET.2024.3490954",
        "publisher": "IEEE",
        "abstract": "From AI-assisted art creation to large language model (LLM)-powered ChatGPT, AI-generated contents and services are becoming a transforming force. It calls for the telecom industry to embrace the prospects of AIGC services and face the unique challenges posed by incorporating generative model services into the AI-native 6G wireless network paradigm. We propose enabling AIGC inference services on mobile devices by optimizing MEC-device computing offloading, through which AIGC task latency is minimized by reinforcement learning based policy agent in a computing resource constrained and bandwidth limited wireless environment. Simulation results are presented to demonstrate the performance advantage.",
        "issn": {
            "Electronic ISSN": "2576-3156"
        },
        "keywords": {
            "IEEE Keywords": [
                "Servers",
                "Computational modeling",
                "Telecommunications",
                "Mobile handsets",
                "Wireless sensor networks",
                "Chatbots",
                "Wireless networks",
                "Optimization",
                "Interference",
                "Collaboration"
            ],
            "Author Keywords": [
                "LLM",
                "AIGC",
                "ChatGPT",
                "MEC",
                "On-device Computing",
                "6G",
                "Constrained Reinforcement Learning"
            ]
        },
        "universities": "Dept. of Electrical and Computer Engineering; Department of Computer Science and Computer Information Systems",
        "countries": "USA",
        "locations": [
            "Dept. of Electrical and Computer Engineering, New Jersey Institute of Technology, NJ, USA",
            "Department of Computer Science and Computer Information Systems, Auburn University, Montgomery, AL, USA",
            "Dept. of Electrical and Computer Engineering, New Jersey Institute of Technology, NJ, USA",
            "Dept. of Electrical and Computer Engineering, New Jersey Institute of Technology, NJ, USA"
        ],
        "title": "Deploying On-device AIGC Inference Services in 6G via Optimal MEC-device Offloading"
    },
    {
        "authors": [
            "Yiheng Zhang",
            "Yunkang Cao",
            "Xiaohao Xu",
            "Weiming Shen"
        ],
        "published_in": "Published in: IEEE Transactions on Automation Science and Engineering ( Early Access )",
        "date_of_publication": "09 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/TASE.2024.3468464",
        "publisher": "IEEE",
        "abstract": "This paper presents LogiCode, a novel framework that leverages Large Language Models (LLMs) for identifying logical anomalies in industrial settings, moving beyond the traditional focus on structural inconsistencies. By harnessing LLMs for logical reasoning, LogiCode autonomously generates Python codes to pinpoint anomalies such as incorrect component quantities or missing elements, marking a significant leap forward in anomaly detection technologies. A custom dataset “LOCO-Annotations” and a benchmark “LogiBench” are introduced to evaluate the LogiCode’s performance across various metrics including binary classification accuracy, code generation success rate, and precision in reasoning. Findings demonstrate LogiCode’s enhanced interpretability, significantly improving the accuracy of logical anomaly detection and offering detailed explanations for identified anomalies. This represents a notable shift towards more intelligent, LLM-driven approaches in industrial anomaly detection, promising substantial impacts on industry-specific applications. Our code are available at https://github.com/22strongestme/LOCO-Annotations. Note to Practitioners —This work introduces LogiCode, an innovative system leveraging Large Language Models (LLMs) for logical anomaly detection in industrial settings, shifting the paradigm from traditional visual inspection methods. LogiCode autonomously generates Python codes for logical anomaly detection, enhancing interpretability and accuracy. Our novel approach, validated through the “LOCO-Annotations” dataset and LogiBench benchmark, demonstrates superior performance in identifying logical anomalies, a challenge often encountered in complex industrial components like assembly and packaging. LogiCode provides a significant advancement in addressing the nuanced requirements of detecting logical anomalies, offering a robust and interpretable solution to practitioners seeking to enhance quality control and reduce manual inspection efforts.",
        "issn": {
            "Print ISSN": "1545-5955",
            "Electronic ISSN": "1558-3783"
        },
        "keywords": {
            "IEEE Keywords": [
                "Anomaly detection",
                "Codes",
                "Cognition",
                "Visualization",
                "Semantics",
                "Logic",
                "Image reconstruction",
                "Automation",
                "Accuracy",
                "Benchmark testing"
            ],
            "Author Keywords": [
                "Logical anomaly detection",
                "large language models",
                "industrial anomaly detection",
                "dataset annotation"
            ]
        },
        "universities": "Michigan Robotics; State Key Laboratory of Intelligent Manufacturing Equipment and Technology",
        "countries": "USA; China",
        "locations": [
            "State Key Laboratory of Intelligent Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, China",
            "State Key Laboratory of Intelligent Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, China",
            "Michigan Robotics, University of Michigan, Ann Arbor, MI, USA",
            "State Key Laboratory of Intelligent Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, China"
        ],
        "title": "LogiCode: An LLM-Driven Framework for Logical Anomaly Detection"
    },
    {
        "authors": [
            "Jaeyoung Kim",
            "Sihyeon Lee",
            "Hyeon Jeon",
            "Keon-Joo Lee",
            "Hee-Joon Bae",
            "Bohyoung Kim",
            "Jinwook Seo"
        ],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "24 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/TVCG.2024.3456215",
        "publisher": "IEEE",
        "abstract": "Acute stroke demands prompt diagnosis and treatment to achieve optimal patient outcomes. However, the intricate and irregular nature of clinical data associated with acute stroke, particularly blood pressure (BP) measurements, presents substantial obstacles to effective visual analytics and decision-making. Through a year-long collaboration with experienced neurologists, we developed PhenoFlow, a visual analytics system that leverages the collaboration between human and Large Language Models (LLMs) to analyze the extensive and complex data of acute ischemic stroke patients. PhenoFlow pioneers an innovative workflow, where the LLM serves as a data wrangler while neurologists explore and supervise the output using visualizations and natural language interactions. This approach enables neurologists to focus more on decision-making with reduced cognitive load. To protect sensitive patient information, PhenoFlow only utilizes metadata to make inferences and synthesize executable codes, without accessing raw patient data. This ensures that the results are both reproducible and interpretable while maintaining patient privacy. The system incorporates a slice-and-wrap design that employs temporal folding to create an overlaid circular visualization. Combined with a linear bar graph, this design aids in exploring meaningful patterns within irregularly measured BP data. Through case studies, PhenoFlow has demonstrated its capability to support iterative analysis of extensive clinical datasets, reducing cognitive load and enabling neurologists to make well-informed decisions. Grounded in long-term collaboration with domain experts, our research demonstrates the potential of utilizing LLMs to tackle current challenges in data-driven clinical decision-making for acute ischemic stroke patients",
        "issn": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Visual analytics",
                "Stroke (medical condition)",
                "Cognitive load",
                "Collaboration",
                "Electronic mail",
                "Decision making"
            ],
            "Author Keywords": [
                "Stroke",
                "Irregularly spaced time-series data",
                "Multi-dimensional data",
                "Cohort analysis",
                "Large language odels"
            ]
        },
        "universities": "Hankuk University of Foreign Studies; Department of Neurology; Seoul National University College of Medicine and Seoul National University Bundang Hospital; Seoul National University",
        "countries": "South Korea",
        "locations": [
            "Seoul National University, South Korea",
            "Seoul National University, South Korea",
            "Seoul National University, South Korea",
            "Department of Neurology, Korea University Guro Hospital, South Korea",
            "Seoul National University College of Medicine and Seoul National University Bundang Hospital, South Korea",
            "Hankuk University of Foreign Studies, South Korea",
            "Seoul National University, South Korea"
        ],
        "title": "PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets"
    },
    {
        "authors": [
            "Micaela Lucia Bangerter",
            "Giuseppe Fenza",
            "Domenico Furno",
            "Mariacristina Gallo",
            "Vincenzo Loia",
            "Claudio Stanzione",
            "Ilsun You"
        ],
        "published_in": "Published in: IEEE Transactions on Fuzzy Systems ( Early Access )",
        "date_of_publication": "22 July 2024",
        "publication_month": "July",
        "publication_year": 2024,
        "doi": "10.1109/TFUZZ.2024.3431710",
        "publisher": "IEEE",
        "abstract": "The widespread utilization of social media for information consumption has significantly exacerbated the problem of information disorder. Recognizing the difficulty people face in discerning the truth, automated assistance is urgently needed. Current state-of-the-art approaches often involve fine-tuning existing models with contributions from domain knowledge bases. The black-box nature and interpretability issues of deep neural networks (DNNs) have increased interest in hybrid approaches, giving rise to Deep Neural Fuzzy Systems (DNFSs). This research paper presents the Hybrid Fact-Checking Framework (HFCF) leveraging a DNFS tailored to address the uncertainty inherent in fact verification tasks and enhance the reliability of model responses. The DNFS integrates a Large Language Model (LLM) with an Adaptive Neuro-Fuzzy Inference System (ANFIS) for automated fact verification. The framework utilizes relevant evidence from open-world and closed-world sources, leveraging deep language models and employing few-shot prompting without additional training to generate and justify verdicts. Including fuzzy rules and considering the trustworthiness and relevance of retrieved evidence enhances response reliability, thereby improving overall effectiveness and outcome interpretability. Experimental validations have been conducted on three publicly available datasets ranging in different domains of expertise: ClimateFEVER, SciFact, and FEVER. The results demonstrate that the proposed framework ensures better outcomes, transparency, and mindful decision-making.",
        "issn": {
            "Print ISSN": "1063-6706",
            "Electronic ISSN": "1941-0034"
        },
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Reliability",
                "Adaptation models",
                "Fuzzy systems",
                "Fuzzy logic",
                "Large language models",
                "Data models"
            ],
            "Author Keywords": [
                "Fact-checking",
                "Large Language Model",
                "Fuzzy Inference System",
                "Deep Neuro-Fuzzy System"
            ]
        },
        "universities": "",
        "countries": "",
        "locations": [],
        "title": "A Hybrid Framework Integrating LLM and ANFIS for Explainable Fact-Checking"
    },
    {
        "authors": [
            "Huichen Will Wang",
            "Jane Hoffswell",
            "Sao Myat Thazin Thane",
            "Victor S. Bursztyn",
            "Cindy Xiong Bearfield"
        ],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "16 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/TVCG.2024.3456378",
        "publisher": "IEEE",
        "abstract": "Large Language Models (LLMs) have been adopted for a variety of visualizations tasks, but how far are we from perceptually aware LLMs that can predict human takeaways? Graphical perception literature has shown that human chart takeaways are sensitive to visualization design choices, such as spatial layouts. In this work, we examine the extent to which LLMs exhibit such sensitivity when generating takeaways, using bar charts with varying spatial layouts as a case study. We conducted three experiments and tested four common bar chart layouts: vertically juxtaposed, horizontally juxtaposed, overlaid, and stacked. In Experiment 1, we identified the optimal configurations to generate meaningful chart takeaways by testing four LLMs, two temperature settings, nine chart specifications, and two prompting strategies. We found that even state-of-the-art LLMs struggled to generate semantically diverse and factually accurate takeaways. In Experiment 2, we used the optimal configurations to generate 30 chart takeaways each for eight visualizations across four layouts and two datasets in both zero-shot and one-shot settings. Compared to human takeaways, we found that the takeaways LLMs generated often did not match the types of comparisons made by humans. In Experiment 3, we examined the effect of chart context and data on LLM takeaways. We found that LLMs, unlike humans, exhibited variation in takeaway comparison types for different bar charts using the same bar layout. Overall, our case study evaluates the ability of LLMs to emulate human interpretations of data and points to challenges and opportunities in using LLMs to predict human chart takeaways.",
        "issn": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "keywords": {
            "IEEE Keywords": [
                "Bars",
                "Data visualization",
                "Layout",
                "Natural languages",
                "Affordances",
                "Companies",
                "Sensitivity"
            ],
            "Author Keywords": [
                "Visualization",
                "Graphical Perception",
                "Large Language Models"
            ]
        },
        "universities": "Adobe Research; Georgia Institute of Technology; University of Washington; UMass Amherst",
        "countries": "USA",
        "locations": [
            "University of Washington, USA",
            "Adobe Research, USA",
            "UMass Amherst, USA",
            "Adobe Research, USA",
            "Georgia Institute of Technology, USA"
        ],
        "title": "How Aligned are Human Chart Takeaways and LLM Predictions? A Case Study on Bar Charts with Varying Layouts"
    },
    {
        "authors": [
            "Yi Rong",
            "Yingchi Mao",
            "Xiaoming He",
            "Mingkai Chen"
        ],
        "published_in": "Published in: IEEE Internet of Things Magazine ( Early Access )",
        "date_of_publication": "04 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/IOTM.001.2400047",
        "publisher": "IEEE",
        "abstract": "Large-scale traffic flow forecasting affiliated with the time is valuable for the management in Intelligent Transportation Systems (ITS). Recently, Large Language Models (LLMs) have shown the prominence on this issue. Unfortunately, the existing LLMs cannot forecast the entire road network, including two problems, i.e., (1) training the largescale data generated by a road network on the central cloud can impose computational pressure. (2) LLMs fail to capture the spatio-temporal correlations in the road network. To overcome the challenges, we propose a novel architecture named Light-weight Spatio-temporal Generative Large Language Model on Edges (LSGLLM-E). Specifically, we first decompose the entire large-scale road network into several subparts, and deploy the Rodeside Unit (RSU) as an edge on each subpart, thus avoiding the computational pressure on the central cloud. In addition, we design an LLM-based method named Light-weight Spatio-temporal Generative Large Language Model (LSGLLM) to extract the spatio-temporal correlations, which compensates for the lack of spatio-temporal features. Finally, the experimental results illustrate that the LSGLLM-E is superior to some advanced baselines in terms of the accuracy and efficiency of the prediction.",
        "issn": {
            "Print ISSN": "2576-3180",
            "Electronic ISSN": "2576-3199"
        },
        "keywords": {
            "IEEE Keywords": [
                "Roads",
                "Cloud computing",
                "Correlation",
                "Training",
                "Predictive models",
                "Time series analysis",
                "Forecasting",
                "Edge computing",
                "Large language models",
                "Feature extraction"
            ],
            "Author Keywords": []
        },
        "universities": "",
        "countries": "",
        "locations": [],
        "title": "Large-Scale Traffic Flow Forecast with Lightweight LLM in Edge Intelligence"
    },
    {
        "authors": [
            "Ziao Liu",
            "Xiao Xie",
            "Moqi He",
            "Wenshuo Zhao",
            "Yihong Wu",
            "Liqi Cheng",
            "Hui Zhang",
            "Yingcai Wu"
        ],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "10 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/TVCG.2024.3456200",
        "publisher": "IEEE",
        "abstract": "Tactics play an important role in team sports by guiding how players interact on the field. Both sports fans and experts have a demand for analyzing sports tactics. Existing approaches allow users to visually perceive the multivariate tactical effects. However, these approaches require users to experience a complex reasoning process to connect the multiple interactions within each tactic to the final tactical effect. In this work, we collaborate with basketball experts and propose a progressive approach to help users gain a deeper understanding of how each tactic works and customize tactics on demand. Users can progressively sketch on a tactic board, and a coach agent will simulate the possible actions in each step and present the simulation to users with facet visualizations. We develop an extensible framework that integrates large language models (LLMs) and visualizations to help users communicate with the coach agent with multimodal inputs. Based on the framework, we design and develop Smartboard, an agent-based interactive visualization system for fine-grained tactical analysis, especially for play design. Smartboard provides users with a structured process of setup, simulation, and evolution, allowing for iterative exploration of tactics based on specific personalized scenarios. We conduct case studies based on real-world basketball datasets to demonstrate the effectiveness and usefulness of our system",
        "issn": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "keywords": {
            "IEEE Keywords": [
                "Sports",
                "Data visualization",
                "Videos",
                "Interviews",
                "Games",
                "Cognition",
                "Training"
            ],
            "Author Keywords": [
                "Sports visualization",
                "tactic board",
                "tactical analysis"
            ]
        },
        "universities": "Department of Sports Science; State Key Lab of CAD&CG",
        "countries": "China",
        "locations": [
            "Department of Sports Science, Zhejiang University, China",
            "Department of Sports Science, Zhejiang University, China",
            "State Key Lab of CAD&CG, Zhejiang University, China",
            "State Key Lab of CAD&CG, Zhejiang University, China",
            "State Key Lab of CAD&CG, Zhejiang University, China",
            "State Key Lab of CAD&CG, Zhejiang University, China",
            "Department of Sports Science, Zhejiang University, China",
            "State Key Lab of CAD&CG, Zhejiang University, China"
        ],
        "title": "Smartboard: Visual Exploration of Team Tactics with LLM Agent"
    },
    {
        "authors": [
            "Zhiyuan Ma",
            "Meiqi Pan",
            "Yunfeng Hou",
            "Ling Yang",
            "Wei Wang"
        ],
        "published_in": "Published in: IEEE Transactions on Computational Social Systems ( Early Access )",
        "date_of_publication": "11 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/TCSS.2024.3484460",
        "publisher": "IEEE",
        "abstract": "Aspect-based sentiment analysis (ABSA) aims to identify specific sentiment elements in social multimedia content. To address aspect extraction and sentiment prediction together, recent studies have utilized a sequence tagging approach, mainly leveraging pretrained language models (PLMs) with specific architecture and auxiliary subtasks. However, these approaches often overlook task-related knowledge and struggle to scale across different domains. With advances in large language models (LLMs), there is a rising trend in constructing generative ABSA models. Nevertheless, these techniques tend to emphasize specific frameworks and overlook comprehensive knowledge representation. To address these challenges while leveraging the advantages of LLM and PLM-based methods, we propose a hybrid knowledge integration framework (HFABGKI). It employs a parameter-efficient fine-tuning technique, allowing for plug-and-play integration with existing LLMs. To bridge the LLM and PLM-based models, HF-ABGKI incorporates a global label semantic representation for potential aspect tokens, in which a simplified gating mechanism is proposed to filter useful information. Experimental results from six public social multimedia datasets demonstrate that our approach can accurately extract aspect terms and predict their sentiment polarity, achieving state-of-the-art performance compared to existing ABSA methods.",
        "issn": {
            "Electronic ISSN": "2329-924X"
        },
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Semantics",
                "Adaptation models",
                "Training",
                "Transformers",
                "Large language models",
                "Knowledge engineering",
                "Tagging",
                "Social networking (online)",
                "Electronic mail"
            ],
            "Author Keywords": [
                "Aspect-based sentiment analysis (ABSA)",
                "gating mechanism",
                "large language model (LLM)",
                "parameter-efficient fine-tuning",
                "social multimedia"
            ]
        },
        "universities": "School of Intelligent Systems Engineering; Institute of Machine Intelligence",
        "countries": "China",
        "locations": [
            "Institute of Machine Intelligence, University of Shanghai for Science and Technology, Shanghai, China",
            "Institute of Machine Intelligence, University of Shanghai for Science and Technology, Shanghai, China",
            "Institute of Machine Intelligence, University of Shanghai for Science and Technology, Shanghai, China",
            "Institute of Machine Intelligence, University of Shanghai for Science and Technology, Shanghai, China",
            "School of Intelligent Systems Engineering, Sun Yat-sen University, Shenzhen, China"
        ],
        "title": "Toward Knowledge Integration With Large Language Model for End-to-End Aspect-Based Sentiment Analysis in Social Multimedia"
    },
    {
        "authors": [
            "Fanfan Lin",
            "Xinze Li",
            "Weihao Lei",
            "Juan J. Rodriguez-Andina",
            "Josep M. Guerrero",
            "Changyun Wen",
            "Xin Zhang",
            "Hao Ma"
        ],
        "published_in": "Published in: IEEE Transactions on Industrial Electronics ( Early Access )",
        "date_of_publication": "01 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/TIE.2024.3454408",
        "publisher": "IEEE",
        "abstract": "Large language models (LLMs) have shown exciting potential in powering the growth of many industries, yet their adoption in the power electronics (PE) sector is hindered by a lack of specialized PE technical expertise and challenges in processing PE-specific data. This study presents a pioneering approach to establish a multimodal LLM tailored for PE design applications, named PE-GPT. The methodology involves enhancing PE-GPT with retrieval augmented generation from a PE knowledge base, and proposes a hybrid framework that integrates an LLM agent with metaheuristic algorithms, Model Zoo, and Simulation Repository. This enhances its multimodal processing capabilities and enables integration into the existing design workflow. The PE-GPT methodology is demonstrated with two case studies: modulation design of the dual-active bridge (DAB) converter and circuit parameter design of the buck converter. PE-GPT demonstrates a 22.2% increase in correctness compared to human experts. Against other leading LLMs, PE-GPT shows a 35.6% improvement in correctness and a 15.4% enhancement in consistency, reducing hallucination. Hardware experiments validate PE-GPT’s multimodal capabilities in optimizing a five-degree-of-freedom modulation strategy for the DAB converter. The generalizability of PE-GPT to other PE design applications and associated AI ethical considerations are also discussed. This research concludes by outlining inspiring future research directions, encouraging researchers to expand the boundaries of the PE industry and advance toward a more intelligent era.",
        "issn": {
            "Print ISSN": "0278-0046",
            "Electronic ISSN": "1557-9948"
        },
        "keywords": {
            "IEEE Keywords": [
                "Modulation",
                "Knowledge based systems",
                "Integrated circuit modeling",
                "Vectors",
                "Metaheuristics",
                "Data models",
                "Power electronics",
                "Analytical models",
                "Adaptation models",
                "Physics"
            ],
            "Author Keywords": [
                "Large language model (LLM)",
                "multimodal AI",
                "physics-informed AI",
                "power electronics (PE) design",
                "power converter design"
            ]
        },
        "universities": "Department of Electronic Technology; College of Electrical Engineering; Catalan Institution for Research and Advanced Studies (ICREA); University of Illinois Urbana-Champaign Institute; University of Arkansas; School of Electrical and Electronic Engineering",
        "countries": "USA; Spain; Singapore; China",
        "locations": [
            "University of Illinois Urbana-Champaign Institute, Zhejiang University, Haining, China",
            "University of Arkansas, Fayetteville, AR, USA",
            "College of Electrical Engineering, Zhejiang University, Hangzhou, China",
            "Department of Electronic Technology, University of Vigo, Vigo, Spain",
            "Catalan Institution for Research and Advanced Studies (ICREA), Barcelona, Spain",
            "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
            "College of Electrical Engineering, Zhejiang University, Hangzhou, China",
            "College of Electrical Engineering, Zhejiang University, Hangzhou, China"
        ],
        "title": "PE-GPT: A New Paradigm for Power Electronics Design"
    },
    {
        "authors": [
            "Ruichen Zhang",
            "Hongyang Du",
            "Yinqiu Liu",
            "Dusit Niyato",
            "Jiawen Kang",
            "Sumei Sun",
            "Xuemin Shen",
            "H. Vincent Poor"
        ],
        "published_in": "Published in: IEEE Network ( Early Access )",
        "date_of_publication": "15 May 2024",
        "publication_month": "May",
        "publication_year": 2024,
        "doi": "10.1109/MNET.2024.3401159",
        "publisher": "IEEE",
        "abstract": "With the advance of artificial intelligence (AI), the concept of interactive AI (IAI) has been introduced, which can interactively understand and respond not only to human user input but also to dynamic system and network conditions. In this article, we explore an integration and enhancement of IAI in networking.We first comprehensively review recent developments and future perspectives of AI and then introduce the technology and components of IAI. We then explore the integration of IAI into next-generation networks, focusing on how implicit and explicit interactions can enhance network functionality, improve user experience, and promote efficient network management. Subsequently, we propose an IAI-enabled network management and optimization framework, which consists of environment, perception, action, and brain units. We also design a pluggable large language model (LLM) module and retrieval augmented generation (RAG) module to build the knowledge base and contextual memory for decision-making in the brain unit. We demonstrate through case studies that our IAI framework can effectively perform optimization problem design. Finally, we discuss potential research directions for IAI-based networks.",
        "issn": {
            "Print ISSN": "0890-8044",
            "Electronic ISSN": "1558-156X"
        },
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Data models",
                "Optimization",
                "Task analysis",
                "Heuristic algorithms",
                "Predictive models",
                "Prediction algorithms"
            ],
            "Author Keywords": [
                "IAI",
                "networking",
                "pluggable LLM module",
                "AGI",
                "RAG",
                "problem formulation"
            ]
        },
        "universities": "Department of Electrical and Computer Engineering; School of Computer Science and Engineering; School of Automation; Institute for Infocomm Research",
        "countries": "USA; Singapore; Canada; China",
        "locations": [
            "School of Computer Science and Engineering, Nanyang Technological University, Singapore",
            "School of Computer Science and Engineering, Nanyang Technological University, Singapore",
            "School of Computer Science and Engineering, Nanyang Technological University, Singapore",
            "School of Computer Science and Engineering, Nanyang Technological University, Singapore",
            "School of Automation, Guangdong University of Technology, China",
            "Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore",
            "Department of Electrical and Computer Engineering, University of Waterloo, Canada",
            "Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ, USA"
        ],
        "title": "Interactive AI with Retrieval-Augmented Generation for Next Generation Networking"
    },
    {
        "authors": [
            "Ruichen Zhang",
            "Hongyang Du",
            "Yinqiu Liu",
            "Dusit Niyato",
            "Jiawen Kang",
            "Zehui Xiong",
            "Abbas Jamalipour",
            "Dong In Kim"
        ],
        "published_in": "Published in: IEEE Journal on Selected Areas in Communications ( Early Access )",
        "date_of_publication": "12 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/JSAC.2024.3459037",
        "publisher": "IEEE",
        "abstract": "In response to the needs of 6G global communications, satellite communication networks have emerged as a key solution. However, the large-scale development of satellite communication networks is constrained by complex system models, whose modeling is challenging for massive users. Moreover, transmission interference between satellites and users seriously affects communication performance. To solve these problems, this paper develops generative artificial intelligence (AI) agents for model formulation and then applies a mixture of experts (MoE) approach to design transmission strategies. Specifically, we leverage large language models (LLMs) to build an interactive modeling paradigm and utilize retrieval-augmented generation (RAG) to extract satellite expert knowledge that supports mathematical modeling. Afterward, by integrating the expertise of multiple specialized components, we propose an MoE-proximal policy optimization (PPO) approach to solve the formulated problem. Each expert can optimize the optimization variables at which it excels through specialized training through its own network and then aggregate them through the gating network to perform joint optimization. The simulation results validate the accuracy and effectiveness of employing a generative agent for problem formulation. Furthermore, the superiority of the proposed MoE-ppo approach over other benchmarks is confirmed in solving the formulated problem. The adaptability of MoE-PPO to various customized modeling problems has also been demonstrated.",
        "issn": {
            "Print ISSN": "0733-8716",
            "Electronic ISSN": "1558-0008"
        },
        "keywords": {
            "IEEE Keywords": [
                "Generative AI",
                "Satellites",
                "Optimization",
                "Low earth orbit satellites",
                "Adaptation models",
                "Mathematical models",
                "Resource management"
            ],
            "Author Keywords": [
                "Satellite communications",
                "generative AI agent",
                "MoE",
                "LLM",
                "PPO",
                "network design"
            ]
        },
        "universities": "College of Computing and Data Science; Pillar of Information Systems Technology and Design; Department of Electrical and Computer Engineering; School of Automation; The University of Sydney; Department of Electrical and Electronic Engineering",
        "countries": "South Korea; Australia; Singapore; China",
        "locations": [
            "College of Computing and Data Science, Nanyang Technological University, Singapore",
            "Department of Electrical and Electronic Engineering, University of Hong Kong, Pok Fu Lam, Hong Kong, China",
            "College of Computing and Data Science, Nanyang Technological University, Singapore",
            "College of Computing and Data Science, Nanyang Technological University, Singapore",
            "School of Automation, Guangdong University of Technology, China",
            "Pillar of Information Systems Technology and Design, Singapore University of Technology and Design, Singapore",
            "The University of Sydney, Sydney, NSW, Australia",
            "Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, South Korea"
        ],
        "title": "Generative AI Agents with Large Language Model for Satellite Networks via a Mixture of Experts Transmission"
    },
    {
        "authors": [
            "Ning Bian",
            "Hongyu Lin",
            "Peilin Liu",
            "Yaojie Lu",
            "Chunkang Zhang",
            "Ben He",
            "Xianpei Han",
            "Le Sun"
        ],
        "published_in": "Published in: IEEE Transactions on Computational Social Systems ( Early Access )",
        "date_of_publication": "06 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/TCSS.2024.3476030",
        "publisher": "IEEE",
        "abstract": "Social cognitive theory explains how people learn and acquire knowledge through observing others. Recent years have witnessed the rapid development of large language models (LLMs), which suggests their potential significance as agents in the society. LLMs, as AI agents, can observe external information, which shapes their cognition and behaviors. However, the extent to which external information influences LLMs’ cognition and behaviors remains unclear. This study investigates how external statements and opinions influence LLMs’ thoughts and behaviors from a social cognitive perspective. Three experiments were conducted to explore the effects of external information on LLMs’ memories, opinions, and social media behavioral decisions. Sociocognitive factors, including source authority, social identity, and social role, were analyzed to investigate their moderating effects. Results showed that external information can significantly shape LLMs’ memories, opinions, and behaviors, with these changes mirroring human social cognitive patterns such as authority bias, in-group bias, emotional positivity, and emotion contagion. This underscores the challenges in developing safe and unbiased LLMs, and emphasizes the importance of understanding the susceptibility of LLMs to external influences.",
        "issn": {
            "Electronic ISSN": "2329-924X"
        },
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Cognition",
                "Shape",
                "Chatbots",
                "Blogs",
                "Psychology",
                "Large language models",
                "Sun",
                "Software",
                "Mirrors"
            ],
            "Author Keywords": [
                "Cognitive bias",
                "large language model (LLM)",
                "social cognitive theory"
            ]
        },
        "universities": "Chinese Information Processing Laboratory; School of Computer Science and Technology",
        "countries": "China",
        "locations": [
            "School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China",
            "Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China",
            "School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China",
            "Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China",
            "School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China",
            "School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China",
            "Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China",
            "Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China"
        ],
        "title": "Influence of External Information on Large Language Models Mirrors Social Cognitive Patterns"
    },
    {
        "authors": [
            "Jihong Park",
            "Seung-Woo Ko",
            "Jinho Choi",
            "Seong-Lyun Kim",
            "Junil Choi",
            "Mehdi Bennis"
        ],
        "published_in": "Published in: IEEE BITS the Information Theory Magazine ( Early Access )",
        "date_of_publication": "05 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/MBITS.2024.3491949",
        "publisher": "IEEE",
        "abstract": "The forthcoming 6G systems are expected to address a wide range of non-stationary tasks. This poses challenges to traditional medium access control (MAC) protocols that are static and predefined. In response, data-driven MAC protocols have recently emerged, offering ability to tailor their signaling messages for specific tasks. This article presents a novel categorization of these data-driven MAC protocols into three levels: Level 1 MAC. task-oriented neural protocols constructed using multi-agent deep reinforcement learning (MADRL); Level 2 MAC. neural network-oriented symbolic protocols developed by converting Level 1 MAC outputs into explicit symbols; and Level 3 MAC. language-oriented semantic protocols harnessing large language models (LLMs) and generative models. With this categorization, we aim to explore the opportunities and challenges of each level by delving into their foundational techniques. Drawing from information theory and associated principles as well as selected case studies, this study provides insights into the trajectory of data-driven MAC protocols and sheds light on future research directions.",
        "issn": {
            "Electronic ISSN": "2692-4110",
            "Print ISSN": "2692-4080"
        },
        "keywords": {
            "IEEE Keywords": [
                "Media Access Control",
                "Protocols",
                "Artificial neural networks",
                "Training",
                "Semantics",
                "6G mobile communication",
                "Electronic mail",
                "Entropy",
                "Transforms",
                "Large language models"
            ],
            "Author Keywords": [
                "Semantic protocol",
                "protocol learning",
                "multi-agent deep reinforcement learning (MADRL)",
                "large language model (LLM)",
                "6G"
            ]
        },
        "universities": "Information Systems Technology and Design Pillar; School of Electrical Engineering; Department of Smart Mobility Engineering; School of Electrical and Mechanical Engineering; Centre for Wireless Communications; School of Electrical and Electronic Engineering",
        "countries": "Korea; Australia; Singapore; Finland",
        "locations": [
            "Information Systems Technology and Design Pillar, Singapore University of Technology and Design, Singapore",
            "Department of Smart Mobility Engineering, Inha University, Incheon, Korea",
            "School of Electrical and Mechanical Engineering, University of Adelaide, North Terrace, Adelaide, SA, Australia",
            "School of Electrical and Electronic Engineering, Yonsei University, Seoul, Korea",
            "School of Electrical Engineering, KAIST, Daejeon, Korea",
            "Centre for Wireless Communications, University of Oulu, Oulu, Finland"
        ],
        "title": "Towards Semantic MAC Protocols for 6G: From Protocol Learning to Language-Oriented Approaches"
    },
    {
        "authors": [
            "Chong Bian",
            "Xue Han",
            "Zhiyu Duan",
            "Chao Deng",
            "Shunkun Yang",
            "Junlan Feng"
        ],
        "published_in": "Published in: IEEE Transactions on Transportation Electrification ( Early Access )",
        "date_of_publication": "22 April 2024",
        "publication_month": "April",
        "publication_year": 2024,
        "doi": "10.1109/TTE.2024.3391938",
        "publisher": "IEEE",
        "abstract": "State-of-charge (SOC) estimation is critical for reliable operation of Li-ion batteries (LIBs). However, the distinct electrochemical characteristics coupled with harsh low-temperature environments make a single estimator struggle to robustly estimate the volatile SOC of multi-type LIBs. To address these issues, this article proposes a hard-soft hybrid prompt learning method to unleash the potential of a pretrained large language model (LLM) for SOC estimation. A textual encoder is introduced to convert LIB measurements into hard text prompts for language modeling, naturally eliciting the pretrained LLM to capture the intra-relations of measured values over time and their inter-relations with contextual semantics for accurate estimates. A side adapter network is constructed to reparameterize model adaptation towards different LIB tasks into optimizations within a low-dimensional subspace, strengthening the estimation generalization of the pretrained LLM in a parameter-efficient manner. A knowledge infusion mechanism is designed to encapsulate task-specific information as soft prompt vectors for model integration along forward propagation, dynamically conditioning the hidden states inside the pretrained LLM to enhance the estimation robustness against SOC volatilities. Extensive experiments verify that the hybrid prompt-driven LLM can simultaneously perform estimations for multi-type LIBs under diverse operations and sub-zero temperatures with superior accuracy, generalization, and robustness.",
        "issn": {
            "Electronic ISSN": "2332-7782"
        },
        "keywords": {
            "IEEE Keywords": [
                "Estimation",
                "Task analysis",
                "State of charge",
                "Temperature measurement",
                "Vectors",
                "Robustness",
                "Transformers"
            ],
            "Author Keywords": [
                "Hybrid prompt learning",
                "large language model",
                "multi-type Li-ion batteries",
                "state-of-charge estimation"
            ]
        },
        "universities": "Artificial Intelligence and Intelligent Operation Center; School of Reliability and Systems Engineering",
        "countries": "China",
        "locations": [
            "Artificial Intelligence and Intelligent Operation Center, China Mobile Research Institute, Beijing, China",
            "Artificial Intelligence and Intelligent Operation Center, China Mobile Research Institute, Beijing, China",
            "School of Reliability and Systems Engineering, Beihang University, Beijing, China",
            "Artificial Intelligence and Intelligent Operation Center, China Mobile Research Institute, Beijing, China",
            "School of Reliability and Systems Engineering, Beihang University, Beijing, China",
            "Artificial Intelligence and Intelligent Operation Center, China Mobile Research Institute, Beijing, China"
        ],
        "title": "Hybrid Prompt-Driven Large Language Model for Robust State-of-Charge Estimation of Multi-Type Li-ion Batteries"
    },
    {
        "authors": [
            "Minrui Xu",
            "Dusit Niyato",
            "Jiawen Kang",
            "Zehui Xiong",
            "Shiwen Mao",
            "Zhu Han",
            "Dong In Kim",
            "Khaled B. Letaief"
        ],
        "published_in": "Published in: IEEE Wireless Communications ( Early Access )",
        "date_of_publication": "26 August 2024",
        "publication_month": "August",
        "publication_year": 2024,
        "doi": "10.1109/MWC.005.2400019",
        "publisher": "IEEE",
        "abstract": "AI agents based on multimodal large language models (LLMs) are expected to revolutionize human-computer interaction, and offer more personalized assistant services across various domains like healthcare, education, manufacturing, and entertainment. Deploying LLM agents in 6G networks enables users to access previously expensive AI assistant services via mobile devices democratically, thereby reducing interaction latency and better preserving user privacy. Nevertheless, the limited capacity of mobile devices constrains the effectiveness of deploying and executing local LLMs, which necessitates offloading complex tasks to global LLMs running on edge servers during long-horizon interactions. In this article, we propose a split learning system for LLM agents in 6G networks, leveraging the collaboration between mobile devices and edge servers, where multiple LLMs with different roles are distributed across mobile devices and edge servers to perform user-agent interactive tasks collaboratively. In the proposed system, LLM agents are split into perception, grounding, and alignment modules, facilitating inter-module communications to meet extended user requirements on 6G network functions, including integrated sensing and communication, digital twins, and task-oriented communications. Furthermore, we introduce a novel model caching algorithm for LLMs within the proposed system to improve model utilization in context, thus reducing network costs of the collaborative mobile and edge LLM agents.",
        "issn": {
            "Print ISSN": "1536-1284",
            "Electronic ISSN": "1558-0687"
        },
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Task analysis",
                "6G mobile communication",
                "Servers",
                "Mobile handsets",
                "Planning",
                "Grounding"
            ],
            "Author Keywords": []
        },
        "universities": "",
        "countries": "",
        "locations": [],
        "title": "When Large Language Model Agents Meet 6G Networks: Perception, Grounding, and Alignment"
    },
    {
        "authors": [
            "Jiahui Hu",
            "Dan Wang",
            "Zhibo Wang",
            "Xiaoyi Pang",
            "Huiyu Xu",
            "Ju Ren",
            "Kui Ren"
        ],
        "published_in": "Published in: IEEE Wireless Communications ( Early Access )",
        "date_of_publication": "23 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/MWC.009.2400244",
        "publisher": "IEEE",
        "abstract": "Large language models (LLMs) have become increasingly popular due to their exceptional performance in various artificial intelligence applications. However, their development often suffers from the scarcity of high-quality data and the extensive requirements for computing resources. These obstacles are even more severe for enterprises in vertical industries, which have limited computer resources but urgently require large-scale models for specific activities. To address these issues, LLMs call for the integration of federated learning (FL), which enables the collaborative learning of a powerful LLM using private data and computing resources from multiple entities. In this article, we present a systematic introduction to the federated large language model (Fed-LLM), a distributed learning of LLM in the FL manner. We first introduce the learning paradigm of Fed-LLM, which is called federated parameter-efficient fine-tuning (Fed-PEFT). Fed-PEFT empowers the collaborative fine-tuning of pre-trained LLMs by only involving a small subset of parameters in local LLMs. Specifically, we detail the workflow of Fed-PEFT, and summarize the state-of-the-art solutions in this area. Additionally, we discuss the challenges faced in Fed-LLMs, including efficiency, privacy, and security. Finally, we introduce future directions to facilitate the research of Fed-LLMs and guide coming explorations in this nascent field.",
        "issn": {
            "Print ISSN": "1536-1284",
            "Electronic ISSN": "1558-0687"
        },
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "LoRa",
                "Servers",
                "Computational modeling",
                "Data models",
                "Tuning",
                "Transformers",
                "Adaptation models",
                "Large language models",
                "Privacy"
            ],
            "Author Keywords": []
        },
        "universities": "",
        "countries": "",
        "locations": [],
        "title": "Federated Large Language Model: Solutions, Challenges and Future Directions"
    },
    {
        "authors": [
            "Faqian Guan",
            "Tianqing Zhu",
            "Hui Sun",
            "Wanlei Zhou",
            "Philip S. Yu"
        ],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "07 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/TBDATA.2024.3489427",
        "publisher": "IEEE",
        "abstract": "Graph data contains rich node features and unique edge information, which have been applied across various domains, such as citation networks or recommendation systems. Graph Neural Networks (GNNs) are specialized for handling such data and have shown impressive performance in many applications. However, GNNs may contain of sensitive information and susceptible to privacy attacks. For example, link stealing is a type of attack in which attackers infer whether two nodes are linked or not. Previous link stealing attacks primarily relied on posterior probabilities from the target GNN model, neglecting the significance of node features. Additionally, variations in node classes across different datasets lead to different dimensions of posterior probabilities. The handling of these varying data dimensions posed a challenge in using a single model to effectively conduct link stealing attacks on different datasets. To address these challenges, we introduce Large Language Models (LLMs) to perform link stealing attacks on GNNs. LLMs can effectively integrate textual features and exhibit strong generalizability, enabling attacks to handle diverse data dimensions across various datasets. We design two distinct LLM prompts to effectively combine textual features and posterior probabilities of graph nodes. Through these designed prompts, we fine-tune the LLM to adapt to the link stealing attack task. Furthermore, we fine-tune the LLM using multiple datasets and enable the LLM to learn features from different datasets simultaneously. Experimental results show that our approach significantly enhances the performance of existing link stealing attack tasks in both white-box and black-box scenarios. Our method can execute link stealing attacks across different datasets using only a single model, making link stealing attacks more applicable to real-world scenarios.",
        "issn": {
            "Electronic ISSN": "2332-7790"
        },
        "keywords": {
            "IEEE Keywords": [
                "Posterior probability",
                "Graph neural networks",
                "Privacy",
                "Data models",
                "Large language models",
                "Adaptation models",
                "Vectors",
                "Semantics",
                "Feature extraction",
                "Data privacy"
            ],
            "Author Keywords": [
                "Link Stealing Attacks",
                "Large Language Models",
                "Graph Neural Networks",
                "Privacy Attacks"
            ]
        },
        "universities": "City University of Macau; China University of Geosciences; University of Illinois Chicago",
        "countries": "USA; China",
        "locations": [
            "China University of Geosciences, Wuhan, China",
            "City University of Macau, Macau, China",
            "City University of Macau, Macau, China",
            "City University of Macau, Macau, China",
            "University of Illinois Chicago, Chicago, IL, USA"
        ],
        "title": "Large Language Models for Link Stealing Attacks Against Graph Neural Networks"
    },
    {
        "authors": [
            "Kemou Jiang",
            "Xuan Cai",
            "Zhiyong Cui",
            "Aoyong Li",
            "Yilong Ren",
            "Haiyang Yu",
            "Hao Yang",
            "Daocheng Fu",
            "Licheng Wen",
            "Pinlong Cai"
        ],
        "published_in": "Published in: IEEE Transactions on Intelligent Vehicles ( Early Access )",
        "date_of_publication": "06 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/TIV.2024.3488793",
        "publisher": "IEEE",
        "abstract": "Large language models (LLMs) as autonomous agents offer a novel avenue for tackling real-world challenges through a knowledge-driven manner. These LLM-enhanced methodologies excel in generalization and interpretability. However, the complexity of driving tasks often necessitates the collaboration of multiple, heterogeneous agents, underscoring the need for such LLM-driven agents to engage in cooperative knowledge sharing and cognitive synergy. Despite the promise of LLMs, current applications predominantly center around single-agent scenarios, which limits their scope in the face of intricate, interconnected tasks. To broaden the horizons of knowledge-driven strategies and bolster the generalization capabilities of autonomous agents, we propose the \\mathsf {KoMA}\nframework consisting of the multi-agent interaction, the multi-step planning, the shared-memory, and the ranking-based reflection modules to enhance multi-agents' decision-making in complex driving scenarios. Based on the framework's generated text descriptions of driving scenarios, the multi-agent interaction module enables LLM agents to analyze and infer the intentions of surrounding vehicles based on scene information, akin to human cognition. The multi-step planning module enables LLM agents to analyze and obtain final action decisions layer by layer to ensure consistent goals for short-term action decisions. The shared memory module can accumulate collective experience to make superior decisions, and the ranking-based reflection module can evaluate and improve agent behavior with the aim of enhancing driving safety and efficiency. The \\mathsf {KoMA}\nframework not only enhances the robustness and adaptability of autonomous driving agents but also significantly elevates their generalization capabilities across diverse scenarios. Empirical results demonstrate the superiority of our approach over traditional methods, particularly in its ability to handle complex, unpredictable driving environments ...",
        "issn": {
            "Electronic ISSN": "2379-8904",
            "Print ISSN": "2379-8858"
        },
        "keywords": {
            "IEEE Keywords": [
                "Cognition",
                "Autonomous vehicles",
                "Reflection",
                "Safety",
                "Memory modules",
                "Complexity theory",
                "Planning",
                "Collaboration",
                "Vehicle dynamics",
                "Training"
            ],
            "Author Keywords": [
                "Autonomous driving",
                "large language models",
                "multi agents",
                "shared memory",
                "multi-step planning",
                "chain of thought"
            ]
        },
        "universities": "School of Transportation Science and Engineering; Department of Civil and Systems Engineering; Shanghai Artificial Intelligence Laboratory",
        "countries": "P.R. China; USA",
        "locations": [
            "School of Transportation Science and Engineering, Beihang University, Beijing, P.R. China",
            "School of Transportation Science and Engineering, Beihang University, Beijing, P.R. China",
            "School of Transportation Science and Engineering, Beihang University, Beijing, P.R. China",
            "School of Transportation Science and Engineering, Beihang University, Beijing, P.R. China",
            "School of Transportation Science and Engineering, Beihang University, Beijing, P.R. China",
            "School of Transportation Science and Engineering, Beihang University, Beijing, P.R. China",
            "Department of Civil and Systems Engineering, Johns Hopkins University, Baltimore, MD, USA",
            "Shanghai Artificial Intelligence Laboratory, Shanghai, P.R. China",
            "Shanghai Artificial Intelligence Laboratory, Shanghai, P.R. China",
            "Shanghai Artificial Intelligence Laboratory, Shanghai, P.R. China"
        ],
        "title": "KoMA: Knowledge-Driven Multi-Agent Framework for Autonomous Driving With Large Language Models"
    },
    {
        "authors": [
            "Kiroong Choe",
            "Chaerin Lee",
            "Soohyun Lee",
            "Jiwon Song",
            "Aeri Cho",
            "Nam Wook Kim",
            "Jinwook Seo"
        ],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "12 June 2024",
        "publication_month": "June",
        "publication_year": 2024,
        "doi": "10.1109/TVCG.2024.3413195",
        "publisher": "IEEE",
        "abstract": "With the growing complexity and volume of data, visualizations have become more intricate, often requiring advanced techniques to convey insights. These complex charts are prevalent in everyday life, and individuals who lack knowledge in data visualization may find them challenging to understand. This paper investigates using Large Language Models (LLMs) to help users with low data literacy understand complex visualizations. While previous studies focus on text interactions with users, we noticed that visual cues are also critical for interpreting charts. We introduce an LLM application that supports both text and visual interaction for guiding chart interpretation. Our study with 26 participants revealed that the in-situ support effectively assisted users in interpreting charts and enhanced learning by addressing specific chart-related questions and encouraging further exploration. Visual communication allowed participants to convey their interests straightforwardly, eliminating the need for textual descriptions. However, the LLM assistance led users to engage less with the system, resulting in fewer insights from the visualizations. This suggests that users, particularly those with lower data literacy and motivation, may have over-relied on the LLM agent. We discuss opportunities for deploying LLMs to enhance visualization literacy while emphasizing the need for a balanced approach.",
        "issn": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Visualization",
                "Task analysis",
                "Education",
                "Artificial intelligence",
                "Annotations",
                "Visual communication"
            ],
            "Author Keywords": [
                "Visualization literacy",
                "large language model",
                "visual communication"
            ]
        },
        "universities": "Boston College; Seoul National University",
        "countries": "U.S.A; South Korea",
        "locations": [
            "Seoul National University, South Korea",
            "Seoul National University, South Korea",
            "Seoul National University, South Korea",
            "Seoul National University, South Korea",
            "Seoul National University, South Korea",
            "Boston College, U.S.A",
            "Seoul National University, South Korea"
        ],
        "title": "Enhancing Data Literacy On-demand: LLMs as Guides for Novices in Chart Interpretation"
    },
    {
        "authors": [
            "Dazhen Deng",
            "Chuhan Zhang",
            "Huawei Zheng",
            "Yuwen Pu",
            "Shouling Ji",
            "Yingcai Wu"
        ],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "16 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/TVCG.2024.3456150",
        "publisher": "IEEE",
        "abstract": "Large Language Models (LLMs) are powerful but also raise significant security concerns, particularly regarding the harm they can cause, such as generating fake news that manipulates public opinion on social media and providing responses to unethical activities. Traditional red teaming approaches for identifying AI vulnerabilities rely on manual prompt construction and expertise. This paper introduces AdversaFlow, a novel visual analytics system designed to enhance LLM security against adversarial attacks through human-AI collaboration. AdversaFlow involves adversarial training between a target model and a red model, featuring unique multi-level adversarial flow and fluctuation path visualizations. These features provide insights into adversarial dynamics and LLM robustness, enabling experts to identify and mitigate vulnerabilities effectively. We present quantitative evaluations and case studies validating our system's utility and offering insights for future AI security solutions. Our method can enhance LLM security, supporting downstream scenarios like social media regulation by enabling more effective detection, monitoring, and mitigation of harmful content and behaviors.",
        "issn": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "keywords": {
            "IEEE Keywords": [
                "Security",
                "Analytical models",
                "Training",
                "Visual analytics",
                "Artificial intelligence",
                "Toxicology",
                "Safety"
            ],
            "Author Keywords": [
                "Visual Analytics for Machine Learning",
                "Artificial Intelligence Security",
                "Large Language Models",
                "Text Visualization"
            ]
        },
        "universities": "Zhejiang University",
        "countries": "China",
        "locations": [
            "Zhejiang University, China",
            "Zhejiang University, China",
            "Zhejiang University, China",
            "Zhejiang University, China",
            "Zhejiang University, China",
            "Zhejiang University, China"
        ],
        "title": "AdversaFlow: Visual Red Teaming for Large Language Models with Multi-Level Adversarial Flow"
    },
    {
        "authors": [
            "Mengyao Wu",
            "F. Richard Yu",
            "Peter Xiaoping Liu",
            "Ying He"
        ],
        "published_in": "Published in: IEEE Intelligent Systems ( Early Access )",
        "date_of_publication": "24 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/MIS.2024.3466518",
        "publisher": "IEEE",
        "abstract": "We explore how Large Language Models (LLMs) can expedite and automate the learning process for autonomous driving tasks. This involves harnessing LLM knowledge to shape a learning framework and utilizing LLMs to guide the learning process. We conduct a case study to demonstrate LLMs’ ability to export driving rules. LLM outputs may not be entirely reliable for direct handling of driving decisions due to potential inaccuracies and inconsistencies. To address these issues, we propose integrating LLM knowledge with statistical learning. This enables LLMs to export task-specific knowledge as symbolic rules, forming the initial learning structure. Rule weights are calculated based on statistical salience derived from training data, resulting in a set of weighted rules for robust decision-making. Furthermore, this set of weighted rules preserves strong semantics, allowing LLMs to comprehend and make modifications based on varying needs. Simulations using a highway driving simulator validate the effectiveness of our approach.",
        "issn": {
            "Print ISSN": "1541-1672",
            "Electronic ISSN": "1941-1294"
        },
        "keywords": {
            "IEEE Keywords": [
                "Safety",
                "Decision making",
                "Autonomous vehicles",
                "Reinforcement learning",
                "Statistical learning",
                "Intelligent systems",
                "Chatbots"
            ],
            "Author Keywords": []
        },
        "universities": "Department of Systems and Computer Engineering; College of Computer Science and Software Engineering",
        "countries": "Canada; China",
        "locations": [
            "Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada",
            "Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada",
            "Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada",
            "College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China"
        ],
        "title": "Facilitating Autonomous Driving Tasks with Large Language Models"
    },
    {
        "authors": [
            "Adrian de Wynter"
        ],
        "published_in": "Published in: IEEE Transactions on Games ( Early Access )",
        "date_of_publication": "13 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/TG.2024.3497601",
        "publisher": "IEEE",
        "abstract": "We show that GPT-4's reasoning and planning capabilities extend to the 1993 first-person shooter Doom. This large language model (LLM) is able to run and play the game with only a few instructions, plus a textual description–generated by the model itself from screenshots–about the state of the game being observed. We find that GPT-4 can play the game to a passable degree: it is able to manipulate doors, combat enemies, and perform pathing. More complex prompting strategies involving multiple model calls provide better results. While further work is required to enable the LLM to play the game as well as its classical, reinforcement learning-based counterparts, we note that GPT-4 required no training, leaning instead on its own reasoning and observational capabilities. We hope our work pushes the boundaries on intelligent, LLM-based agents in video games. We conclude by discussing the ethical implications of our work.",
        "issn": {
            "Print ISSN": "2475-1502",
            "Electronic ISSN": "2475-1510"
        },
        "keywords": {
            "IEEE Keywords": [],
            "Author Keywords": [
                "GPT-4",
                "planning",
                "reasoning",
                "Doom",
                "FPS"
            ]
        },
        "universities": "The University of York and Microsoft",
        "countries": "U.k.",
        "locations": [
            "The University of York and Microsoft, U.k."
        ],
        "title": "Will GPT-4 Run DOOM?"
    },
    {
        "authors": [
            "Sifan Long",
            "Fengxiao Tang",
            "Yangfan Li",
            "Tiao Tan",
            "Zhengjie Jin",
            "Ming Zhao",
            "Nei Kato"
        ],
        "published_in": "Published in: IEEE Network ( Early Access )",
        "date_of_publication": "30 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/MNET.2024.3470774",
        "publisher": "IEEE",
        "abstract": "The sixth generation mobile communication standard (6G) can promote the development of Industrial Internet and Internet of Things (IoT). To achieve comprehensive intelligent development of the network and provide customers with higher quality personalized services. This paper proposes a network performance optimization and intelligent operation network architecture based on Large Language Model (LLM), aiming to build a comprehensive intelligent 6G network system. The Large Language Model, with more parameters and stronger learning ability, can more accurately capture patterns and features in data, which can achieve more accurate content output and high intelligence and provide strong support for related research such as network data security, privacy protection, and health assessment. This paper also presents the design framework of a network health assessment system based on LLM and focuses on its potential application scenarios, through the case of network health management system, it is fully demonstrated that the 6G intelligent network system based on LLM has important practical significance for the comprehensive realization of intelligence.",
        "issn": {
            "Print ISSN": "0890-8044",
            "Electronic ISSN": "1558-156X"
        },
        "keywords": {
            "IEEE Keywords": [
                "Large language models",
                "6G mobile communication",
                "Optimization",
                "Monitoring",
                "Data models",
                "Transformers",
                "Fault diagnosis",
                "Training",
                "Protection",
                "Long short term memory"
            ],
            "Author Keywords": [
                "6G",
                "Large Language Model",
                "Network health assessment",
                "Network performance optimization"
            ]
        },
        "universities": "Tohoku University; Central South University",
        "countries": "Japan; China",
        "locations": [
            "Central South University, China",
            "Central South University, China",
            "Central South University, China",
            "Central South University, China",
            "Central South University, China",
            "Central South University, China",
            "Tohoku University, Japan"
        ],
        "title": "6G comprehensive intelligence: network operations and optimization based on Large Language Models"
    },
    {
        "authors": [
            "Feibo Jiang",
            "Li Dong",
            "Yubo Peng",
            "Kezhi Wang",
            "Kun Yang",
            "Cunhua Pan",
            "Xiaohu You"
        ],
        "published_in": "Published in: IEEE Communications Magazine ( Early Access )",
        "date_of_publication": "09 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/MCOM.001.2300575",
        "publisher": "IEEE",
        "abstract": "Multimodal signals, including text, audio, image, and video, can be integrated into semantic communication (SC) systems to provide an immersive experience with low latency and high quality at the semantic level. However, the multimodal SC has several challenges, including data heterogeneity, semantic ambiguity, and signal distortion during transmission. Recent advancements in large AI models, particularly in the multimodal language model (MLM) and large language model (LLM), offer potential solutions for addressing these issues. To this end, we propose a large AI model-based multimodal SC (LAM-MSC) framework, where we first present the MLMbased multimodal alignment (MMA) that utilizes the MLM to enable the transformation between multimodal and unimodal data while preserving semantic consistency. Then, a personalized LLM-based knowledge base (LKB) is proposed, which allows users to perform personalized semantic extraction or recovery through the LLM. This effectively addresses the semantic ambiguity. Finally, we apply the conditional generative adversarial networks-based channel estimation (CGE) for estimating the wireless channel state information. This approach effectively mitigates the impact of fading channels in SC. Finally, we conduct simulations that demonstrate the superior performance of the LAM-MSC framework.",
        "issn": {
            "Print ISSN": "0163-6804",
            "Electronic ISSN": "1558-1896"
        },
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Data models",
                "Channel estimation",
                "Artificial intelligence",
                "Receivers",
                "Adaptation models",
                "Accuracy"
            ],
            "Author Keywords": []
        },
        "universities": "",
        "countries": "",
        "locations": [],
        "title": "Large AI Model Empowered Multimodal Semantic Communications"
    },
    {
        "authors": [
            "Seungjae Moon",
            "Jung-Hoon Kim",
            "Junsoo Kim",
            "Seongmin Hong",
            "Junseo Cha",
            "Minsu Kim",
            "Sukbin Lim",
            "Gyubin Choi",
            "Dongjin Seo",
            "Jongho Kim",
            "Hunjong Lee",
            "Hyunjun Park",
            "Ryeowook Ko",
            "Soongyu Choi",
            "Jongse Park",
            "Jinwon Lee",
            "Joo-Young Kim"
        ],
        "published_in": "Published in: IEEE Micro ( Early Access )",
        "date_of_publication": "09 July 2024",
        "publication_month": "July",
        "publication_year": 2024,
        "doi": "10.1109/MM.2024.3420728",
        "publisher": "IEEE",
        "abstract": "The explosive arrival of OpenAI’s ChatGPT has fueled the globalization of large language model (LLM), which consists of billions of pretrained parameters that embodies the aspects of syntax and semantics. HyperAccel introduces latency processing unit (LPU), a latency-optimized and highly scalable processor architecture for the acceleration of LLM inference. LPU perfectly balances the memory bandwidth and compute logic with streamlined dataflow to maximize performance and efficiency. LPU is equipped with expandable synchronization link (ESL) that hides data synchronization latency between multiple LPUs. HyperDex complements LPU as an intuitive software framework to run LLM applications. LPU achieves 1.25 ms/token and 20.9 ms/token for 1.3B and 66B model, respectively, which is 2.09× and 1.37× faster than the GPU. LPU, synthesized using Samsung 4nm process, has total area of 0.824 mm 2 and power consumption of 284.31 mW. LPU-based servers achieve 1.33× and 1.32× energy efficiency over NVIDIA H100 and L4 servers, respectively.",
        "issn": {
            "Print ISSN": "0272-1732",
            "Electronic ISSN": "1937-4143"
        },
        "keywords": {
            "IEEE Keywords": [
                "Bandwidth",
                "Hardware",
                "Decoding",
                "Memory management",
                "Graphics processing units",
                "Software",
                "Large language models"
            ],
            "Author Keywords": []
        },
        "universities": "HyperAccel; Korea Advanced Institute of Science Technology",
        "countries": "South Korea",
        "locations": [
            "HyperAccel, Seoul, South Korea",
            "Korea Advanced Institute of Science Technology, Daejeon, South Korea",
            "HyperAccel, Seoul, South Korea",
            "HyperAccel, Seoul, South Korea",
            "HyperAccel, Seoul, South Korea",
            "Korea Advanced Institute of Science Technology, Daejeon, South Korea",
            "HyperAccel, Seoul, South Korea",
            "HyperAccel, Seoul, South Korea",
            "HyperAccel, Seoul, South Korea",
            "HyperAccel, Seoul, South Korea",
            "HyperAccel, Seoul, South Korea",
            "HyperAccel, Seoul, South Korea",
            "HyperAccel, Seoul, South Korea",
            "HyperAccel, Seoul, South Korea",
            "Korea Advanced Institute of Science Technology, Daejeon, South Korea",
            "HyperAccel, Seoul, South Korea",
            "HyperAccel, Seoul, South Korea"
        ],
        "title": "LPU: A Latency-Optimized and Highly Scalable Processor for Large Language Model Inference"
    },
    {
        "authors": [
            "Jiahui Xiang",
            "Lirong Fu",
            "Tong Ye",
            "Peiyu Liu",
            "Huan Le",
            "Liming Zhu",
            "Wenhai Wang"
        ],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "04 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/JIOT.2024.3490661",
        "publisher": "IEEE",
        "abstract": "The diversity of web configuration interfaces for IoT devices has exacerbated issues such as inadequate permission controls and insecure interfaces, resulting in various vulnerabilities. Owing to the varying interface configurations across various devices, the existing methods are inadequate for identifying these vulnerabilities precisely and comprehensively. This study addresses these issues by introducing an automated vulnerability detection system, called LuaTaint. It is designed for the commonly used web configuration interface of IoT devices. LuaTaint combines static taint analysis with a large language model (LLM) to achieve widespread and high-precision detection. The extensive traversal of the static analysis ensures the comprehensiveness of the detection. The system also incorporates rules related to page handler control logic within the taint detection process to enhance its precision and extensibility. Moreover, we leverage the prodigious abilities of LLM for code analysis tasks. By utilizing LLM in the process of pruning false alarms, the precision of LuaTaint is enhanced while significantly reducing its dependence on manual analysis. We develop a prototype of LuaTaint and evaluate it using 2,447 IoT firmware samples from 11 renowned vendors. LuaTaint has discovered 111 vulnerabilities. Moreover, LuaTaint exhibits a vulnerability detection precision rate of up to 89.29%.",
        "issn": {
            "Electronic ISSN": "2327-4662"
        },
        "keywords": {
            "IEEE Keywords": [
                "Internet of Things",
                "Microprogramming",
                "Static analysis",
                "Security",
                "Codes",
                "Uniform resource locators",
                "Performance evaluation",
                "Dispatching",
                "Bandwidth",
                "Web servers"
            ],
            "Author Keywords": [
                "Device Security",
                "Web Configuration Interface",
                "Static Analysis",
                "LLMs"
            ]
        },
        "universities": "China Tobacco Zhejiang Industrial CO; School of Cyberspace Security; College of Control Science and Engineering",
        "countries": "China",
        "locations": [
            "College of Control Science and Engineering, Zhejiang University, Hangzhou, China",
            "School of Cyberspace Security, Hangzhou Dianzi University, Hangzhou, China",
            "College of Control Science and Engineering, Zhejiang University, Hangzhou, China",
            "College of Control Science and Engineering, Zhejiang University, Hangzhou, China",
            "China Tobacco Zhejiang Industrial CO, LTD, Hangzhou, China",
            "China Tobacco Zhejiang Industrial CO, LTD, Hangzhou, China",
            "College of Control Science and Engineering, Zhejiang University, Hangzhou, China"
        ],
        "title": "LuaTaint: A Static Analysis System for Web Configuration Interface Vulnerability of Internet of Things Device"
    },
    {
        "authors": [
            "Oscar G. Lira",
            "Oscar M. Caicedo",
            "Nelson L. S. da Fonseca"
        ],
        "published_in": "Published in: IEEE Communications Magazine ( Early Access )",
        "date_of_publication": "22 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/MCOM.001.2400368",
        "publisher": "IEEE",
        "abstract": "The zero-touch network and service management (ZSM) paradigm, a direct response to the increasing complexity of communication networks, is a problem-solving approach. In this article, taking advantage of recent advances in generative artificial intelligence, we introduce the network configuration generator (LLM-NetCFG) that architects ZSM configuration agents by large language models. LLM-NetCFG can automatically generate configurations, verify them, and configure network devices based on intents expressed in natural language. We also show the automation and verification of network configurations with minimum human intervention. Moreover, we explore the opportunities and challenges of integrating LLM in functional areas of network management to fully achieve ZSM.",
        "issn": {
            "Print ISSN": "0163-6804",
            "Electronic ISSN": "1558-1896"
        },
        "keywords": {
            "IEEE Keywords": [
                "Autonomous networks",
                "Transformers",
                "Training",
                "Data models",
                "Large language models",
                "Analytical models",
                "Adaptation models",
                "Prompt engineering",
                "Knowledge engineering",
                "Generators"
            ],
            "Author Keywords": []
        },
        "universities": "",
        "countries": "",
        "locations": [],
        "title": "Large Language Models for Zero Touch Network Configuration Management"
    },
    {
        "authors": [
            "Li Zhou",
            "Xinfeng Deng",
            "Zhe Wang",
            "Xiaoying Zhang",
            "Yanjie Dong",
            "Xiping Hu",
            "Zhaolong Ning",
            "Jibo Wei"
        ],
        "published_in": "Published in: IEEE Transactions on Cognitive Communications and Networking ( Early Access )",
        "date_of_publication": "17 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/TCCN.2024.3482354",
        "publisher": "IEEE",
        "abstract": "The collaboration among multiple agents demands for efficient communication. However, the observational data in the multi-agent systems are typically voluminous and redundant and pose substantial challenges to the communication system when transmitted directly. To address this issue, this paper introduces a multi-agent communication scheme based on large language model (LLM), referred to as GPT-based semantic information extraction for multi-agent communication (GMAC). This scheme utilizes an LLM to extract semantic information and leverages the generative capabilities to predict subsequent actions, thereby enabling agents to make more informed decisions. The GMAC approach significantly reduces signaling expenditure exchanged among agents by extracting key semantic data via LLM. This method not only simplifies the communication process but also effectively reduces the communication overhead by approximately 53% compared to the baseline methods. Experimental results indicate that GMAC not only improves the convergence speed and accuracy of decision-making but also substantially decreases the signaling expenditure among agents. Consequently, GMAC offers a straightforward and effective method to achieve efficient and economical communication in the multi-agent systems.",
        "issn": {
            "Electronic ISSN": "2332-7731"
        },
        "keywords": {
            "IEEE Keywords": [
                "Bandwidth",
                "Data mining",
                "Data models",
                "Training",
                "Data communication",
                "Computational modeling",
                "Multi-agent systems",
                "Large language models",
                "Generative adversarial networks",
                "Feature extraction"
            ],
            "Author Keywords": [
                "generative ai",
                "multi-agent",
                "reinforcement learning",
                "semantic communication"
            ]
        },
        "universities": "School of Communications and Information Engineering; College of Electronic Science and Technology; Artificial Intelligence Research Institute and the Guangdong-Hong Kong-Macao Joint Laboratory for Emotional Intelligence and Pervasive Computing",
        "countries": "China",
        "locations": [
            "College of Electronic Science and Technology, National University of Defense Technology, Changsha, China",
            "College of Electronic Science and Technology, National University of Defense Technology, Changsha, China",
            "College of Electronic Science and Technology, National University of Defense Technology, Changsha, China",
            "College of Electronic Science and Technology, National University of Defense Technology, Changsha, China",
            "Artificial Intelligence Research Institute and the Guangdong-Hong Kong-Macao Joint Laboratory for Emotional Intelligence and Pervasive Computing, Shenzhen MSU-BIT University, Shenzhen, China",
            "Artificial Intelligence Research Institute and the Guangdong-Hong Kong-Macao Joint Laboratory for Emotional Intelligence and Pervasive Computing, Shenzhen MSU-BIT University, Shenzhen, China",
            "School of Communications and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China",
            "College of Electronic Science and Technology, National University of Defense Technology, Changsha, China"
        ],
        "title": "Semantic Information Extraction and Multi-Agent Communication Optimization Based on Generative Pre-Trained Transformer"
    },
    {
        "authors": [
            "Haoyi Xiong",
            "Jiang Bian",
            "Yuchen Li",
            "Xuhong Li",
            "Mengnan Du",
            "Shuaiqiang Wang",
            "Dawei Yin",
            "Sumi Helal"
        ],
        "published_in": "Published in: IEEE Transactions on Services Computing ( Early Access )",
        "date_of_publication": "28 August 2024",
        "publication_month": "August",
        "publication_year": 2024,
        "doi": "10.1109/TSC.2024.3451185",
        "publisher": "IEEE",
        "abstract": "Combining Large Language Models (LLMs) with search engine services marks a significant shift in the field of services computing, opening up new possibilities to enhance how we search for and retrieve information, understand content, and interact with internet services. This paper conducts an in-depth examination of how integrating LLMs with search engines can mutually benefit both technologies. We focus on two main areas: using search engines to improve LLMs (Search4LLM) and enhancing search engine functions using LLMs (LLM4Search). For Search4LLM, we investigate how search engines can provide diverse high-quality datasets for pre-training of LLMs, how they can use the most relevant documents to help LLMs learn to answer queries more accurately, how training LLMs with Learning-To-Rank (LTR) tasks can enhance their ability to respond with greater precision, and how incorporating recent search results can make LLM-generated content more accurate and current. In terms of LLM4Search, we examine how LLMs can be used to summarize content for better indexing by search engines, improve query outcomes through optimization, enhance the ranking of search results by analyzing document relevance, and help in annotating data for learning-to-rank tasks in various learning contexts. However, this promising integration comes with its challenges, which include addressing potential biases and ethical issues in training models, managing the computational and other costs of incorporating LLMs into search services, and continuously updating LLM training with the ever-changing web content. We discuss these challenges and chart out required research directions to address them. We also discuss broader implications for service computing, such as scalability, privacy concerns, and the need to adapt search engine architectures for these advanced models.",
        "issn": {
            "Electronic ISSN": "1939-1374"
        },
        "keywords": {
            "IEEE Keywords": [
                "Search engines",
                "Accuracy",
                "Training",
                "Service computing",
                "Indexing",
                "Chatbots",
                "Transformers"
            ],
            "Author Keywords": [
                "Large Language Models (LLMs)",
                "Search Engines",
                "Learning-to-Rank (LTR)",
                "and Retrieve-Augmented Generation (RAG)"
            ]
        },
        "universities": "New Jersey Institute of Technology; Baidu; University of Bologna",
        "countries": "NJ; Italy; China",
        "locations": [
            "Baidu, Inc., Beijing, China",
            "Baidu, Inc., Beijing, China",
            "Baidu, Inc., Beijing, China",
            "Baidu, Inc., Beijing, China",
            "New Jersey Institute of Technology, Newark, NJ",
            "Baidu, Inc., Beijing, China",
            "Baidu, Inc., Beijing, China",
            "University of Bologna, Italy"
        ],
        "title": "When Search Engine Services meet Large Language Models: Visions and Challenges"
    },
    {
        "authors": [
            "Yudong Huang",
            "Hongyang Du",
            "Xinyuan Zhang",
            "Dusit Niyato",
            "Jiawen Kang",
            "Zehui Xiong",
            "Shuo Wang",
            "Tao Huang"
        ],
        "published_in": "Published in: IEEE Network ( Early Access )",
        "date_of_publication": "30 July 2024",
        "publication_month": "July",
        "publication_year": 2024,
        "doi": "10.1109/MNET.2024.3435752",
        "publisher": "IEEE",
        "abstract": "The rapid evolution of network technologies and the growing complexity of network tasks necessitate a paradigm shift in how networks are designed, configured, and managed. With a wealth of knowledge and expertise, large language models (LLMs) are one of the most promising candidates. This paper aims to pave the way for constructing domain-adapted LLMs for networking. Firstly, we present potential LLM applications for vertical network fields and showcase the mapping from natural language to network language. Then, several enabling technologies are investigated, including parameter-efficient finetuning and prompt engineering. The insight is that language understanding and tool usage are both required for network LLMs. Driven by the idea of embodied intelligence, we propose the ChatNet, a domain-adapted network LLM framework with access to various external network tools. ChatNet can reduce the time required for burdensome network planning tasks significantly, leading to a substantial improvement in processing efficiency. Finally, key challenges and future research directions are highlighted.",
        "issn": {
            "Print ISSN": "0890-8044",
            "Electronic ISSN": "1558-156X"
        },
        "keywords": {
            "IEEE Keywords": [
                "Natural languages",
                "Task analysis",
                "Manuals",
                "Protocols",
                "Knowledge engineering",
                "Artificial intelligence",
                "Planning"
            ],
            "Author Keywords": [
                "Large Language Models",
                "Generative AI",
                "Intentdriven Networking",
                "Network Intelligence"
            ]
        },
        "universities": "School of Computer Science and Engineering; School of Automation; Information Systems Technology and Design (ISTD) Pillar; State Key Laboratory of Networking and Switching Technology",
        "countries": "P.R. China; Singapore; China",
        "locations": [
            "State Key Laboratory of Networking and Switching Technology, BUPT, Beijing, P.R. China",
            "School of Computer Science and Engineering, Nanyang Technological University, Singapore",
            "State Key Laboratory of Networking and Switching Technology, BUPT, Beijing, P.R. China",
            "School of Computer Science and Engineering, Nanyang Technological University, Singapore",
            "School of Automation, Guangdong University of Technology, China",
            "Information Systems Technology and Design (ISTD) Pillar, Singapore University of Technology and Design, Singapore",
            "State Key Laboratory of Networking and Switching Technology, BUPT, Beijing, P.R. China",
            "State Key Laboratory of Networking and Switching Technology, BUPT, Beijing, P.R. China"
        ],
        "title": "Large Language Models for Networking: Applications, Enabling Techniques, and Challenges"
    },
    {
        "authors": [
            "Zhehui Wang",
            "Tao Luo",
            "Cheng Liu",
            "Weichen Liu",
            "Rick Siow Mong Goh",
            "Weng-Fai Wong"
        ],
        "published_in": "Published in: IEEE Transactions on Pattern Analysis and Machine Intelligence ( Early Access )",
        "date_of_publication": "18 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/TPAMI.2024.3483654",
        "publisher": "IEEE",
        "abstract": "Large language models (LLMs) have garnered substantial attention due to their promising applications in diverse domains. Nevertheless, the increasing size of LLMs comes with a significant surge in the computational requirements for training and deployment. Memristor crossbars have emerged as a promising solution, which demonstrated a small footprint and remarkably high energy efficiency in computer vision (CV) models. Memristors possess higher density compared to conventional memory technologies, making them highly suitable for effectively managing the extreme model size associated with LLMs. However, deploying LLMs on memristor crossbars faces three major challenges. Firstly, the size of LLMs increases rapidly, already surpassing the capabilities of state-of-the-art memristor chips. Secondly, LLMs often incorporate multi-head attention blocks, which involve non-weight stationary multiplications that traditional memristor crossbars cannot support. Third, while memristor crossbars excel at performing linear operations, they are not capable of executing complex nonlinear operations in LLM such as softmax and layer normalization. To address these challenges, we present a novel architecture for the memristor crossbar that enables the deployment of state-of-the-art LLM on a single chip or package, eliminating the energy and time inefficiencies associated with off-chip communication. Our testing on BERT $_{\\rm {Large}}$ showed negligible accuracy loss. Compared to traditional memristor crossbars, our architecture achieves enhancements of up to $39\\times$ in area overhead and $18\\times$ in energy consumption. Compared to modern TPU/GPU systems, our architecture demonstrates at least a $68\\times$ reduction in the area-delay product and a significant 69% energy consumption reduction.",
        "issn": {
            "Print ISSN": "0162-8828",
            "Electronic ISSN": "1939-3539"
        },
        "keywords": {
            "IEEE Keywords": [
                "Memristors",
                "Computer architecture",
                "Random access memory",
                "Nonvolatile memory",
                "Computational modeling",
                "Neural networks",
                "Mathematical models",
                "Energy efficiency",
                "Energy consumption",
                "Transistors"
            ],
            "Author Keywords": [
                "Large language model",
                "memristor crossbar",
                "model deployment",
                "natural language processing",
                "non-volatile memory"
            ]
        },
        "universities": "National University of Singapore; Chinese Academy of Sciences; Nanyang Technological University; Institute of High Performance Computing (IHPC)",
        "countries": "Singapore; China",
        "locations": [
            "Institute of High Performance Computing (IHPC), Agency for Science, Technology and Research (A*STAR), Singapore",
            "Institute of High Performance Computing (IHPC), Agency for Science, Technology and Research (A*STAR), Singapore",
            "Chinese Academy of Sciences, China",
            "Nanyang Technological University, Singapore",
            "Institute of High Performance Computing (IHPC), Agency for Science, Technology and Research (A*STAR), Singapore",
            "National University of Singapore, Singapore"
        ],
        "title": "Enabling Energy-Efficient Deployment of Large Language Models on Memristor Crossbar: A Synergy of Large and Small"
    },
    {
        "authors": [
            "Raghvendra Kumar",
            "Bhargav Goddu",
            "Sriparna Saha",
            "Adam Jatowt"
        ],
        "published_in": "Published in: IEEE Transactions on Artificial Intelligence ( Early Access )",
        "date_of_publication": "08 August 2024",
        "publication_month": "August",
        "publication_year": 2024,
        "doi": "10.1109/TAI.2024.3440248",
        "publisher": "IEEE",
        "abstract": "In the times of advanced generative artificial intelligence, distinguishing truth from fallacy and deception has become a critical societal challenge. This research attempts to analyze the capabilities of large language models for detecting misinformation. Our study employs a versatile approach, covering multiple Large Language Models (LLMs) with few and zero-shot prompting. These models are rigorously evaluated across various fake news and rumour detection datasets. Introducing a novel dimension, we additionally incorporate sentiment and emotion annotations to understand the emotional influence on misinformation detection using LLMs. Moreover, to extend our inquiry, we employ ChatGPT to intentionally distort authentic news as well as human-written fake news, utilizing zero-shot and iterative prompts. This deliberate corruption allows for a detailed examination of various parameters such as abstractness, concreteness, and named entity density, providing insights into differentiating be...",
        "issn": {
            "Electronic ISSN": "2691-4581"
        },
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Social networking (online)",
                "Large language models",
                "Task analysis",
                "Chatbots",
                "Linguistics",
                "Blogs"
            ],
            "Author Keywords": [
                "Fake News",
                "Large Language Models (LLMs)",
                "Misinformation Detection",
                "Prompting Techniques",
                "Rumour News",
                "Sentiment and Emotion"
            ]
        },
        "universities": "Department of Computer Science; Department of Computer Science and Engineering",
        "countries": "India; Austria",
        "locations": [
            "Department of Computer Science and Engineering, Indian Institute of Technology Patna, India",
            "Department of Computer Science and Engineering, Indian Institute of Technology Patna, India",
            "Department of Computer Science and Engineering, Indian Institute of Technology Patna, India",
            "Department of Computer Science, University of Innsbruck, Austria"
        ],
        "title": "Silver Lining in the Fake News Cloud: Can Large Language Models Help Detect Misinformation?"
    },
    {
        "authors": [
            "Mengyi Fu",
            "Pan Wang",
            "Minyao Liu",
            "Ze Zhang",
            "Xiaokang Zhou"
        ],
        "published_in": "Published in: IEEE Transactions on Vehicular Technology ( Early Access )",
        "date_of_publication": "17 May 2024",
        "publication_month": "May",
        "publication_year": 2024,
        "doi": "10.1109/TVT.2024.3402366",
        "publisher": "IEEE",
        "abstract": "The traditional vehicular ad hoc network (VANET) gradually evolved into the internet of vehicles (IoV), which has also become a potential target for attacks and faces security challenges in an open network environment. Intrusion detection systems (IDS) based on machine learning (ML) and deep learning (DL) are introduced to mitigate security threats. However, existing ML/DL-based IDS suffer from challenges in IoV environments. First, due to the limitations of ML/DLbased methods, classification performance is unsatisfactory when they extract only unidirectional contextual features or spatial characteristics. Second, existing research on in-vehicle network IDS often limits validation and testing to a static dataset of a single vehicle model. This approach may not adequately address diverse potential attacks in a dynamic environment. Third, few studies of hybrid IDS can simultaneously implement in-vehicle and extra-vehicle network intrusion detection. Large language models (LLM) have shown outstanding applications in fields such as natural language processing (NLP) and computer vision (CV). In particular, bidirectional encoder representations from transformers (BERT) obtain new state-of-the-art results on eleven famous NLP tasks. Consequently, this paper introduces a hybrid network IDS in IoV utilising LLM, denoted as IoV-BERT-IDS. This framework encompasses four modules: semantic extractor (SE), input embedding, IoV-BERT-IDS pre-training, and IoVBERT- IDS fine-tuning. To conform to the BERT model, the semantic extractor is introduced to transform traffic data devoid of apparent semantics into contextual semantics, comprising bidirectional and unidirectional SE. Through SE, controller area network (CAN) data is transformed into a CAN byte sentence (CBS), while extra-vehicle network traffic data is transformed into a traffic byte sentence (TBS). Additionally, two pre-training tasks, the masked byte word model (MBWM) and next byte sentence prediction (NBSP) are proposed t...",
        "issn": {
            "Print ISSN": "0018-9545",
            "Electronic ISSN": "1939-9359"
        },
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Encoding",
                "Bidirectional control",
                "Task analysis",
                "Natural language processing",
                "Computational modeling",
                "Telecommunication traffic"
            ],
            "Author Keywords": [
                "BERT",
                "pre-training model",
                "intrusion detection system",
                "internet of vehicle",
                "large language model"
            ]
        },
        "universities": "Faculty of Business Data Science; School of Modern Posts",
        "countries": "Japan; China",
        "locations": [
            "School of Modern Posts, Nanjing University of Post&Telecommunications, Nanjing, Jiangsu, China",
            "School of Modern Posts, Nanjing University of Post&Telecommunications, Nanjing, Jiangsu, China",
            "School of Modern Posts, Nanjing University of Post&Telecommunications, Nanjing, Jiangsu, China",
            "School of Modern Posts, Nanjing University of Post&Telecommunications, Nanjing, Jiangsu, China",
            "Faculty of Business Data Science, Kansai University, Osaka, Japan"
        ],
        "title": "IoV-BERT-IDS: Hybrid Network Intrusion Detection System in IoV Using Large Language Models"
    },
    {
        "authors": [
            "Soveatin Kuntur",
            "Anna Wróblewska",
            "Marcin Paprzycki",
            "Maria Ganzha"
        ],
        "published_in": "Published in: IEEE Transactions on Artificial Intelligence ( Early Access )",
        "date_of_publication": "02 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/TAI.2024.3471735",
        "publisher": "IEEE",
        "abstract": "Research into fake news detection has a long history, although it gained significant attention following the 2016 US election. During this time, the widespread use of social media and the resulting increase in interpersonal communication led to the extensive spread of ambiguous and potentially misleading news. Traditional approaches, relying solely on pre- LLM (large language model) techniques and addressing the issue as a simple classification problem, have shown to be insufficient for improving detection accuracy. In this context, large language models have become crucial, as their advanced architectures overcome the limitations of pre-LLM methods, which often fail to capture the subtleties of fake news. This literature review aims to shed light on the field of fake news detection by providing a brief historical overview, defining fake news, reviewing detection methods used before the advent of large language models, and discussing the strengths and weaknesses of these models in an increasingly complex landscape. Furthermore, it will emphasize the importance of using multimodal datasets in the effort to detect fake news.",
        "issn": {
            "Electronic ISSN": "2691-4581"
        },
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Large language models",
                "Artificial intelligence",
                "Social networking (online)",
                "Internet",
                "Voting",
                "Visualization",
                "Reviews",
                "Moon",
                "History"
            ],
            "Author Keywords": [
                "Fake news",
                "Fake news detection",
                "Large language models (LLMs)",
                "Machine learning"
            ]
        },
        "universities": "Systems Research Institute; Warsaw University of Technology",
        "countries": "Poland",
        "locations": [
            "Warsaw University of Technology, Warsaw, Poland",
            "Warsaw University of Technology, Warsaw, Poland",
            "Systems Research Institute, Polish Academy of Sciences, Warsaw, Poland",
            "Warsaw University of Technology, Warsaw, Poland"
        ],
        "title": "Under the Influence: A Survey of Large Language Models in Fake News Detection"
    },
    {
        "authors": [
            "Dianshu Liao",
            "Shidong Pan",
            "Xiaoyu Sun",
            "Xiaoxue Ren",
            "Qing Huang",
            "Zhenchang Xing",
            "Huan Jin",
            "Qinying Li"
        ],
        "published_in": "Published in: IEEE Transactions on Software Engineering ( Early Access )",
        "date_of_publication": "24 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/TSE.2024.3486195",
        "publisher": "IEEE",
        "abstract": "LLM-based code generation tools are essential to help developers in the software development process. Existing tools often disconnect with the working context, i.e., the code repository, causing the generated code to be not similar to human developers. In this paper, we propose a novel code generation framework, dubbed A 3 -CodGen, to harness information within the code repository to generate code with fewer potential logical errors, code redundancy, and library-induced compatibility issues. We identify three types of representative information for the code repository: local-aware information from the current code file, global-aware information from other code files, and third-party- library information. Results demonstrate that by adopting the A 3 -CodGen framework, we successfully extract, fuse, and feed code repository information into the LLM, generating more accurate, efficient, and highly reusable code. The effectiveness of our framework is further underscored by generating code with a higher reuse rate, compared to human developers. This research contributes significantly to the field of code generation, providing developers with a more powerful tool to address the evolving demands in software development in practice.",
        "issn": {
            "Print ISSN": "0098-5589",
            "Electronic ISSN": "1939-3520"
        },
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Libraries",
                "Software development management",
                "Data mining",
                "Benchmark testing",
                "Transformers",
                "Software engineering",
                "Context modeling",
                "Chatbots",
                "Australia"
            ],
            "Author Keywords": [
                "Code Generation",
                "Repository Knowledge Mining",
                "Code Reuse",
                "Retrieval-Augmented Generation"
            ]
        },
        "universities": "Jiangxi University of Technology; School of Computing; School of Computer Information Engineering at Jiangxi Normal University; CSIRO’s Data61; State Key Laboratory of Blockchain and Data Security",
        "countries": "Australia; Zhejiang University; China",
        "locations": [
            "School of Computing, Australian National University, Australia",
            "CSIRO’s Data61, Australia",
            "School of Computing, Australian National University, Australia",
            "State Key Laboratory of Blockchain and Data Security, Zhejiang University",
            "School of Computer Information Engineering at Jiangxi Normal University, China",
            "CSIRO’s Data61, Australia",
            "Jiangxi University of Technology, China",
            "Jiangxi University of Technology, China"
        ],
        "title": "A3-CodGen : A Repository-Level Code Generation Framework for Code Reuse with Local-Aware, Global-Aware, and Third-Party-Library-Aware"
    },
    {
        "authors": [
            "Taslim Mahbub",
            "Dana Dghaym",
            "Aadhith Shankarnarayanan",
            "Taufiq Syed",
            "Salsabeel Shapsough",
            "Imran Zualkernan"
        ],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "19 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/ACCESS.2024.3464242",
        "publisher": "IEEE",
        "abstract": "Effective software projects hinge on robust requirements, yet flawed requirements often lead to costly delays and revisions. While tools have been developed to identify defects in Software Requirements Specifications (SRS), the advent of Large Language Models (LLMs) like GPT-4 presents new opportunities for enhancing requirements quality. However, the potential of LLMs in this realm remains largely unexplored, particularly in the context of large-scale industrial documents. To bridge this gap, we investigate the efficacy of zero-shot GPT-4 in various requirements analysis tasks using an industrial software specification document. Our study evaluates LLM performance in detecting defects, such as ambiguities, inconsistencies, and incompleteness, while also analyzing GPT-4’s ability to identify issues across version iterations and support technical experts in requirements analysis. Qualitatively, we identify key limitations of LLMs in defect detection, notably their inability to cross-reference throughout the document and their constrained understanding of specialized contexts. Quantitatively, we find that while LLMs excel in identifying incomplete requirements (precision 0.61), their performance is less impressive in detecting inconsistencies (precision 0.43) and ambiguities (precision 0.39). Although GPT-4 demonstrates promise in automating early defect detection across versions and providing accurate technical answers, our results underscore that they cannot entirely replace human analysts due to their lack of nuanced domain knowledge in a zero-shot setting. Nevertheless, avenues like few-shot learning and complex prompt design offer the potential to enhance LLM precision in defect detection.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Stakeholders",
                "Large language models",
                "Accuracy",
                "Requirements engineering",
                "Defect detection",
                "Software development management",
                "Software engineering"
            ],
            "Author Keywords": [
                "Ambiguity",
                "Completeness",
                "GPT",
                "Inconsistency",
                "Large Language Models (LLMs)",
                "Requirements Engineering",
                "Software Engineering",
                "Software Requirements Specifications (SRS)"
            ]
        },
        "universities": "Department of Computer Science and Engineering",
        "countries": "United Arab Emirates",
        "locations": [
            "Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates",
            "Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates",
            "Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates",
            "Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates",
            "Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates",
            "Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates"
        ],
        "title": "Can GPT-4 aid in detecting ambiguities, inconsistencies, and incompleteness in requirements analysis? A comprehensive case study."
    },
    {
        "authors": [
            "Yi Rong",
            "Yingchi Mao",
            "Huajun Cui",
            "Xiaoming He",
            "Mingkai Chen"
        ],
        "published_in": "Published in: IEEE Transactions on Intelligent Transportation Systems ( Early Access )",
        "date_of_publication": "17 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/TITS.2024.3456890",
        "publisher": "IEEE",
        "abstract": "The Intelligent Autonomous Transport System in 6G (6G-IATS) refers to the coordination of 6G, Artificial Intelligence (AI), and intelligent transportation systems, which is expected to revolutionize future intelligent transportation systems. In 6G-IATS, large-scale traffic flow prediction, affiliated with time series prediction, holds significant value for transportation planning and urban management. As an emerging AI method, Large Language Models (LLMs) have emerged prominently in time series forecasting. Unfortunately, it is challenging to achieve accurate and efficient large-scale traffic flow prediction by LLMs in 6G-IATS, due to the two issues: a) these LLMs fail to capture the spatio-temporal correlations in a large-scale road network, leading to limited prediction accuracy, and b) they process a substantial amount of training data on the central server, which imposes low training efficiency. Jointly considering the two concerns, this paper proposes a novel LLM and edge computing-based architecture for large-scale traffic flow prediction in 6G-IATS, called Spatio-Temporal Generative Large Language Model on Edge (STGLLM-E). In this architecture, we first decompose the entire large-scale road network into several subgraphs. To capture the spatio-temporal correlations, an LLM-based method named Spatio-Temporal Generative Large Language Model (STGLLM) including Spatio-Temporal Module (STM) and Generative Large Language Model (GLLM) is proposed. Secondly, to improve the training efficiency of the STGLLM-E, an edge training strategy based on edge servers is devised. Experiments are conducted on two real-world traffic flow datasets. The experimental results illustrate that the STGLLM-E is superior to the baselines in the prediction accuracy and the efficiency of training.",
        "issn": {
            "Print ISSN": "1524-9050",
            "Electronic ISSN": "1558-0016"
        },
        "keywords": {
            "IEEE Keywords": [
                "Roads",
                "6G mobile communication",
                "Training",
                "Servers",
                "Correlation",
                "Accuracy",
                "Artificial intelligence"
            ],
            "Author Keywords": [
                "IATS",
                "6G",
                "large-scale traffic flow prediction",
                "LLMs",
                "edge computing"
            ]
        },
        "universities": "Digital Intelligence Research Institute; Key Laboratory of Broadband Wireless Communication and Sensor Network Technology; College of Computer Science and Software Engineering; College of Internet of Things",
        "countries": "China",
        "locations": [
            "College of Computer Science and Software Engineering, Hohai University, Nanjing, China",
            "College of Computer Science and Software Engineering, Hohai University, Nanjing, China",
            "Digital Intelligence Research Institute, PowerChina Beijing Engineering Corporation Ltd, Beijing, China",
            "College of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing, China",
            "Key Laboratory of Broadband Wireless Communication and Sensor Network Technology, Nanjing University of Posts and Telecommunications, Nanjing, China"
        ],
        "title": "Edge Computing Enabled Large-Scale Traffic Flow Prediction With GPT in Intelligent Autonomous Transport System for 6G Network"
    },
    {
        "authors": [
            "Engin Zeydan",
            "Josep Mangues",
            "Suayb S. Arslan",
            "Yekta Turk",
            "Madhusanka Liyanage"
        ],
        "published_in": "Published in: IEEE Consumer Electronics Magazine ( Early Access )",
        "date_of_publication": "04 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/MCE.2024.3490780",
        "publisher": "IEEE",
        "abstract": "The evolution of consumer electronics is increasingly driven by advancements in industrial automation, where generative artificial intelligence (AI) plays a pivotal role, particularly in intent-based systems. This study presents a comprehensive framework for integrating generative AI into intent-based industrial automation, which aims to align high-level business goals with precise operational tasks on the factory floor. The proposed architecture synergistically combines three main components: Business Intents, the Intent Layer and the Factory Floor Shop. This framework leverages foundation models such as the most prominent large language models (LLMs) and advanced communication technologies to translate strategic business intents — such as cost optimization, order management and market adaptation — into actionable tasks to improve operational efficiency, responsiveness and strategic alignment. We also propose a process of fine-tuning LLMs to optimize their interaction flow within the intent-based system, highlighting the augmentation techniques employed to adapt LLMs for industrial contexts. Numerical results demonstrate the effectiveness of the proposed framework and show percentage improvements compared to pre-trained LLM models.",
        "issn": {
            "Print ISSN": "2162-2248",
            "Electronic ISSN": "2162-2256"
        },
        "keywords": {
            "IEEE Keywords": [
                "Business",
                "Automation",
                "Data models",
                "Reviews",
                "Training",
                "Production facilities",
                "Generative AI",
                "Consumer electronics",
                "Adaptation models",
                "Analytical models"
            ],
            "Author Keywords": []
        },
        "universities": "Aselsan Corporation; Centre Tecnológic de Telecomunicacions de Catalunya; Boğaziçi University; University College Dublin",
        "countries": "Turkey; Ireland; Türkiye; Spain",
        "locations": [
            "Centre Tecnológic de Telecomunicacions de Catalunya, Spain",
            "Centre Tecnológic de Telecomunicacions de Catalunya, Spain",
            "Boğaziçi University, Türkiye",
            "Aselsan Corporation, Turkey",
            "University College Dublin, Ireland"
        ],
        "title": "Generative Artificial Intelligence for Intent-Based Industrial Automation"
    },
    {
        "authors": [
            "Kehai Qiu",
            "Stefanos Bakirtzis",
            "Ian Wassell",
            "Hui Song",
            "Jie Zhang",
            "Kezhi Wang"
        ],
        "published_in": "Published in: IEEE Wireless Communications Letters ( Early Access )",
        "date_of_publication": "17 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/LWC.2024.3462556",
        "publisher": "IEEE",
        "abstract": "In this paper, we present the Large Language Model-based combinatorial optimizer (LMCO) for wireless network optimization and planning tasks, focusing on optimizing the number and the placement of wireless access point placement. The performance and efficiency of LMCO are evaluated and compared with the well-established Ant Colony Optimization (ACO) algorithm. The results indicate that LMCO exhibits superior performance, particularly as the complexity of the problem increases. These findings also underscore the significant potential of LLM-based algorithms in revolutionizing combinatorial optimization across a wide range of applications.",
        "issn": {
            "Print ISSN": "2162-2337",
            "Electronic ISSN": "2162-2345"
        },
        "keywords": {
            "IEEE Keywords": [
                "Optimization",
                "Planning",
                "Solid modeling",
                "Wireless communication",
                "Wireless networks",
                "Ray tracing",
                "Floors"
            ],
            "Author Keywords": [
                "Large language model",
                "network optimization",
                "combinatorial optimization",
                "access point placement"
            ]
        },
        "universities": "Department of Computer Science and Technology; Ranplan Wireless Network Design LTD; Department of Computer Science",
        "countries": "U.K.; UK",
        "locations": [
            "Department of Computer Science and Technology, University of Cambridge, Cambridge, U.K.",
            "Department of Computer Science and Technology, University of Cambridge, Cambridge, U.K.",
            "Department of Computer Science and Technology, University of Cambridge, Cambridge, U.K.",
            "Ranplan Wireless Network Design LTD, Cambridge, U.K.",
            "Ranplan Wireless Network Design LTD, Cambridge, U.K.",
            "Department of Computer Science, Brunel University London, UK"
        ],
        "title": "Large Language Model-Based Wireless Network Design"
    },
    {
        "authors": [
            "Yifan Tang",
            "Yihao Wang",
            "Ru Zhang",
            "Jianyi Liu"
        ],
        "published_in": "Published in: IEEE Signal Processing Letters ( Early Access )",
        "date_of_publication": "13 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/LSP.2024.3496817",
        "publisher": "IEEE",
        "abstract": "To detect stego (steganographic text) in complex scenarios, linguistic steganalysis (LS) with various motivations has been proposed and achieved excellent performance. However, with the development of generative steganography, some stegos have strong concealment, especially after the emergence of LLMsbased steganography, the existing LS has low detection or cannot detect them. We designed a novel LS with two modes called LSG/C. In the generation mode, we created an LS-task “description” and used the generation ability of LLM to explain whether texts to be detected are stegos. On this basis, we rethought the principle of LS and LLMs, and proposed the classification mode. In this mode, LS-G/C deleted the LS-task “description” and used the “causalLM” LLMs to extract steganographic features. The LS features can be extracted by only one pass of the model, and a linear layer with initialization weights is added to obtain the classification probability. Experiments on strongly concealed stegos show that LS-G/C significantly improves detection and reaches SOTA performance. Additionally, LS-G/C in classification mode greatly reduces training time while maintaining high performance.",
        "issn": {
            "Print ISSN": "1070-9908",
            "Electronic ISSN": "1558-2361"
        },
        "keywords": {
            "IEEE Keywords": [],
            "Author Keywords": [
                "Linguistic steganalysis",
                "LLMs",
                "classification mode",
                "generation mode",
                "efficient steganalysis"
            ]
        },
        "universities": "School of Cyberspace Security",
        "countries": "China",
        "locations": [
            "School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China",
            "School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China",
            "School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China",
            "School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China"
        ],
        "title": "Linguistic Steganalysis via LLMs: Two Modes for Efficient Detection of Strongly Concealed Stego"
    },
    {
        "authors": [
            "Wenhao Li",
            "Jingtong Zhao",
            "Liujinxiang Zhu",
            "Li Zhang",
            "Han Wang"
        ],
        "published_in": "Published in: Tsinghua Science and Technology ( Early Access )",
        "date_of_publication": "17 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.26599/TST.2024.9010114",
        "publisher": "TUP",
        "abstract": "Drug-Target Interactions (DTIs) identification is a crucial phase in drug development to screen potential drugs and targets and improve the efficiency of drug development. Accompanied by advances in Artificial Intelligence (AI) technology, Deep Learning (DL) methods have been introduced to the field and designed for DTI prediction, which can expedite the Research and Development (R&D) cycle. However, with the diverse DTIs involving various types of drugs and target protein molecules, it is still challenging to reveal the rules behind those interactions and further make reliable suggestions for the pharmaceutical industry. Currently, AI technology is expected to promote the ability to characterize the molecules against limited knowledge about DTIs. In this study, we accordingly propose a novel DTI prediction method named TopoPharmDTI, dedicated to better characterizing both the drug and target molecules, where an innovative dual-tier drug features fusion strategy is designed for drug molecules and a most adaptive Large Language Model (LLM) for target protein sequence representation is chosen under the evaluation of six top models by far. Our method achieves considerable prediction performance and a promising capability to identify the binding domains on the target protein. The method is freely available at http://ex.nenucompbio.com/TopoPharmDTI.html.",
        "issn": {
            "Electronic ISSN": "1007-0214"
        },
        "keywords": {
            "IEEE Keywords": [
                "Bacteria",
                "Archaea",
                "Viruses (medical)",
                "Fungi",
                "Proteins",
                "Drugs",
                "Atomic measurements"
            ],
            "Author Keywords": [
                "Drug-Target Interactions (DTIs)",
                "Deep Learning (DL)",
                "protein language model",
                "drug features fusion"
            ]
        },
        "universities": "",
        "countries": "",
        "locations": [],
        "title": "TopoPharmDTI: Improving interactions prediction by enhanced deep learning representation for both drug and target molecules"
    },
    {
        "authors": [
            "Ali Maatouk",
            "Nicola Piovesan",
            "Fadhel Ayed",
            "Antonio De Domenico",
            "Merouane Debbah"
        ],
        "published_in": "Published in: IEEE Communications Magazine ( Early Access )",
        "date_of_publication": "15 July 2024",
        "publication_month": "July",
        "publication_year": 2024,
        "doi": "10.1109/MCOM.001.2300473",
        "publisher": "IEEE",
        "abstract": "Large language models (LLMs) -- AI-driven models that can achieve general-purpose language understanding and generation -- have emerged as a transformative force, revolutionizing fields well beyond natural language processing (NLP) and garnering unprecedented attention. As LLM technology continues to progress, the telecom industry is facing the prospect of its impact on the landscape. To elucidate these implications, we delve into the inner workings of LLMs, providing insights into their current capabilities and limitations. We also examine the use cases that can be readily implemented in the telecom industry, streamlining tasks, such as anomaly resolution and technical specification comprehension, which currently hinder operational efficiency and demand significant manpower and expertise. Furthermore, we uncover essential research directions that deal with the distinctive challenges of utilizing the LLMs within the telecom domain. Addressing them represents a significant stride toward fully harnessing the potential of LLMs, and unlocking their capabilities to the fullest extent within the telecom domain.",
        "issn": {
            "Print ISSN": "0163-6804",
            "Electronic ISSN": "1558-1896"
        },
        "keywords": {
            "IEEE Keywords": [
                "Telecommunications",
                "Industries",
                "Task analysis",
                "Data models",
                "Training",
                "Natural language processing",
                "Biological system modeling"
            ],
            "Author Keywords": []
        },
        "universities": "",
        "countries": "",
        "locations": [],
        "title": "Large Language Models for Telecom: Forthcoming Impact on the Industry"
    },
    {
        "authors": [
            "Yuxuan Chen",
            "Rongpeng Li",
            "Zhifeng Zhao",
            "Chenghui Peng",
            "Jianjun Wu",
            "Ekram Hossain",
            "Honggang Zhang"
        ],
        "published_in": "Published in: IEEE Network ( Early Access )",
        "date_of_publication": "18 March 2024",
        "publication_month": "March",
        "publication_year": 2024,
        "doi": "10.1109/MNET.2024.3376419",
        "publisher": "IEEE",
        "abstract": "Large language models (LLMs) have triggered tremendous success to empower our daily life by generative information. The personalization of LLMs could further contribute to their applications due to better alignment with human intents. Towards personalized generative services, a collaborative cloud-edge methodology is promising, as it facilitates the effective orchestration of heterogeneous distributed communication and computing resources. In this article, we put forward NetGPT to capably synergize appropriate LLMs at the edge and the cloud based on their computing capacity. In addition, edge LLMs could efficiently leverage location-based information for personalized prompt completion, thus benefiting the interaction with the cloud LLM. In particular, we present the feasibility of NetGPT by leveraging low-rank adaptation-based fine-tuning of open-source LLMs (i.e., GPT-2-base model and LLaMA model), and conduct comprehensive numerical comparisons with alternative cloud-edge collaboration or cloud-only techniques, so as to demonstrate the superiority of NetGPT. Subsequently, we highlight the essential changes required for an artificial intelligence (AI)-native network architecture towards NetGPT, with emphasis on deeper integration of communications and computing resources and careful calibration of logical AI workflow. Furthermore, we demonstrate several benefits of NetGPT, which come as by-products, as the edge LLMs’ capability to predict trends and infer intents promises a unified solution for intelligent network management & orchestration. We argue that NetGPT is a promising AI-native network architecture for provisioning beyond personalized generative services.",
        "issn": {
            "Print ISSN": "0890-8044",
            "Electronic ISSN": "1558-156X"
        },
        "keywords": {
            "IEEE Keywords": [
                "Computational modeling",
                "Collaboration",
                "Servers",
                "Artificial intelligence",
                "Adaptation models",
                "Training",
                "Context modeling"
            ],
            "Author Keywords": []
        },
        "universities": "University of Manitoba; Huawei Technologies Co.; Zhejiang University",
        "countries": "Canada; China",
        "locations": [
            "Zhejiang University, Hangzhou, China",
            "Zhejiang University, Hangzhou, China",
            "Zhejiang University, Hangzhou, China",
            "Huawei Technologies Co., Ltd, Shanghai, China",
            "Huawei Technologies Co., Ltd, Shanghai, China",
            "University of Manitoba, Winnipeg, Manitoba, Canada",
            "Zhejiang University, Hangzhou, China"
        ],
        "title": "NetGPT: An AI-Native Network Architecture for Provisioning Beyond Personalized Generative Services"
    },
    {
        "authors": [
            "Tianyu Tu",
            "Zhili He",
            "Zhigao Zheng",
            "Zimu Zheng",
            "Jiawei Jiang",
            "Yili Gong",
            "Chuang Hu",
            "Dazhao Cheng"
        ],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "06 May 2024",
        "publication_month": "May",
        "publication_year": 2024,
        "doi": "10.1109/JIOT.2024.3396282",
        "publisher": "IEEE",
        "abstract": "With the rapid development of the Internet of Things (IoT), IoT devices find applications in various domains. The data generated by these devices is utilized for analysis and services, especially in the field of Artificial Intelligence (AI) applied to IoT, known as Artificial Intelligence of Things (AIoT). The enhancement of edge device computing power in the IoT has led to the emergence of research areas like edge-cloud synergy AI theories and application services. In the context of lifelong learning and real-time processes in AIoT edge-cloud synergy services, addressing unseen tasks becomes crucial. Unseen tasks arise when inference requests from edge devices involve models not present in the cloud’s model repository. Addressing these challenges involves generating data to either augment small sample problems or alter the data distribution for heterogeneous sample issues. As the application of large language models (LLMs) for data generation gains traction, challenges emerge in the context of AIoT edge-cloud synergy services. Firstly, fine-tuning LLMs with heterogeneous data exacerbates model bias issues. Secondly, the substantial data requirements for training LLMs pose a contradiction. Lastly, the involvement of manual annotation in LLM-based data generation introduces complexity and cost. This paper proposes a framework Seafarer to these challenges using Generative Adversarial Networks and Self-taught Learning. Seafarer avoids model bias, reduces data requirements, and eliminates the need for manual annotation. The design demonstrates effectiveness theoretically and is validated on the Cityscapes dataset, achieving an 80% reduction in training loss and improved validation loss stability.",
        "issn": {
            "Electronic ISSN": "2327-4662"
        },
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Artificial intelligence",
                "Internet of Things",
                "Training",
                "Cloud computing",
                "Manuals",
                "Data mining"
            ],
            "Author Keywords": [
                "Edge-Cloud Synergy AI",
                "Lifelong Learning",
                "Internet of Things (IoT)",
                "Artificial Intelligence of Things (AIoT)"
            ]
        },
        "universities": "Computer School; Edge Cloud Innovation Lab",
        "countries": "China",
        "locations": [
            "Computer School, Wuhan University, Hubei, China",
            "Computer School, Wuhan University, Hubei, China",
            "Computer School, Wuhan University, Hubei, China",
            "Edge Cloud Innovation Lab, China",
            "Computer School, Wuhan University, Hubei, China",
            "Computer School, Wuhan University, Hubei, China",
            "Computer School, Wuhan University, Hubei, China",
            "Computer School, Wuhan University, Hubei, China"
        ],
        "title": "Towards Lifelong Unseen Task Processing With a Lightweight Unlabeled Data Schema for AIoT"
    },
    {
        "authors": [
            "Siddhant Bikram Shah",
            "Surendrabikram Thapa",
            "Ashish Acharya",
            "Kritesh Rauniyar",
            "Sweta Poudel",
            "Sandesh Jain",
            "Anum Masood",
            "Usman Naseem"
        ],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "29 May 2024",
        "publication_month": "May",
        "publication_year": 2024,
        "doi": "10.1109/ACCESS.2024.3406644",
        "publisher": "IEEE",
        "abstract": "This paper explores the dual role of Large Language Models (LLMs) in the context of online misinformation and disinformation. In today’s digital landscape, where the internet and social media facilitate the rapid dissemination of information, discerning between accurate content and falsified information presents a formidable challenge. Misinformation, often arising unintentionally, and disinformation, crafted deliberately, are at the forefront of this challenge. LLMs such as OpenAI’s GPT-4, equipped with advanced language generation abilities, present a double-edged sword in this scenario. While they hold promise in combating misinformation by fact-checking and detecting LLM-generated text, their ability to generate realistic, contextually relevant text also poses risks for creating and propagating misinformation. Further, LLMs are plagued with many problems such as biases, knowledge cutoffs, and hallucinations, which may further perpetuate misinformation and disinformation. The paper outlines historical developments in misinformation detection and how it affects social media consumption, especially among youth, and introduces LLMs and their applications in various domains. It then critically analyzes the potential of LLMs to generate and counter misinformation and disinformation in sensitive topics such as healthcare, COVID-19, and political agendas. Further, it discusses mitigation strategies, ethical considerations, and regulatory measures, summarizing previous methods and proposing future research direction toward leveraging the benefits of LLMs while minimizing misuse risks. The paper concludes by acknowledging LLMs as powerful tools with significant implications in both spreading and combating misinformation in the digital age.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Information integrity",
                "Social networking (online)",
                "Navigation",
                "Market research",
                "Feature extraction",
                "Neural networks",
                "Large language models",
                "Social sciences"
            ],
            "Author Keywords": [
                "Large Language Models",
                "Disinformation",
                "Computational Social Sciences",
                "ChatGPT",
                "Hallucinations in LLMs"
            ]
        },
        "universities": "School of Computing; Kathmandu Engineering College; Department of Computer Science and Engineering; Herald College Kathmandu; Department of Circulation and Medical Imaging; Virginia Tech",
        "countries": "India; Norway; Australia; USA; Nepal",
        "locations": [
            "Department of Computer Science and Engineering, Delhi Technological University, New Delhi, India",
            "Virginia Tech, Blacksburg, VA, USA",
            "Herald College Kathmandu, Sanogaucharan, Naxal, Bhagwatibahal, Nepal",
            "Department of Computer Science and Engineering, Delhi Technological University, New Delhi, India",
            "Kathmandu Engineering College, Tribhuvan University, Kathmandu, Nepal",
            "Virginia Tech, Blacksburg, VA, USA",
            "Department of Circulation and Medical Imaging, Norwegian University of Science and Technology, Trondheim, Norway",
            "School of Computing, Macquarie University, Sydney, NSW, Australia"
        ],
        "title": "Navigating the Web of Disinformation and Misinformation: Large Language Models as Double-Edged Swords"
    },
    {
        "authors": [
            "Feibo Jiang",
            "Yubo Peng",
            "Li Dong",
            "Kezhi Wang",
            "Kun Yang",
            "Cunhua Pan",
            "Dusit Niyato",
            "Octavia A. Dobre"
        ],
        "published_in": "Published in: IEEE Wireless Communications ( Early Access )",
        "date_of_publication": "16 August 2024",
        "publication_month": "August",
        "publication_year": 2024,
        "doi": "10.1109/MWC.016.2300600",
        "publisher": "IEEE",
        "abstract": "The rapid development of the large language model (LLM) presents huge opportunities for 6G communications -- for example, network optimization and management -- by allowing users to input task requirements to LLMs with natural language. However, directly applying native LLMs in 6G encounters various challenges, such as a lack of communication data and knowledge, and limited logical reasoning, evaluation, and refinement abilities. Integrating LLMs with the capabilities of retrieval, planning, memory, evaluation, and reflection in agents can greatly enhance the potential of LLMs for 6G communications. To this end, we propose CommLLM, a multi-agent system with customized communication knowledge and tools for solving communication-related tasks using natural language. This system consists of three components: multi-agent data retrieval (MDR), which employs the condensate and inference agents to refine and summarize communication knowledge from the knowledge base, expanding the knowledge boundaries of LLMs in 6G communications; multi-agent collaborative planning (MCP), which utilizes multiple planning agents to generate feasible solutions for the communication-related task from different perspectives based on the retrieved knowledge; and multi-agent evaluation and reflection (MER), which utilizes the evaluation agent to assess the solutions, and applies the reflection agent and refinement agent to provide improvement suggestions for current solutions. Finally, we validate the effectiveness of the proposed multi-agent system by designing a semantic communication system as a case study of 6G communications.",
        "issn": {
            "Print ISSN": "1536-1284",
            "Electronic ISSN": "1558-0687"
        },
        "keywords": {
            "IEEE Keywords": [
                "6G mobile communication",
                "Task analysis",
                "Knowledge engineering",
                "Artificial intelligence",
                "Multi-agent systems",
                "Communication systems",
                "Cognition"
            ],
            "Author Keywords": []
        },
        "universities": "",
        "countries": "",
        "locations": [],
        "title": "Large Language Model Enhanced Multi-Agent Systems for 6G Communications"
    },
    {
        "authors": [
            "Pengyu Xue",
            "Linhao Wu",
            "Zhongxing Yu",
            "Zhi Jin",
            "Zhen Yang",
            "Xinyi Li",
            "Zhenyu Yang",
            "Yue Tan"
        ],
        "published_in": "Published in: IEEE Transactions on Software Engineering ( Early Access )",
        "date_of_publication": "10 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/TSE.2024.3478317",
        "publisher": "IEEE",
        "abstract": "Commit Message Generation (CMG) approaches aim to automatically generate commit messages based on given code diff s , which facilitate collaboration among developers and play a critical role in Open-Source Software (OSS). Very recently, Large Language Models (LLMs) have been applied in diverse code-related tasks owing to their powerful generality. Yet, in the CMG field, few studies systematically explored their effectiveness. This paper conducts the first comprehensive experiment to investigate how far we have been in applying LLM to generate high-quality commit messages and how to go further beyond in this field. Motivated by a pilot analysis, we first construct a multi-lingual high-quality CMG test set following practitioners’ criteria. Afterward, we re-evaluate diverse CMG approaches and make comparisons with recent LLMs. To delve deeper into LLMs’ ability, we further propose four manual metrics following the practice of OSS, including Accuracy, Integrity, Readability, and Applicability for assessment. Results reveal that LLMs have outperformed existing CMG approaches overall, and different LLMs carry different advantages, where GPT-3.5 performs best. To further boost LLMs’ performance in the CMG task, we propose an Efficient Retrieval-based In-Context Learning (ICL) framework, namely ERICommiter, which leverages a two-step filtering to accelerate the retrieval efficiency and introduces semantic/lexical-based retrieval algorithm to construct the ICL examples, thereby guiding the generation of high-quality commit messages with LLMs. Extensive experiments demonstrate the substantial performance improvement of ERICommiter on various LLMs across different programming languages. Meanwhile, ERICommiter also significantly reduces the retrieval time while keeping almost the same performance. Our research contributes to the understanding of LLMs’ capabilities in the CMG field and provides valuable insights for practitioners seeking to leverage these tools in their workf...",
        "issn": {
            "Print ISSN": "0098-5589",
            "Electronic ISSN": "1939-3520"
        },
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Measurement",
                "Manuals",
                "Collaboration",
                "Systematics",
                "Solid modeling",
                "Data models",
                "Python",
                "Large language models",
                "Java"
            ],
            "Author Keywords": [
                "Commit Message Generation",
                "Large Language Model",
                "Empirical Study",
                "In-Context Learning"
            ]
        },
        "universities": "School of Electrical and Electronic Engineering; Key Laboratory of High Confidence Software Technologies (Peking University); School of Computer Science and Technology",
        "countries": "Singapore; China",
        "locations": [
            "School of Computer Science and Technology, Shandong University, Qingdao, China",
            "School of Computer Science and Technology, Shandong University, Qingdao, China",
            "School of Computer Science and Technology, Shandong University, Qingdao, China",
            "Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, and the School of Computer Science, Peking University, Beijing, China",
            "School of Computer Science and Technology, Shandong University, Qingdao, China",
            "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
            "School of Computer Science and Technology, Shandong University, Qingdao, China",
            "School of Computer Science and Technology, Shandong University, Qingdao, China"
        ],
        "title": "Automated Commit Message Generation with Large Language Models: An Empirical Study and Beyond"
    },
    {
        "authors": [
            "Harsh Patel",
            "Dominique Boucher",
            "Emad Fallahzadeh",
            "Ahmed E. Hassan",
            "Bram Adams"
        ],
        "published_in": "Published in: IEEE Software ( Early Access )",
        "date_of_publication": "08 August 2024",
        "publication_month": "August",
        "publication_year": 2024,
        "doi": "10.1109/MS.2024.3440190",
        "publisher": "IEEE",
        "abstract": "This paper investigates the complexities of integrating Large Language Models (LLMs) into software products, with a focus on the challenges encountered for determining their readiness for release. Our systematic review of grey literature identifies common challenges in deploying LLMs, ranging from pre-training and finetuning to user experience considerations. The study introduces a comprehensive checklist designed to guide practitioners in evaluating key release readiness aspects such as performance, monitoring, and deployment strategies, aiming to enhance the reliability and effectiveness of LLM-based applications in real-world settings.",
        "issn": {
            "Print ISSN": "0740-7459",
            "Electronic ISSN": "1937-4194"
        },
        "keywords": {
            "IEEE Keywords": [
                "Software",
                "Data models",
                "Artificial intelligence",
                "Production",
                "Vectors",
                "Ethics",
                "Companies"
            ],
            "Author Keywords": []
        },
        "universities": "National Bank of Canada; Queen’s University",
        "countries": "Canada",
        "locations": [
            "Queen’s University, Canada",
            "National Bank of Canada, Canada",
            "Queen’s University, Canada",
            "Queen’s University, Canada",
            "Queen’s University, Canada"
        ],
        "title": "A State-of-the-practice Release-readiness Checklist for Generative AI-based Software Products"
    },
    {
        "authors": [
            "Sam Yu-Te Lee",
            "Kwan-Liu Ma"
        ],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "12 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/TVCG.2024.3459961",
        "publisher": "IEEE",
        "abstract": "Sensemaking on a large collection of documents (corpus) is a challenging task often found in fields such as market research, legal studies, intelligence analysis, political science, or computational linguistics. Previous works approach this problem from topic- and entity-based perspectives, but the capability of the underlying NLP model limits their effectiveness. Recent advances in prompting with LLMs present opportunities to enhance such approaches with higher accuracy and customizability. However, poorly designed prompts and visualizations could mislead users into falsely interpreting the visualizations and hinder the system's trustworthiness. In this paper, we address this issue by taking into account the user analysis tasks and visualization goals in the prompt-based data extraction stage, thereby extending the concept of Model Alignment. We present HINTs, a VA system for supporting sensemaking on large collections of documents, combining previous entity-based and topic-based approaches. The visualization pipeline of HINTs consists of three stages. First, entities and topics are extracted from the corpus with prompts. Then, the result is modeled as a hypergraph and hierarchically clustered. Finally, an enhanced space-filling curve layout is applied to visualize the hypergraph for interactive exploration. The system further integrates an LLM-based intelligent chatbot agent in the interface to facilitate the sensemaking of interested documents. To demonstrate the generalizability and effectiveness of the HINTs system, we present two case studies on different domains and a comparative user study. We report our insights on the behavior patterns and challenges when intelligent agents are used to facilitate sensemaking. We find that while intelligent agents can address many challenges in sensemaking, the visual hints that visualizations provide are still necessary. We discuss limitations and future work for combining interactive visualization and LLMs more profoundly...",
        "issn": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Data mining",
                "Intelligent agents",
                "Visual analytics",
                "Tag clouds",
                "Pipelines",
                "Fake news"
            ],
            "Author Keywords": [
                "Text visualization",
                "sensemaking",
                "hypergraph",
                "hierarchical clusters",
                "corpus analysis",
                "large language models"
            ]
        },
        "universities": "Department of Computer Science",
        "countries": "USA",
        "locations": [
            "Department of Computer Science, University of California at Davis, One Shields Ave., Davis, CA, USA",
            "Department of Computer Science, University of California at Davis, One Shields Ave., Davis, CA, USA"
        ],
        "title": "HINTs: Sensemaking on large collections of documents with Hypergraph visualization and INTelligent agents"
    },
    {
        "authors": [
            "Youfu Yan",
            "Yu Hou",
            "Yongkang Xiao",
            "Rui Zhang",
            "Qianwen Wang"
        ],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "10 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/TVCG.2024.3456364",
        "publisher": "IEEE",
        "abstract": "The increasing reliance on Large Language Models (LLMs) for health information seeking can pose severe risks due to the potential for misinformation and the complexity of these topics. This paper introduces KNOWNET a visualization system that integrates LLMs with Knowledge Graphs (KG) to provide enhanced accuracy and structured exploration. Specifically, for enhanced accuracy, KNOWNET extracts triples (e.g., entities and their relations) from LLM outputs and maps them into the validated information and supported evidence in external KGs. For structured exploration, KNOWNET provides next-step recommendations based on the neighborhood of the currently explored entities in KGs, aiming to guide a comprehensive understanding without overlooking critical aspects. To enable reasoning with both the structured data in KGs and the unstructured outputs from LLMs, KNOWNET conceptualizes the understanding of a subject as the gradual construction of graph visualization. A progressive graph visualization is introduced to monitor past inquiries, and bridge the current query with the exploration history and next-step recommendations. We demonstrate the effectiveness of our system via use cases and expert interviews.",
        "issn": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "keywords": {
            "IEEE Keywords": [
                "Knowledge graphs",
                "Visualization",
                "Alzheimer's disease",
                "Accuracy",
                "Data visualization",
                "Large language models",
                "Electronic mail"
            ],
            "Author Keywords": [
                "Human-AI interactions",
                "knowledge graph",
                "conversational agent",
                "large language model",
                "progressive visualization"
            ]
        },
        "universities": "Medical School; Department of Computer Science and Engineering",
        "countries": "USA",
        "locations": [
            "Department of Computer Science and Engineering, University of Minnesota, Twin Cities, MN, USA",
            "Medical School, University of Minnesota, Twin Cities, MN, USA",
            "Medical School, University of Minnesota, Twin Cities, MN, USA",
            "Medical School, University of Minnesota, Twin Cities, MN, USA",
            "Department of Computer Science and Engineering, University of Minnesota, Twin Cities, MN, USA"
        ],
        "title": "KNOWNET: Guided Health Information Seeking from LLMs via Knowledge Graph Integration"
    },
    {
        "authors": [
            "Sakina Fatima",
            "Hadi Hemmati",
            "Lionel Briand"
        ],
        "published_in": "Published in: IEEE Transactions on Software Engineering ( Early Access )",
        "date_of_publication": "02 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/TSE.2024.3472476",
        "publisher": "IEEE",
        "abstract": "Flaky tests are problematic because they non-deterministically pass or fail for the same software version under test, causing confusion and wasting development effort. While machine learning models have been used to predict flakiness and its root causes, there is much less work on providing support to fix the problem. To address this gap, in this paper, we focus on predicting the type of fix that is required to remove flakiness and then repair the test code on that basis. We do this for a subset of flaky tests where the root cause of flakiness is in the test itself and not in the production code. One key idea is to guide the repair process with additional knowledge about the test’s flakiness in the form of its predicted fix category. Thus, we first propose a framework that automatically generates labeled datasets for 13 fix categories and trains models to predict the fix category of a flaky test by analyzing the test code only. Our experimental results using code models and few-shot learning show that we can correctly predict most of the fix categories. To show the usefulness of such fix category labels for automatically repairing flakiness, we augment the prompts of GPT 3.5 Turbo, a Large Language Model (LLM), with such extra knowledge to request repair suggestions. The results show that our suggested fix category labels, complemented with in-context learning, significantly enhance the capability of GPT 3.5 Turbo in generating fixes for flaky tests. Based on the execution and analysis of a sample of GPT-repaired flaky tests, we estimate that a large percentage of such repairs, (roughly between 51% and 83%) can be expected to pass. For the failing repaired tests, on average, 16% of the test code needs to be further changed for them to pass.",
        "issn": {
            "Print ISSN": "0098-5589",
            "Electronic ISSN": "1939-3520"
        },
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Predictive models",
                "Maintenance engineering",
                "Analytical models",
                "Production",
                "Large language models",
                "Java",
                "Few shot learning",
                "Python",
                "Manuals"
            ],
            "Author Keywords": [
                "Flaky Tests",
                "Fix Category",
                "Test Repair",
                "Large Language Models",
                "Code Models",
                "Few Shot Learning",
                "Software Testing"
            ]
        },
        "universities": "School of EECS; Electrical Engineering and Computer Science Department",
        "countries": "Canada",
        "locations": [
            "School of EECS, University of Ottawa, Canada",
            "Electrical Engineering and Computer Science Department, York University, Canada",
            "School of EECS, University of Ottawa, Canada"
        ],
        "title": "FlakyFix: Using Large Language Models for Predicting Flaky Test Fix Categories and Test Code Repair"
    },
    {
        "authors": [
            "Yaru Zhao",
            "Yi Yue",
            "Shoulu Hou",
            "Bo Cheng",
            "Yakun Huang"
        ],
        "published_in": "Published in: IEEE Transactions on Cognitive Communications and Networking ( Early Access )",
        "date_of_publication": "16 May 2024",
        "publication_month": "May",
        "publication_year": 2024,
        "doi": "10.1109/TCCN.2024.3401712",
        "publisher": "IEEE",
        "abstract": "The advancement of artificial intelligence (AI) has the potential to revolutionize network communication. The use of advanced feature extraction in semantic communication can enhance transmission capacity. However, relying solely on unimodal visual characteristics derived from images through these approaches may result in inaccuracies in decoding under low signal-to-noise ratio (SNR) conditions. This paper introduces LaMoSC, a semantic communication system driven by large language models (LLMs) that uses multimodal features to reconstruct raw visual information, thereby improving transmission quality. The system proposes an LLM-driven multimodal fusion semantic communication framework, which aims to expand unimodal transmission systems and enhance generalization ability. LaMoSC has designed an end-to-end encoding-decoding network that integrates visual and textual multimodal feature inputs. The design deeply integrates modal features using the attention mechanism. Comprehensive comparisons with state-of-the-art baselines across various datasets demonstrate the robustness of the proposed method, particularly highlighting its superiority in low SNR conditions. LaMoSC outperforms Deep-JSCC and multi-level semantic aware communication system (MLSC) by 5.5% and 2.6%, respectively, under low SNR conditions, such as 4 dB. Its exceptional generalization capacity sets it apart from other methods.",
        "issn": {
            "Electronic ISSN": "2332-7731"
        },
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Feature extraction",
                "Image reconstruction",
                "Communication systems",
                "Visualization",
                "Signal to noise ratio",
                "Decoding"
            ],
            "Author Keywords": [
                "Semantic communication",
                "large language models",
                "multimodal fusion",
                "robust reconstruction"
            ]
        },
        "universities": "State Key Laboratory of Networking and Switching Technology",
        "countries": "China",
        "locations": [
            "State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China",
            "State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China",
            "State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China",
            "State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China",
            "State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China"
        ],
        "title": "LaMoSC: Large Language Model-Driven Semantic Communication System for Visual Transmission"
    },
    {
        "authors": [
            "Hyeongwon Jang",
            "June Yong Yang",
            "Jaeryong Hwang",
            "Eunho Yang"
        ],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "07 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/ACCESS.2024.3475471",
        "publisher": "IEEE",
        "abstract": "Time series classification requires specialized models that can effectively capture temporal structures. Consequently, Large Language Models (LLMs) have emerged as promising candidates due to their proficiency in sequence modeling and semantic reasoning. However, converting time series data into text results in sequences that exceed the maximum token limit, necessitating truncation or the removal of word embeddings for fixed-length time series embeddings. This restriction not only sacrifices semantic reasoning capabilities accessed through natural language but also limits the ability to handle temporal irregularities. To overcome these challenges, we propose the Language-Scaffolded Time Series Transformer (LSTST), which combines linguistic components and time series embeddings to effectively harness LLMs while overcoming dimensional constraints. Our Language Scaffold reformulates time series classification as a contextual question-answering task, with time series embeddings as context, facilitating the LLM to utilize its inherent semantic knowledge. Moreover, the preserved linguistic structure allows a dynamic number of input context embeddings with real-time positional encoding, handling length restrictions and irregularity in the temporal dimension. Through experiments, we show that LSTST achieves state-of-the-art performance on regular time series classification and also handles irregular time series without any model modifications.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Time series analysis",
                "Transformers",
                "Linguistics",
                "Large language models",
                "Semantics",
                "Cognition",
                "Predictive models",
                "Vectors",
                "Sensors",
                "Encoding",
                "Artificial neural networks",
                "Classification algorithms"
            ],
            "Author Keywords": [
                "Artificial neural networks",
                "deep learning",
                "irregular time series classification",
                "pre-trained language models",
                "time series classification"
            ]
        },
        "universities": "Department of Cyber Science; Kim Jaechul Graduate School of Artificial Intelligence; Department of Mathematical Sciences",
        "countries": "Republic of Korea; South Korea",
        "locations": [
            "Department of Mathematical Sciences, Seoul National University, Seoul, South Korea",
            "Kim Jaechul Graduate School of Artificial Intelligence, KAIST 291, Daehak-ro, Yuseong-gu, Daejeon, Republic of Korea",
            "Department of Cyber Science, Republic of Korea Naval Academy, 1 Jungwon-ro, Jinhae-gu, Changwon, Republic of Korea",
            "Kim Jaechul Graduate School of Artificial Intelligence, KAIST 291, Daehak-ro, Yuseong-gu, Daejeon, Republic of Korea"
        ],
        "title": "Time Series Classification with Large Language Models via Linguistic Scaffolding"
    },
    {
        "authors": [
            "Yanshu Wang",
            "Jinyi Zhang",
            "Tianrong Shi",
            "Dashuai Deng",
            "Ye Tian",
            "Tadahiro Matsumoto"
        ],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "28 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/ACCESS.2024.3487352",
        "publisher": "IEEE",
        "abstract": "This paper explores the role of Large Language Models (LLMs) in revolutionizing interactive Machine Translation (MT), providing a comprehensive analysis across nine innovative research directions. LLMs demonstrate exceptional capabilities in handling complex tasks through advanced text generation and interactive human-machine collaboration, significantly enhancing translation accuracy and efficiency, especially in low-resource language scenarios. This study also outlines potential advancements in LLM applications, emphasizing the integration of domain-specific knowledge and the exploration of model combinations to optimize performance. Future research is suggested to focus on enhancing model adaptability to diverse linguistic environments and refining human-machine interaction frameworks to better serve practical translation needs. The findings contribute to the ongoing discourse on the strategic deployment of MT with LLMs, aiming to direct future developments towards more robust and nuanced language processing solutions.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Machine translation",
                "Chatbots",
                "Transformers",
                "Adaptation models",
                "Accuracy",
                "Privacy",
                "Large language models",
                "Context modeling",
                "Tuning"
            ],
            "Author Keywords": [
                "machine translation",
                "large language models",
                "pre-trained language model",
                "in-context learning",
                "post-editing"
            ]
        },
        "universities": "Art and Design College; Faculty of Engineering; School of Information Science and Engineering; Zhuzhou CRRC Times Electric Co.",
        "countries": "Japan; China",
        "locations": [
            "Art and Design College, Shenyang Ligong University, Shenyang, China",
            "School of Information Science and Engineering, Shenyang Ligong University, Shenyang, China",
            "School of Information Science and Engineering, Shenyang Ligong University, Shenyang, China",
            "School of Information Science and Engineering, Shenyang Ligong University, Shenyang, China",
            "Zhuzhou CRRC Times Electric Co., Ltd, Zhuzhou, China",
            "Faculty of Engineering, Gifu University, Gifu, Japan"
        ],
        "title": "Recent Advances in Interactive Machine Translation with Large Language Models"
    },
    {
        "authors": [
            "Chunggi Lee",
            "Tica Lin",
            "Hanspeter Pfister",
            "Chen Zhu-Tian"
        ],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "10 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/TVCG.2024.3456332",
        "publisher": "IEEE",
        "abstract": "As basketball's popularity surges, fans often find themselves confused and overwhelmed by the rapid game pace and complexity. Basketball tactics, involving a complex series of actions, require substantial knowledge to be fully understood. This complexity leads to a need for additional information and explanation, which can distract fans from the game. To tackle these challenges, we present Sportify, a Visual Question Answering system that integrates narratives and embedded visualization for demystifying basketball tactical questions, aiding fans in understanding various game aspects. We propose three novel action visualizations (i.e., Pass, Cut, and Screen) to demonstrate critical action sequences. To explain the reasoning and logic behind players' actions, we leverage a large-language model (LLM) to generate narratives. We adopt a storytelling approach for complex scenarios from both first and third-person perspectives, integrating action visualizations. We evaluated Sportify with basketball fans to investigate its impact on understanding of tactics, and how different personal perspectives of narratives impact the understanding of complex tactic with action visualizations. Our evaluation with basketball fans demonstrates Sportify's capability to deepen tactical insights and amplify the viewing experience. Furthermore, third-person narration assists people in getting in-depth game explanations while first-person narration enhances fans' game engagement",
        "issn": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "keywords": {
            "IEEE Keywords": [
                "Games",
                "Visualization",
                "Fans",
                "Sports",
                "Data visualization",
                "Trajectory",
                "Pipelines"
            ],
            "Author Keywords": [
                "Embedded Visualization",
                "Narrative and storytelling",
                "Basketball tactic",
                "Question-answering (QA) system"
            ]
        },
        "universities": "CSE department; John A. Paulson School of Engineering and Applied Sciences",
        "countries": "USA",
        "locations": [
            "John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, USA",
            "John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, USA",
            "John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, USA",
            "CSE department, University of Minnesota, Minneapolis, MN, USA"
        ],
        "title": "Sportify: Question Answering with Embedded Visualizations and Personified Narratives for Sports Video"
    },
    {
        "authors": [
            "Edyta Bogucka",
            "Marios Constantinides",
            "Sanja Šćepanović",
            "Daniele Quercia"
        ],
        "published_in": "Published in: IEEE Internet Computing ( Early Access )",
        "date_of_publication": "02 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/MIC.2024.3451351",
        "publisher": "IEEE",
        "abstract": "Impact assessment reports for high-risk AI systems will be legally required but challenging to complete, especially for smaller companies. That is because the current process is complex, costly, and relies on guidebooks with limited assistance. We propose AI Design , a semi-automatic framework for populating these reports. It consists of two components: (A) StakeLinker , an interactive tool combining various stakeholders’ perspectives; and (B) FillGen , an LLM-based tool processing stakeholders’ perspectives and producing the report to be reviewed by regulatory experts. We conducted two user studies: the first with 13 AI practitioners who confirmed StakeLinker’s effectiveness in gathering comprehensive input for impact assessment; the second with 8 additional practitioners who successfully evaluated a report for a crime analysis system pre-populated by FillGen . For generalizability purposes, we provide reports for two other AI systems.",
        "issn": {
            "Print ISSN": "1089-7801",
            "Electronic ISSN": "1941-0131"
        },
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Stakeholders",
                "Prevention and mitigation",
                "Internet",
                "Prototypes",
                "Companies",
                "Risk mitigation"
            ],
            "Author Keywords": []
        },
        "universities": "Nokia Bell Labs",
        "countries": "UK",
        "locations": [
            "Nokia Bell Labs, Cambridge, UK",
            "Nokia Bell Labs, Cambridge, UK",
            "Nokia Bell Labs, Cambridge, UK",
            "Nokia Bell Labs, Cambridge, UK"
        ],
        "title": "AI Design: A Responsible AI Framework for Impact Assessment Reports"
    },
    {
        "authors": [
            "Chao He",
            "Yuntao Wang",
            "Juan Hu",
            "Tom H. Luan",
            "Yuanguo Bi",
            "Zhou Su"
        ],
        "published_in": "Published in: IEEE Transactions on Intelligent Transportation Systems ( Early Access )",
        "date_of_publication": "26 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/TITS.2024.3461855",
        "publisher": "IEEE",
        "abstract": "The rapid development of the Internet of Vehicles (IoV) has spurred innovations in Intelligent Transportation Systems (ITS), but it also faces increasingly sophisticated cybersecurity threats. Traditional defense mechanisms often fall short in handling emerging and complex attacks due to the lack of flexibility to adapt to the rapidly evolving IoV environment. An emerging solution is to employ Large Language Models (LLMs), such as ChatGPT, to enhance IoV security, which depends on the quality, quantity, and freshness of the threat data used for fine-tuning. In this paper, we introduce a collaborative vehicular threat sharing framework that utilizes vehicular honeypots to gather threat data for fine-tuning LLMs, thereby bolstering IoV security. Local differential privacy is leveraged to safeguard the vehicles’ privacy. Given that vehicles have different privacy preferences that may change over time, it is critical to design an appropriate incentive mechanism to encourage sustainable participation in the dynamic IoV environment. Moreover, since privacy preferences are the private information of the vehicles, an information asymmetry exists between the vehicles and the IDS cloud server. To address this challenge, we propose a dynamic contract-based incentive mechanism that considers the dynamically changing privacy preference during long-term participation. The optimal contract is derived to maximize the expected utility of the IDS cloud server. Extensive simulation results demonstrate the feasibility of our proposed dynamic contract based incentive mechanism and validate the effectiveness of the LLM-based threat classification in handling complex threats.",
        "issn": {
            "Print ISSN": "1524-9050",
            "Electronic ISSN": "1558-0016"
        },
        "keywords": {
            "IEEE Keywords": [
                "Privacy",
                "Contracts",
                "Vehicle dynamics",
                "Security",
                "Collaboration",
                "Costs",
                "Servers"
            ],
            "Author Keywords": [
                "Internet of Vehicles",
                "vehicular honeypot",
                "dynamic contract theory",
                "privacy-preserving",
                "incentive mechanism"
            ]
        },
        "universities": "School of Computer Science and Engineering; National Key Laboratory of Radar Signal Processing; School of Cyber Engineering; School of Cyber Science and Engineering",
        "countries": "China",
        "locations": [
            "School of Cyber Engineering, Xidian University, Xi’an, China",
            "School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China",
            "National Key Laboratory of Radar Signal Processing, Xidian University, Xi’an, China",
            "School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China",
            "School of Computer Science and Engineering, Northeastern University, Shenyang, China",
            "School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China"
        ],
        "title": "Collaborative Vehicular Threat Sharing: A Long-Term Contract-Based Incentive Mechanism With Privacy Preservation"
    },
    {
        "authors": [
            "Huichen Will Wang",
            "Mitchell Gordon",
            "Leilani Battle",
            "Jeffrey Heer"
        ],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "16 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/TVCG.2024.3456350",
        "publisher": "IEEE",
        "abstract": "Trained on vast corpora, Large Language Models (LLMs) have the potential to encode visualization design knowledge and best practices. However, if they fail to do so, they might provide unreliable visualization recommendations. What visualization design preferences, then, have LLMs learned? We contribute DracoGPT, a method for extracting, modeling, and assessing visualization design preferences from LLMs. To assess varied tasks, we develop two pipelines—DracoGPT-Rank and DracoGPT-Recommend—to model LLMs prompted to either rank or recommend visual encoding specifications. We use Draco as a shared knowledge base in which to represent LLM design preferences and compare them to best practices from empirical research. We demonstrate that DracoGPT can accurately model the preferences expressed by LLMs, enabling analysis in terms of Draco design constraints. Across a suite of backing LLMs, we find that DracoGPT-Rank and DracoGPT-Recommend moderately agree with each other, but both substantially diverge from guidelines drawn from human subjects experiments. Future work can build on our approach to expand Draco's knowledge base to model a richer set of preferences and to provide a robust and cost-effective stand-in for LLMs.",
        "issn": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Knowledge based systems",
                "Best practices",
                "Vectors",
                "Training data",
                "Costs",
                "Visualization"
            ],
            "Author Keywords": [
                "Visualization",
                "Large Language Models",
                "Visualization Recommendation",
                "Graphical Perception"
            ]
        },
        "universities": "University of Washington",
        "countries": "USA",
        "locations": [
            "University of Washington, USA",
            "University of Washington, USA",
            "University of Washington, USA",
            "University of Washington, USA"
        ],
        "title": "DracoGPT: Extracting Visualization Design Preferences from Large Language Models"
    },
    {
        "authors": [
            "Xuran Wang",
            "Xinguang Zhang",
            "Vanessa Hoo",
            "Zhouhang Shao",
            "Xuguang Zhang"
        ],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "12 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/ACCESS.2024.3496666",
        "publisher": "IEEE",
        "abstract": "Legal judgment prediction (LJP) presents a formidable challenge in artificial intelligence, demanding intricate comprehension of legal texts, nuanced interpretation of statutes, and complex reasoning over multifaceted case elements. While recent advancements in natural language processing have shown promise, existing approaches often struggle to capture the sophisticated interplay between facts, legal principles, and precedents that characterize legal decision-making. This paper introduces LegalReasoner, a novel multi-stage framework that leverages large language models (LLMs) and integrates domain-specific knowledge for enhanced legal judgment prediction. Our approach encompasses four key stages: (1) legal knowledge infusion, where we pre-train an LLM on a vast corpus of legal literature using contrastive learning techniques; (2) case-law retrieval, employing a graph neural network to identify relevant precedents and statutes; (3) multi-hop reasoning, utilizing a transformer-based architecture with a hierarchical attention mechanism to navigate complex legal arguments; and (4) judgment synthesis, where we employ a generative adversarial network to produce coherent and legally sound judgments. We evaluate LegalReasoner on two diverse datasets: the European Court of Human Rights (ECHR) cases and the Chinese AI and Law Challenge (CAIL2018). Our framework demonstrates substantial improvements over state-of-the-art baselines, achieving an average accuracy increase of 7.8% across all datasets. Furthermore, we conduct extensive ablation studies and interpretability analyses to elucidate the contributions of each component and provide insights into the model’s decision-making process. Our work not only advances the field of automated legal reasoning but also offers a transparent and explainable system that could serve as a valuable tool for legal professionals. By bridging the gap between AI and legal expertise, LegalReasoner paves the way for more efficient, consistent, a...",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Law",
                "Cognition",
                "Artificial intelligence",
                "Predictive models",
                "Natural language processing",
                "Decision making",
                "Large language models",
                "Transformers",
                "Contrastive learning",
                "Knowledge based systems"
            ],
            "Author Keywords": [
                "Legal Judgment Prediction",
                "Large Language Models",
                "Knowledge Integration",
                "Multi-hop Reasoning"
            ]
        },
        "universities": "The University of Gloucestershire; University of California; Georgia Institute of Technology; The University of Texas; University of Pennsylvania",
        "countries": "USA; UK",
        "locations": [
            "University of Pennsylvania, Pennsylvania, USA",
            "The University of Texas, Dallas, Texas, USA",
            "Georgia Institute of Technology, Georgia, USA",
            "University of California, San Diego, California, USA",
            "The University of Gloucestershire, Cheltenham, UK"
        ],
        "title": "LegalReasoner: A Multi-Stage Framework for Legal Judgment Prediction via Large Language Models and Knowledge Integration"
    },
    {
        "authors": [
            "Xu Han",
            "Qiannan Yang",
            "Xianda Chen",
            "Zhenghan Cai",
            "Xiaowen Chu",
            "Meixin Zhu"
        ],
        "published_in": "Published in: IEEE Transactions on Intelligent Vehicles ( Early Access )",
        "date_of_publication": "24 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/TIV.2024.3485964",
        "publisher": "IEEE",
        "abstract": "Autonomous driving technology has made significant strides, with reinforcement learning (RL) proving crucial due to its superior decision-making capabilities. However, designing effective reward functions for RL in autonomous driving remains challenging due to the limitations of manual design, generalization issues, multidimensional complexity, and difficulties in quantification. This paper introduces AutoReward, a novel closed-loop framework that leverages large language models (LLMs) to automatically generate and optimize reward functions tailored for autonomous driving tasks. In this method, we guide the LLM to create reward functions from input task and environment code, and then iteratively refine these designs based on feedback collected from training the RL agent. The framework integrates Chain-of-Thought-based Environment Code Analysis and Task Requirements Decomposition modules to enhance the usability and effectiveness of the generated reward functions. Our approach reduces the complexity and time costs associated with manual design and demonstrates strong generalization across diverse traffic scenarios, including highways, intersections, and roundabouts. Extensive experiments show that our method improves key performance indicators, such as success rate and average success steps, by 15% to 30% compared to human-designed reward functions. Additionally, the framework exhibits broad adaptability with various LLMs and RL algorithms, marking a significant advancement in autonomous driving.",
        "issn": {
            "Electronic ISSN": "2379-8904",
            "Print ISSN": "2379-8858"
        },
        "keywords": {
            "IEEE Keywords": [
                "Autonomous vehicles",
                "Codes",
                "Decision making",
                "Intelligent vehicles",
                "Complexity theory",
                "Safety",
                "Training",
                "Manuals",
                "Large language models",
                "Costs"
            ],
            "Author Keywords": [
                "Reward Design",
                "Large Language Models",
                "Autonomous Driving",
                "Reinforcement Learning",
                "Automatic Generation"
            ]
        },
        "universities": "Data Science and Analytics Thrust; Intelligent Transportation Thrust; Department of Automation",
        "countries": "China",
        "locations": [
            "Data Science and Analytics Thrust, Information Hub, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",
            "Intelligent Transportation Thrust, Systems Hub, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",
            "Intelligent Transportation Thrust, Systems Hub, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",
            "Department of Automation, School of Electrical Automation and Information Engineering, Tianjin University, Tianjin, China",
            "Data Science and Analytics Thrust, Information Hub, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",
            "Intelligent Transportation Thrust, Systems Hub, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China"
        ],
        "title": "AutoReward: Closed-Loop Reward Design with Large Language Models for Autonomous Driving"
    },
    {
        "authors": [
            "Gavin S. Black",
            "Bhaskar P. Rimal",
            "Varghese Mathew Vaidyan"
        ],
        "published_in": "Published in: IEEE Transactions on Emerging Topics in Computational Intelligence ( Early Access )",
        "date_of_publication": "29 August 2024",
        "publication_month": "August",
        "publication_year": 2024,
        "doi": "10.1109/TETCI.2024.3446695",
        "publisher": "IEEE",
        "abstract": "Large language models (LLMs) continue to be adopted for a multitude of previously manual tasks, with code generation as a prominent use. Multiple commercial models have seen wide adoption due to the accessible nature of the interface. Simple prompts can lead to working solutions that save developers time. However, the generated code has a significant challenge with maintaining security. There are no guarantees on code safety, and LLM responses can readily include known weaknesses. To address this concern, our research examines different prompt types for shaping responses from code generation tasks to produce safer outputs. The top set of common weaknesses is generated through unconditioned prompts to create vulnerable code across multiple commercial LLMs. These inputs are then paired with different contexts, roles, and identification prompts intended to improve security. Our findings show that the inclusion of appropriate guidance reduces vulnerabilities in generated code, with the choice of model having the most significant effect. Additionally, timings are presented to demonstrate the efficiency of singular requests that limit the number of model interactions.",
        "issn": {
            "Electronic ISSN": "2471-285X"
        },
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Security",
                "Testing",
                "Task analysis",
                "Software",
                "Logic",
                "Computational intelligence"
            ],
            "Author Keywords": [
                "Code generation",
                "code security",
                "CWE",
                "large language models",
                "prompt engineering",
                "vulnerability"
            ]
        },
        "universities": "Department of Computer Science; Beacom College of Computer and Cyber Sciences",
        "countries": "USA",
        "locations": [
            "Beacom College of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA",
            "Department of Computer Science, University of Idaho, Moscow, ID, USA",
            "Beacom College of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA"
        ],
        "title": "Balancing Security and Correctness in Code Generation: An Empirical Study on Commercial Large Language Models"
    },
    {
        "authors": [
            "Jin Li",
            "Yiyan Deng",
            "Qi Sun",
            "Junjie Zhu",
            "Yu Tian",
            "Jingsong Li",
            "Tingting Zhu"
        ],
        "published_in": "Published in: IEEE Journal of Biomedical and Health Informatics ( Early Access )",
        "date_of_publication": "21 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/JBHI.2024.3483816",
        "publisher": "IEEE",
        "abstract": "Evidence-based medicine (EBM) represents a paradigm of providing patient care grounded in the most current and rigorously evaluated research. Recent advances in large language models (LLMs) offer a potential solution to transform EBM by automating labor-intensive tasks and thereby improving the efficiency of clinical decision-making. This study explores integrating LLMs into the key stages in EBM, evaluating their ability across evidence retrieval (PICO extraction, biomedical question answering), synthesis (summarizing randomized controlled trials), and dissemination (medical text simplification). We conducted a comparative analysis of seven LLMs, including both proprietary and open-source models, as well as those fine-tuned on medical corpora. Specifically, we benchmarked the performance of various LLMs on each EBM task under zero-shot settings as baselines, and employed prompting techniques, including in-context learning, chain-of-thought reasoning, and knowledge-guided prompting to enhance their capabilities. Our extensive experiments revealed the strengths of LLMs, such as remarkable understanding capabilities even in zero-shot settings, strong summarization skills, and effective knowledge transfer via prompting. Promoting strategies such as knowledge-guided prompting proved highly effective (e.g., improving the performance of GPT-4 by 13.10% over zero-shot in PICO extraction). However, the experiments also showed limitations, with LLM performance falling well below state-of-the-art baselines like PubMedBERT in handling named entity recognition tasks. Moreover, human evaluation revealed persisting challenges with factual inconsistencies and domain inaccuracies, underscoring the need for rigorous quality control before clinical application. This study provides insights into enhancing EBM using LLMs while highlighting critical areas for further research. The code is publicly available on Github.",
        "issn": {
            "Print ISSN": "2168-2194",
            "Electronic ISSN": "2168-2208"
        },
        "keywords": {
            "IEEE Keywords": [
                "Medical services",
                "Sleep",
                "Question answering (information retrieval)",
                "Prompt engineering",
                "Large language models",
                "Bioinformatics",
                "Diseases",
                "Cognition",
                "Biological system modeling",
                "Benchmark testing"
            ],
            "Author Keywords": [
                "Large language models",
                "evidence-based medicine",
                "clinical NLP",
                "Prompt engineering"
            ]
        },
        "universities": "Institute for AI in Medicine; Institute of Biomedical Engineering; Engineering Research Center of EMR and Intelligent Expert System; Department of Pathology",
        "countries": "U.K.; China",
        "locations": [
            "Institute for AI in Medicine, School of Artificial Intelligence, Nanjing University of Information Science and Technology, Nanjing, China",
            "Institute for AI in Medicine, School of Artificial Intelligence, Nanjing University of Information Science and Technology, Nanjing, China",
            "Department of Pathology, Nanjing Drum Tower Hospital, The Affiliated Hospital of Nanjing University Medical School, Nanjing, China",
            "Institute for AI in Medicine, School of Artificial Intelligence, Nanjing University of Information Science and Technology, Nanjing, China",
            "Engineering Research Center of EMR and Intelligent Expert System, Ministry of Education, College of Biomedical Engineering and Instrument Science, Zhejiang University, Hangzhou, China",
            "Engineering Research Center of EMR and Intelligent Expert System, Ministry of Education, College of Biomedical Engineering and Instrument Science, Zhejiang University, Hangzhou, China",
            "Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Oxford, U.K."
        ],
        "title": "Benchmarking Large Language Models in Evidence-Based Medicine"
    },
    {
        "authors": [
            "Wenji Fang",
            "Yao Lu",
            "Shang Liu",
            "Qijun Zhang",
            "Ceyu Xu",
            "Lisa Wu Wills",
            "Hongce Zhang",
            "Zhiyao Xie"
        ],
        "published_in": "Published in: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems ( Early Access )",
        "date_of_publication": "01 July 2024",
        "publication_month": "July",
        "publication_year": 2024,
        "doi": "10.1109/TCAD.2024.3420904",
        "publisher": "IEEE",
        "abstract": "In modern VLSI design flow, evaluating the quality of register-transfer level (RTL) designs involves time-consuming logic synthesis using EDA tools, a process that often slows down early optimization. While recent machine learning solutions offer some advancements, they typically struggle with maintaining high accuracy across any given RTL design. In this work, we propose an innovative transferable pre-synthesis PPA estimation framework named MasterRTL. It first converts the HDL code to a new bit-level design representation named the simple operator graph (SOG). By only adopting single-bit simple operators, this SOG proves to be a general representation that unifies different design types and styles. The SOG is also more similar to the target gate-level netlist, reducing the gap between RTL representation and netlist. In addition to the new SOG representation, Master-RTL proposes new ML methods for the RTL-stage modeling of timing, power, and area separately. Compared with state-of-theart solutions, the experiment on a comprehensive dataset with 90 different designs shows accuracy improvement by 0.33, 0.22, and 0.15 in correlation for total negative slack (TNS), worst negative slack (WNS), and power, respectively. Besides the prediction of synthesis results, MasterRTL also excels in accurately predicting layout-stage PPA based on RTL designs and in adapting across different technology nodes and process corners. Furthermore, we investigate two effective data augmentation techniques: a graph generation method and a Large Language Model (LLM)-based approach. Our results validate the effectiveness of the generated RTL designs in mitigating data shortage challenges.",
        "issn": {
            "Print ISSN": "0278-0070",
            "Electronic ISSN": "1937-4151"
        },
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Layout",
                "Timing",
                "Data augmentation",
                "Codes",
                "Predictive models",
                "Logic gates"
            ],
            "Author Keywords": [
                "register-transfer level",
                "timing analysis",
                "power modeling",
                "data augmentation"
            ]
        },
        "universities": "Department of Electronic and Computer Engineering; Department of Computer Science and Electrical and Computer Engineering",
        "countries": "USA; China",
        "locations": [
            "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
            "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
            "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
            "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
            "Department of Computer Science and Electrical and Computer Engineering, Duke University, Durham, NC, USA",
            "Department of Computer Science and Electrical and Computer Engineering, Duke University, Durham, NC, USA",
            "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
            "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China"
        ],
        "title": "Transferable Pre-Synthesis PPA Estimation for RTL Designs With Data Augmentation Techniques"
    },
    {
        "authors": [
            "Alexander Bendeck",
            "John Stasko"
        ],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "10 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/TVCG.2024.3456155",
        "publisher": "IEEE",
        "abstract": "Large Language Models (LLMs) like GPT-4 which support multimodal input (i.e., prompts containing images in addition to text) have immense potential to advance visualization research. However, many questions exist about the visual capabilities of such models, including how well they can read and interpret visually represented data. In our work, we address this question by evaluating the GPT-4 multimodal LLM using a suite of task sets meant to assess the model's visualization literacy. The task sets are based on existing work in the visualization community addressing both automated chart question answering and human visualization literacy across multiple settings. Our assessment finds that GPT-4 can perform tasks such as recognizing trends and extreme values, and also demonstrates some understanding of visualization design best-practices. By contrast, GPT-4 struggles with simple value retrieval when not provided with the original dataset, lacks the ability to reliably distinguish between colors in charts, and occasionally suffers from hallucination and inconsistency. We conclude by reflecting on the model's strengths and weaknesses as well as the potential utility of models like GPT-4 for future visualization research. We also release all code, stimuli, and results for the task sets at the following link: https://doi.org/10.17605/OSF.IO/F39J6",
        "issn": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Visualization",
                "Question answering (information retrieval)",
                "Data models",
                "Computational modeling",
                "Education",
                "Codes"
            ],
            "Author Keywords": [
                "Visualization Literacy",
                "Large Language Models",
                "Natural Language"
            ]
        },
        "universities": "Georgia Institute of Technology",
        "countries": "USA",
        "locations": [
            "Georgia Institute of Technology, USA",
            "Georgia Institute of Technology, USA"
        ],
        "title": "An Empirical Evaluation of the GPT-4 Multimodal Language Model on Visualization Literacy Tasks"
    },
    {
        "authors": [
            "Liao Bingli",
            "Danilo Vasconcellos Vargas"
        ],
        "published_in": "Published in: IEEE Transactions on Games ( Early Access )",
        "date_of_publication": "24 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/TG.2024.3466898",
        "publisher": "IEEE",
        "abstract": "In the realm of RPGs, creating immersive, persona-driven dialogues remains a challenge, especially in intricate settings like Call of Cthulhu (CoC). Existing methodologies often falter in portraying character personas within complex conversations accurately. To address this, we introduce a novel card-based framework, utilizing the advanced 7B language model for tailored dialogue generation. Guided by detailed scene settings and character personas, 7B language model exhibited a striking ability to craft context-aware dialogues for even unseen characters and scenarios. To assess the quality of these dialogues, we present an innovative metric, circumventing the traditional hurdles of human evaluations. Furthermore, insights into the attention mechanism shed light on the dynamics of information flow during dialogue creation. Collectively, our findings underscore the transformative potential of large language models in computational storytelling, particularly in RPG settings. Source code: https://github.com/metacarbon/coc-llm.",
        "issn": {
            "Print ISSN": "2475-1502",
            "Electronic ISSN": "2475-1510"
        },
        "keywords": {
            "IEEE Keywords": [
                "Games",
                "Transformers",
                "Oral communication",
                "Data models",
                "Computational modeling",
                "Large language models",
                "Analytical models"
            ],
            "Author Keywords": [
                "Attention",
                "games",
                "generative models",
                "procedural content generation",
                "visual analytics"
            ]
        },
        "universities": "",
        "countries": "",
        "locations": [],
        "title": "Towards Immersive Computational Storytelling: Card-Framework for Enhanced Persona-Driven Dialogues"
    },
    {
        "authors": [
            "Lin Gao",
            "Jing Lu",
            "Zekai Shao",
            "Ziyue Lin",
            "Shengbin Yue",
            "Chiokit Ieong",
            "Yi Sun",
            "Rory James Zauner",
            "Zhongyu Wei",
            "Siming Chen"
        ],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "10 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/TVCG.2024.3456145",
        "publisher": "IEEE",
        "abstract": "Large Language Models (LLMs) have shown great potential in intelligent visualization systems, especially for domainspecific applications. Integrating LLMs into visualization systems presents challenges, and we categorize these challenges into three alignments: domain problems with LLMs, visualization with LLMs, and interaction with LLMs. To achieve these alignments, we propose a framework and outline a workflow to guide the application of fine-tuned LLMs to enhance visual interactions for domain-specific tasks. These alignment challenges are critical in education because of the need for an intelligent visualization system to support beginners' self-regulated learning. Therefore, we apply the framework to education and introduce Tailor-Mind, an interactive visualization system designed to facilitate self-regulated learning for artificial intelligence beginners. Drawing on insights from a preliminary study, we identify self-regulated learning tasks and fine-tuning objectives to guide visualization design and tuning data construction. Our focus on aligning visualization with fine-tuned LLM makes Tailor-Mind more like a personalized tutor. Tailor-Mind also supports interactive recommendations to help beginners better achieve their learning goals. Model performance evaluations and user studies confirm that Tailor-Mind improves the self-regulated learning experience, effectively validating the proposed framework.",
        "issn": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Data models",
                "Education",
                "Adaptation models",
                "Tutorials",
                "Large language models",
                "Knowledge based systems"
            ],
            "Author Keywords": [
                "Fine-tuned large language model",
                "visualization system",
                "self-regulated learning",
                "intelligent tutorial system"
            ]
        },
        "universities": "Faculty of Computer Science; School of Data Science at Fudan University",
        "countries": "Austria; China",
        "locations": [
            "School of Data Science at Fudan University, China",
            "School of Data Science at Fudan University, China",
            "School of Data Science at Fudan University, China",
            "School of Data Science at Fudan University, China",
            "School of Data Science at Fudan University, China",
            "School of Data Science at Fudan University, China",
            "School of Data Science at Fudan University, China",
            "Faculty of Computer Science, University of Vienna, Vienna, Austria",
            "School of Data Science at Fudan University, China",
            "School of Data Science at Fudan University, China"
        ],
        "title": "Fine-Tuned Large Language Model for Visualization System: A Study on Self-Regulated Learning in Education"
    },
    {
        "authors": [
            "Yusuf Mücahit Çetinkaya",
            "Yeonjung Lee",
            "Emre Külah",
            "İsmail Hakkı Toroslu",
            "Michael A. Cowan",
            "Hasan Davulcu"
        ],
        "published_in": "Published in: IEEE Internet Computing ( Early Access )",
        "date_of_publication": "29 August 2024",
        "publication_month": "August",
        "publication_year": 2024,
        "doi": "10.1109/MIC.2024.3450090",
        "publisher": "IEEE",
        "abstract": "The rise of harmful online content underscores the urgent need for AI systems to effectively detect, filter those, and foster safer and healthier communication. This article introduces a novel approach to mitigate toxic content generation propensities of Large Language Models (LLMs) by fine-tuning them with a programmable stance-directed focus on core human values and common good. We propose a streamlined keyword coding and processing pipeline to generate weakly labeled data to train AI models that can avoid toxicity and champion civil discourse. We also developed a toxicity classifier and an Aspect-based Sentiment Analysis (ABSA) model to assess and control the effectiveness of a humanizing AI model. We evaluate the proposed pipeline using a contentious real-world Twitter dataset on U.S. race relations. Our approach successfully curbs the toxic content generation propensity of an unrestricted LLM by a significant 85%.",
        "issn": {
            "Print ISSN": "1089-7801",
            "Electronic ISSN": "1941-0131"
        },
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Training",
                "Toxicology",
                "Social networking (online)",
                "Internet",
                "Blogs",
                "Analytical models"
            ],
            "Author Keywords": []
        },
        "universities": "Middle East Technical University; Arizona State University; Loyola University",
        "countries": "USA; Turkiye",
        "locations": [
            "Middle East Technical University, Ankara, Turkiye",
            "Arizona State University, Tempe, Arizona, USA",
            "Middle East Technical University, Ankara, Turkiye",
            "Middle East Technical University, Ankara, Turkiye",
            "Loyola University, New Orleans, Louisiana, USA",
            "Arizona State University, Tempe, Arizona, USA"
        ],
        "title": "Towards a Programmable Humanizing AI through Scalable Stance-Directed Architecture"
    },
    {
        "authors": [
            "Yunxin Li",
            "Baotian Hu",
            "Xinyu Chen",
            "Lin Ma",
            "Yong Xu",
            "Min Zhang"
        ],
        "published_in": "Published in: IEEE Transactions on Multimedia ( Early Access )",
        "date_of_publication": "15 July 2024",
        "publication_month": "July",
        "publication_year": 2024,
        "doi": "10.1109/TMM.2024.3428317",
        "publisher": "IEEE",
        "abstract": "Current efficient approaches to building Multimodal Large Language Models (MLLMs) mainly incorporate visual information into LLMs with a simple visual mapping network such as a linear projection layer, a multilayer perceptron (MLP), or Q-former from BLIP-2. Such networks project the image feature once and do not consider the interaction between the image and the human inputs. Hence, the obtained visual information without being connected to human intention may be inadequate for LLMs to generate intention-following responses, which we refer to as static visual information. To alleviate this issue, our paper introduces LMEye, a human-like eye with a play-and plug interactive perception network, designed to enable dynamic interaction between LLMs and external visual information. It can allow the LLM to request the desired visual information aligned with various human instructions, which we term dynamic visual information acquisition. Specifically, LMEye consists of a simple visual mapping network to provide the basic perception of an image for LLMs. It also contains additional modules responsible for acquiring requests from LLMs, performing request-based visual information seeking, and transmitting the resulting interacted visual information to LLMs, respectively. In this way, LLMs act to understand the human query, deliver the corresponding request to the request-based visual information interaction module, and generate the response based on the interleaved multimodal information. We evaluate LMEye through extensive experiments on multimodal benchmarks, demonstrating that it significantly improves zero-shot performances on various multimodal tasks compared to previous methods, with fewer parameters. Moreover, we also verify its effectiveness and scalability on various language models and video understanding, respectively.",
        "issn": {
            "Print ISSN": "1520-9210",
            "Electronic ISSN": "1941-0077"
        },
        "keywords": {
            "IEEE Keywords": [
                "Visualization",
                "Task analysis",
                "Data models",
                "Tuning",
                "Large language models",
                "Training",
                "Cognition"
            ],
            "Author Keywords": [
                "Multimodal Large Language Models",
                "VisualLanguage Learning",
                "Interactive Perception Network"
            ]
        },
        "universities": "Department of Computer Science and Technology; Meituan",
        "countries": "China",
        "locations": [
            "Department of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China",
            "Department of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China",
            "Department of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China",
            "Meituan, Beijing, China",
            "Department of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China",
            "Department of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China"
        ],
        "title": "LMEye: An Interactive Perception Network for Large Language Models"
    },
    {
        "authors": [
            "Zhengqiu Zhu",
            "Yong Zhao",
            "Sihang Qiu",
            "Kai Xu",
            "Quanjun Yin",
            "Jincai Huang",
            "Zhong Liu",
            "Fei-Yue Wang"
        ],
        "published_in": "Published in: IEEE Transactions on Computational Social Systems ( Early Access )",
        "date_of_publication": "15 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/TCSS.2024.3451649",
        "publisher": "IEEE",
        "abstract": "The transition from cyber-physical-system-based (CPS-based) Industry 4.0 to cyber-physical-social-system-based (CPSS-based) Industry 5.0 brings new requirements and opportunities to current sensing approaches, especially in light of recent progress in large language models (LLMs) and retrieval augmented generation (RAG). Therefore, the advancement of parallel intelligence powered crowdsensing intelligence (CSI) is witnessed, which is currently advancing toward linguistic intelligence. In this article, we propose a novel sensing paradigm, namely conversational crowdsensing, for Industry 5.0 (especially for social manufacturing). It can alleviate workload and professional requirements of individuals and promote the organization and operation of diverse workforce, thereby facilitating faster response and wider popularization of crowdsensing systems. Specifically, we design the architecture of conversational crowdsensing to effectively organize three types of participants (biological, robotic, and digital) from diverse communities. Through three levels of effective conversation (i.e., interhuman, human–AI, and inter-AI), complex interactions and service functionalities of different workers can be achieved to accomplish various tasks across three sensing phases (i.e., requesting, scheduling, and executing). Moreover, we explore the foundational technologies for realizing conversational crowdsensing, encompassing LLM-based multiagent systems, scenarios engineering and conversational human–AI cooperation. Finally, we present potential applications of conversational crowdsensing and discuss its implications. We envision that conversations in natural language will become the primary communication channel during crowdsensing process, enabling richer information exchange and cooperative problem-solving among humans, robots, and AI.",
        "issn": {
            "Electronic ISSN": "2329-924X"
        },
        "keywords": {
            "IEEE Keywords": [
                "Crowdsensing",
                "Robot sensing systems",
                "Sensors",
                "Fifth Industrial Revolution",
                "Robots",
                "Collaboration",
                "Oral communication",
                "Computer architecture",
                "Aerospace electronics",
                "Linguistics"
            ],
            "Author Keywords": [
                "Conversational crowdsensing",
                "crowdsensing intelligence (CSI)",
                "Industry 5.0",
                "large language models (LLMs)",
                "parallel intelligence",
                "retrieval augmented generation (RAG)"
            ]
        },
        "universities": "State Key Laboratory for Management and Control of Complex Systems; College of Systems Engineering",
        "countries": "China",
        "locations": [
            "College of Systems Engineering, National University of Defense Technology, Changsha, Hunan, China",
            "College of Systems Engineering, National University of Defense Technology, Changsha, Hunan, China",
            "College of Systems Engineering, National University of Defense Technology, Changsha, Hunan, China",
            "College of Systems Engineering, National University of Defense Technology, Changsha, Hunan, China",
            "College of Systems Engineering, National University of Defense Technology, Changsha, Hunan, China",
            "College of Systems Engineering, National University of Defense Technology, Changsha, Hunan, China",
            "College of Systems Engineering, National University of Defense Technology, Changsha, Hunan, China",
            "State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China"
        ],
        "title": "Conversational Crowdsensing in the Age of Industry 5.0: A Parallel Intelligence and Large Models Powered Novel Sensing Approach"
    },
    {
        "authors": [
            "Abdelkader Mekrache",
            "Mohamed Mekki",
            "Adlen Ksentini",
            "Bouziane Brik",
            "Christos Verikoukis"
        ],
        "published_in": "Published in: IEEE Communications Magazine ( Early Access )",
        "date_of_publication": "04 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/MCOM.002.2400276",
        "publisher": "IEEE",
        "abstract": "Zero-touch network and service management (ZSM) is a key pillar of 6G networks. It allows the 6G management and orchestration framework to operate the networks without external (e.g., human) intervention. To effectively achieve ZSM, advanced network management procedures are required to detect and resolve anomalies within the 6G network autonomously, which usually requires artificial intelligence (AI) and machine learning (ML) models. However, relying solely on AI can raise concerns about trust due to their lack of explainability. Indeed, as these models are not explainable, it is difficult to understand and trust their decisions. To overcome this limitation, this article introduces a novel pipeline for ensuring trustworthy ZSM in 6G networks by combining AI for detecting anomalies; eXplainable AI (XAI) to identify the root causes of anomalies using feature importance analysis; and large language models (LLMs) to generate user-friendly explanations and suggest/apply corrective actions to resolve anomalies. A use case is presented using XGBoost as AI, SHAP as XAI, and Llama2 as LLM to address service level agreement (SLA) latency violations within cloud-native 6G microservices. Evaluation results obtained through real experiments demonstrate the framework's efficiency in scaling cloud resources to prevent SLA violations while providing understandable explanations to users, thereby enhancing trust in the system.",
        "issn": {
            "Print ISSN": "0163-6804",
            "Electronic ISSN": "1558-1896"
        },
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "6G mobile communication",
                "Predictive models",
                "Anomaly detection",
                "Pipelines",
                "Explainable AI",
                "Service level agreements",
                "Random access memory",
                "Monitoring",
                "Microservice architectures"
            ],
            "Author Keywords": []
        },
        "universities": "",
        "countries": "",
        "locations": [],
        "title": "On Combining XAI and LLMs for Trustworthy Zero-Touch Network and Service Management in 6G"
    },
    {
        "authors": [
            "Renyou Xie",
            "Xin Yin",
            "Chaojie Li",
            "Guo Chen",
            "Nian Liu",
            "Bo Zhao",
            "Zhaoyang Dong"
        ],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "18 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/JIOT.2024.3483441",
        "publisher": "IEEE",
        "abstract": "Distribution system state estimation (DSSE) plays a crucial role in the real-time monitoring, control, and operation of distribution networks. Besides intensive computational requirements, conventional DSSE methods need high-quality measurements to obtain accurate states, whereas missing values often occur due to sensor failures or communication delays. To address these challenging issues, a forecast-then-estimate framework of edge learning is proposed for DSSE, leveraging large language models (LLMs) to forecast missing measurements and provide pseudo-measurements. Firstly, natural language-based prompts and measurement sequences are integrated by the proposed LLM to learn patterns from historical data and provide accurate forecasting results. Secondly, a convolutional layer-based neural network model is introduced to improve the robustness of state estimation under missing measurement. Thirdly, to alleviate the overfitting of the deep learning-based DSSE, it is reformulated as a multi-task learning framework containing shared and task-specific layers. The uncertainty weighting algorithm is applied to find the optimal weights to balance different tasks. The numerical simulation on the Simbench case is used to demonstrate the effectiveness of the proposed forecast-then-estimate framework.",
        "issn": {
            "Electronic ISSN": "2327-4662"
        },
        "keywords": {
            "IEEE Keywords": [
                "State estimation",
                "Voltage measurement",
                "Neural networks",
                "Accuracy",
                "Distribution networks",
                "Power measurement",
                "Training",
                "Topology",
                "Real-time systems",
                "Predictive models"
            ],
            "Author Keywords": [
                "Distribution system state estimation",
                "large language models",
                "forecasting",
                "multi-task learning"
            ]
        },
        "universities": "Department of Electrical Engineering; School of Electrical Engineering and Telecommunications; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources",
        "countries": "Australia; Hong Kong; China",
        "locations": [
            "School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, Australia",
            "School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, Australia",
            "School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, Australia",
            "School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, Australia",
            "State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, North China Electric Power University, Beijing, China",
            "State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, North China Electric Power University, Beijing, China",
            "Department of Electrical Engineering, City University of Hong Kong, Hong Kong"
        ],
        "title": "Large Language Model-Aided Edge Learning in Distribution System State Estimation"
    },
    {
        "authors": [
            "Xiaomao Zhou",
            "Yujiao Hu",
            "Qingmin Jia",
            "Renchao Xie"
        ],
        "published_in": "Published in: IEEE Sensors Journal ( Early Access )",
        "date_of_publication": "21 October 2024",
        "publication_month": "October",
        "publication_year": 2024,
        "doi": "10.1109/JSEN.2024.3480932",
        "publisher": "IEEE",
        "abstract": "Synthetic data has emerged as a critical component in the fields of machine learning and data science, providing a solution to overcome limitations associated with real-world data, including scarcity, privacy concerns, and the high cost of acquisition. While existing generative models demonstrate promising results in synthesizing various sensor data, they are struggling to enhance performance and generalization. In this paper, we introduce a Large Language Models (LLMs) driven framework that leverages the power of LLMs in concert with various domain-specific generative models (DGMs) for general sensor data synthesis. Specifically, our method employs LLMs as the core to interpret task requests, decompose a complex task into a manageable set of sub-tasks, and delegate each sub-task to the most suitable DGM, thereby automatically constructing customized data generation pipelines. Meanwhile, DGMs contribute their expertise to generate high-fidelity, domain-relevant data, whose specialized knowledge can be further enhanced by the LLM’s broad linguistic knowledge via knowledge transfer. In addition, the integration of Diffusion Model (DM) based Reinforcement Learning (RL) is promising to enhance the framework’s ability to optimally utilize DGMs, resulting in data generation with superior quality and control flexibility. Experimental results demonstrate the effectiveness of LLMs in augmenting DGMs via knowledge transfer and in facilitating multi-modal data synthesis through collaborative interactions with diverse DGMs, which is further improved by the DM-based refinement process.",
        "issn": {
            "Print ISSN": "1530-437X",
            "Electronic ISSN": "1558-1748"
        },
        "keywords": {
            "IEEE Keywords": [
                "Sensors",
                "Data models",
                "Data collection",
                "Sensor phenomena and characterization",
                "Adaptation models",
                "Synthetic data",
                "Reinforcement learning",
                "Planning",
                "Pipelines",
                "Knowledge transfer"
            ],
            "Author Keywords": [
                "Sensor data synthesis",
                "Large Language Models",
                "generative models",
                "knowledge transfer",
                "Diffusion Model",
                "Reinforcement Learning"
            ]
        },
        "universities": "State Key Laboratory of networking and Switching Technology; Future Network Research Center",
        "countries": "China",
        "locations": [
            "Future Network Research Center, Purple Mountain Laboratories, Nanjing, China",
            "Future Network Research Center, Purple Mountain Laboratories, Nanjing, China",
            "Future Network Research Center, Purple Mountain Laboratories, Nanjing, China",
            "State Key Laboratory of networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China"
        ],
        "title": "Cross-Domain Integration for General Sensor Data Synthesis: Leveraging LLMs and Domain-Specific Generative Models in Collaborative Environments"
    },
    {
        "authors": [
            "Xingsi Xue",
            "Mu-En Wu",
            "Fazlullah Khan"
        ],
        "published_in": "Published in: IEEE Journal of Biomedical and Health Informatics ( Early Access )",
        "date_of_publication": "11 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/JBHI.2024.3496495",
        "publisher": "IEEE",
        "abstract": "Integrating diverse biomedical knowledge information is essential to enhance the accuracy and efficiency of medical diagnoses, facilitate personalized treatment plans, and ultimately improve patient outcomes. However, Biomedical Information Integration (BII) faces significant challenges due to variations in terminology and the complex structure of entity descriptions across different datasets. A critical step in BII is biomedical entity alignment, which involves accurately identifying and matching equivalent entities across diverse datasets to ensure seamless data integration. In recent years, Large Language Model (LLMs), such as Bidirectional Encoder Representations from Transformers (BERTs), have emerged as valuable tools for discerning heterogeneous biomedical data due to their deep contextual embeddings and bidirectionality. However, different LLMs capture various nuances and complexity levels within the biomedical data, and none of them can ensure their effectiveness in all heterogeneous entity matching tasks. To address this issue, we propose a novel Two-Stage LLM construction (TSLLM) framework to adaptively select and combine LLMs for Biomedical Information Integration (BII). First, a Multi-Objective Genetic Programming (MOGP) algorithm is proposed for generating versatile high-level LLMs, and then, a Single-Objective Genetic Algorithm (SOGA) employs a confidence-based strategy is presented to combine the built LLMs, which can further improve the discriminative power of distinguishing heterogeneous entities. The experiment utilizes OAEI's entity matching datasets, i.e., Benchmark and Conference, along with LargeBio, Disease and Phenotype datasets to test the performance of TSLLM. The experimental findings validate the efficiency of TSLLM in adaptively differentiating heterogeneous biomedical entities, which significantly outperforms the leading entity matching techniques.",
        "issn": {
            "Print ISSN": "2168-2194",
            "Electronic ISSN": "2168-2208"
        },
        "keywords": {
            "IEEE Keywords": [
                "Bioinformatics",
                "Semantics",
                "Biological system modeling",
                "Accuracy",
                "Complexity theory",
                "Encoding",
                "Bidirectional control",
                "Optimization",
                "Large language models",
                "Terminology"
            ],
            "Author Keywords": [
                "Biomedical Information Integration",
                "Large Language Model",
                "Genetic Programming",
                "Genetic Algorithm"
            ]
        },
        "universities": "Fujian Provincial Key Laboratory of Big Data Mining and Applications; School of Computer Science; Department of Information and Finance Management",
        "countries": "Taiwan; China",
        "locations": [
            "Fujian Provincial Key Laboratory of Big Data Mining and Applications, Fujian University of Technology, Fuzhou, Fujian, China",
            "Department of Information and Finance Management, National Taipei University of Technology, Taipei, Taiwan",
            "School of Computer Science, University of Nottingham Ningbo China, Ningbo, Zhejiang, China"
        ],
        "title": "Biomedical Information Integration via Adaptive Large Language Model Construction"
    },
    {
        "authors": [
            "Xingchen Zeng",
            "Haichuan Lin",
            "Yilin Ye",
            "Wei Zeng"
        ],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "10 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/TVCG.2024.3456159",
        "publisher": "IEEE",
        "abstract": "Emerging multimodal large language models (MLLMs) exhibit great potential for chart question answering (CQA). Recent efforts primarily focus on scaling up training datasets (i.e., charts, data tables, and question-answer (QA) pairs) through data collection and synthesis. However, our empirical study on existing MLLMs and CQA datasets reveals notable gaps. First, current data collection and synthesis focus on data volume and lack consideration of fine-grained visual encodings and QA tasks, resulting in unbalanced data distribution divergent from practical CQA scenarios. Second, existing work follows the training recipe of the base MLLMs initially designed for natural images, under-exploring the adaptation to unique chart characteristics, such as rich text elements. To fill the gap, we propose a visualization-referenced instruction tuning approach to guide the training dataset enhancement and model development. Specifically, we propose a novel data engine to effectively filter diverse and high-quality data from existing datasets and subsequently refine and augment the data using LLM-based generation techniques to better align with practical QA tasks and visual encodings. Then, to facilitate the adaptation to chart characteristics, we utilize the enriched data to train an MLLM by unfreezing the vision encoder and incorporating a mixture-of-resolution adaptation strategy for enhanced fine-grained recognition. Experimental results validate the effectiveness of our approach. Even with fewer training examples, our model consistently outperforms state-of-the-art CQA models on established benchmarks. We also contribute a dataset split as a benchmark for future research. Source codes and datasets of this paper are available at https://github.com/zengxingchen/ChartQA-MLLM.",
        "issn": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "keywords": {
            "IEEE Keywords": [
                "Visualization",
                "Benchmark testing",
                "Data models",
                "Training",
                "Question answering (information retrieval)",
                "Data visualization",
                "Adaptation models"
            ],
            "Author Keywords": [
                "Chart-question answering",
                "multimodal large language models",
                "benchmark"
            ]
        },
        "universities": "Hong Kong University of Science and Technology (Guangzhou)",
        "countries": "China",
        "locations": [
            "Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",
            "Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",
            "Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",
            "Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China"
        ],
        "title": "Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning"
    },
    {
        "authors": [
            "Sam Yu-Te Lee",
            "Aryaman Bahukhandi",
            "Dongyu Liu",
            "Kwan-Liu Ma"
        ],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "09 September 2024",
        "publication_month": "September",
        "publication_year": 2024,
        "doi": "10.1109/TVCG.2024.3456398",
        "publisher": "IEEE",
        "abstract": "Recent advancements in Large Language Models (LLMs) and Prompt Engineering have made chatbot customization more accessible, significantly reducing barriers to tasks that previously required programming skills. However, prompt evaluation, especially at the dataset scale, remains complex due to the need to assess prompts across thousands of test instances within a dataset. Our study, based on a comprehensive literature review and pilot study, summarized five critical challenges in prompt evaluation. In response, we introduce a feature-oriented workflow for systematic prompt evaluation. In the context of text summarization, our workflow advocates evaluation with summary characteristics (feature metrics) such as complexity, formality, or naturalness, instead of using traditional quality metrics like ROUGE. This design choice enables a more user-friendly evaluation of prompts, as it guides users in sorting through the ambiguity inherent in natural language. To support this workflow, we introduce Awesum, a visual analytics system that facilitates identifying optimal prompt refinements for text summarization through interactive visualizations, featuring a novel Prompt Comparator design that employs a BubbleSet-inspired design enhanced by dimensionality reduction techniques. We evaluate the effectiveness and general applicability of the system with practitioners from various domains and found that (1) our design helps overcome the learning curve for non-technical people to conduct a systematic evaluation of summarization prompts, and (2) our feature-oriented workflow has the potential to generalize to other NLG and image-generation tasks. For future works, we advocate moving towards feature-oriented evaluation of LLM prompts and discuss unsolved challenges in terms of human-agent interaction",
        "issn": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "keywords": {
            "IEEE Keywords": [
                "Measurement",
                "Text summarization",
                "Prompt engineering",
                "Complexity theory",
                "Systematics",
                "Natural language generation",
                "Linguistics"
            ],
            "Author Keywords": [
                "Visual analytics",
                "prompt engineering",
                "text summarization",
                "human-computer interaction",
                "dimensionality reduction"
            ]
        },
        "universities": "University of California",
        "countries": "USA",
        "locations": [
            "University of California, Davis, USA",
            "University of California, Davis, USA",
            "University of California, Davis, USA",
            "University of California, Davis, USA"
        ],
        "title": "Towards Dataset-scale and Feature-oriented Evaluation of Text Summarization in Large Language Model Prompts"
    },
    {
        "authors": [
            "Yongshuo Zhu",
            "Lu Li",
            "Keyan Chen",
            "Chenyang Liu",
            "Fugen Zhou",
            "Zhenwei Shi"
        ],
        "published_in": "Published in: IEEE Transactions on Geoscience and Remote Sensing ( Early Access )",
        "date_of_publication": "13 November 2024",
        "publication_month": "November",
        "publication_year": 2024,
        "doi": "10.1109/TGRS.2024.3497338",
        "publisher": "IEEE",
        "abstract": "Remote sensing image change captioning (RSICC) aims to articulate the changes in objects of interest within bi-temporal remote sensing images using natural language. Given the limitations of current RSICC methods in expressing general features across multi-temporal and spatial scenarios, and their deficiency in providing granular, robust, and precise change descriptions, we introduce a novel change captioning (CC) method based on the foundational knowledge and semantic guidance, which we term Semantic-CC. Semantic-CC alleviates the dependency of high-generalization algorithms on extensive annotations by harnessing the latent knowledge of foundation models, and it generates more comprehensive and accurate change descriptions guided by pixel-level semantics from change detection (CD). Specifically, we propose a bi-temporal SAM-based encoder for dual-image feature extraction; a multi-task semantic aggregation neck for facilitating information interaction between heterogeneous tasks; a straightforward multi-scale change detection decoder to provide pixel-level semantic guidance; and a change caption decoder based on the large language model (LLM) to generate change description sentences. Moreover, to ensure the stability of the joint training of CD and CC, we propose a three-stage training strategy that supervises different tasks at various stages. We validate the proposed method on the LEVIR-CC and LEVIR-CD datasets. The experimental results corroborate the complementarity of CD and CC, demonstrating that Semantic-CC can generate more accurate change descriptions and achieve optimal performance across both tasks.",
        "issn": {
            "Print ISSN": "0196-2892",
            "Electronic ISSN": "1558-0644"
        },
        "keywords": {
            "IEEE Keywords": [],
            "Author Keywords": [
                "Remote sensing image",
                "change captioning",
                "foundation model",
                "multi-task learning"
            ]
        },
        "universities": "School of Astronautics",
        "countries": "China",
        "locations": [
            "School of Astronautics, Image Processing Center, Beihang University, Beijing, China",
            "School of Astronautics, Image Processing Center, Beihang University, Beijing, China",
            "School of Astronautics, Image Processing Center, Beihang University, Beijing, China",
            "School of Astronautics, Image Processing Center, Beihang University, Beijing, China",
            "School of Astronautics, Image Processing Center, Beihang University, Beijing, China",
            "School of Astronautics, Image Processing Center, Beihang University, Beijing, China"
        ],
        "title": "Semantic-CC: Boosting Remote Sensing Image Change Captioning via Foundational Knowledge and Semantic Guidance"
    },
    {
        "authors": [
            "Taniya Seth",
            "Pranab K. Muhuri"
        ],
        "published_in": "Published in: IEEE Transactions on Fuzzy Systems ( Early Access )",
        "date_of_publication": "21 August 2024",
        "publication_month": "August",
        "publication_year": 2024,
        "doi": "10.1109/TFUZZ.2024.3429240",
        "publisher": "IEEE",
        "abstract": "With ever-increasing abundance of text data, decisionmaking problems are becoming more complex. Such complexity is often a consequence of the nuanced input linguistic information which are already highly uncertain and subjective. In this paper, a novel multi-attribute decision making (MADM) model named MARSHAL is introduced in order to capture the aforesaid nuanced characteristics from raw input linguistic data. It is for the first time in the literature of fuzzy-based linguistic MADM models that MARSHAL treats inputs as rich linguistic features from a pretrained deep learning based large language model (LLM) in addition to being uncertain and hesitant, while also presenting vector arithmetic-based information elicitation from corresponding hesitant fuzzy linguistic term sets. The idea is to introduce semantically-aware probabilistic attribute weights based on high-dimensional linguistic features learnt by an enhanced variant of BERT, utilized to solve MADM problems alongside risk and regret-aversive behaviours of experts. The proposed model is tested for applicability on a real case-study of employee flight risk detection. Additionally, extensive quantitative and qualitative experiments are performed to prove the proposed model's gained interpretability and adaptability amongst several other properties which existing congeneric models do not possess",
        "issn": {
            "Print ISSN": "1063-6706",
            "Electronic ISSN": "1941-0034"
        },
        "keywords": {
            "IEEE Keywords": [
                "Linguistics",
                "Decision making",
                "Computational modeling",
                "Semantics",
                "Probabilistic logic",
                "Vectors",
                "Adaptation models"
            ],
            "Author Keywords": [
                "Hesitant fuzzy linguistic term sets",
                "multi attributes decision making",
                "natural language models",
                "regret theory",
                "semantically aware weights",
                "semantic textual similarity"
            ]
        },
        "universities": "Department of Computer Science",
        "countries": "India",
        "locations": [
            "Department of Computer Science, South Asian University, Maidan Garhi, New Delhi, India",
            "Department of Computer Science, South Asian University, Maidan Garhi, New Delhi, India"
        ],
        "title": "MARSHAL: Multiple-Attribute Regret Theory and Semantically Aware Probabilistic Weights based Hesitant Linguistic Decision-Making"
    }
]
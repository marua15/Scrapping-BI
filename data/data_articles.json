[
    {
        "authors": [
            "Jinyong Kim",
            "Jaehoon Jeong",
            "Jeonghyeon Kim",
            "Joomin Kim"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Network ( Early Access )",
        "date_of_publication": "08 October 2024",
        "doi": "10.1109/MNET.2024.3476380",
        "publisher": "IEEE",
        "abstract": "As the healthcare industry has continued to develop and the medical data becomes digitized, the risk of data leakage from attacks grows. All medical data is encrypted and stored to prevent data leakage, but from big data perspective, it is inefficient because the encryption of this medical data lowers the big data processing performance. To address this problem, this paper proposes an Anonymity-based Big Data Management (ABDM) for protecting healthcare data from privacy breach without compromising on performance. The idea of ABDM is to separate and store identity data and healthcare data in databases on different cloud servers. By storing the identity data and healthcare data separately in databases on different cloud servers, hackers are unable to identify whose healthcare data is obtained until they obtain both the identity data and healthcare data. Through experiments in a public cloud, ABDM outperforms existing healthcare data management systems by two times speed.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Medical services",
                "Databases",
                "Computer hacking",
                "Encryption",
                "Cryptography",
                "Big Data",
                "Cloud computing",
                "Data privacy",
                "Servers",
                "Medical diagnostic imaging"
            ],
            "Author Keywords": []
        },
        "Field": "data",
        "title": "ABDM: Anonymity-based Big Data Management for Protecting Healthcare Data from Privacy Breach",
        "link": "https://ieeexplore.ieee.org/document/10707342/"
    },
    {
        "authors": [
            "Jiajun Chen",
            "Chunqiang Hu",
            "Zewei Liu",
            "Tao Xiang",
            "Pengfei Hu",
            "Jiguo Yu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "25 July 2024",
        "doi": "10.1109/TBDATA.2024.3433433",
        "publisher": "IEEE",
        "abstract": "The pursuit of refined data analysis and the preservation of privacy in Big Data pose significant concerns. Among the paramount paradigms for addressing these challenges, differential privacy stands out as a vital area of research. However, traditional differential privacy tends to be excessively restrictive when it comes to individuals' control over their own data. It often treats all data as inherently sensitive, whereas in reality, not all information related to individuals is sensitive and requires an identical level of protection. In this paper, we define secret specification-based differential privacy (SSDP), where the term “secret specification” implies enabling users to decide what aspects of their information are sensitive and what are not, prior to data generation or processing. By allowing individuals to independently define their secret specifications, the SSDP achieves personalized privacy protection and facilitates effective data analysis. To enable the targeted application of SSDP, we further present task-specific mechanisms designed for database and graph data scenarios. Finally, we assess the trade-offs between privacy and utility inherent in the proposed mechanisms through comparative experiments conducted on real datasets, demonstrating the utility enhancements offered by SSDP mechanisms in practical applications.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data privacy",
                "Privacy",
                "Protection",
                "Sensitivity",
                "Big Data",
                "Differential privacy",
                "Data analysis"
            ],
            "Author Keywords": [
                "Big data",
                "differential privacy",
                "personalized privacy preservation",
                "secret specification"
            ]
        },
        "Field": "data",
        "title": "Secret Specification Based Personalized Privacy-Preserving Analysis in Big Data",
        "link": "https://ieeexplore.ieee.org/document/10609563/"
    },
    {
        "authors": [
            "Nicholas Tan Jerome",
            "Timo Dritschler",
            "Suren Chilingaryan",
            "Andreas Kopmann"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Nuclear Science ( Early Access )",
        "date_of_publication": "30 September 2024",
        "doi": "10.1109/TNS.2024.3471071",
        "publisher": "IEEE",
        "abstract": "Given the rapid improvement of the detectors at high-energy physics experiments, the need for real-time data monitoring systems has become imperative. The significance of these systems lies in their ability to display experiment status, steer software and hardware instrumentation, and provide alarms, thus enabling researchers to manage their experiments better. Such systems commonly comprise multiple interacting parts: experiment and process control. There are multiple processing stages that record process data and derive information. And there is a component that communicates and displays the evaluated information to the operators. As the process control and data acquisition stages are usually specific to the experiment, it is common for researches to also build custom monitoring systems in unison with their data acquisition, leading to poor reusability for other experiments or future upgrades. This paper presents BORA (personalized collaBORAtive data display), a lightweight browser-based monitoring frontend that supports diverse data sources and is built specifically for customizable visualization of complex data, standardized via video streaming. It is shown how absolute positioning layout and visual overlay background can address the diverse data display design requirements. Integration of Jupyter Notebooks as part of the ecosystem addresses limitations of static web-based frameworks, providing a foundation to leverage scripting capabilities and integrate popular AI frameworks. Video streaming protocols like HLS, WebRTC, and MPEG-Websocket are used to forward visual outputs of remote processing and imaging pipelines of an experiment. The study explores the implications for these use cases, highlighting its potential to transform data visualization and decision-making processes.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Monitoring",
                "Data visualization",
                "Streaming media",
                "Visualization",
                "Data acquisition",
                "Streams",
                "Real-time systems",
                "Layout",
                "Detectors",
                "Process control"
            ],
            "Author Keywords": [
                "data monitoring",
                "high-speed data",
                "web display"
            ]
        },
        "Field": "data",
        "title": "BORA: A Personalized Data Display for Large-scale Experiments",
        "link": "https://ieeexplore.ieee.org/document/10700767/"
    },
    {
        "authors": [
            "Souad. Boauicha",
            "Wafa. Ghemmaz",
            "Sahar. Smaali"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "06 November 2024",
        "doi": "10.1109/ACCESS.2024.3492972",
        "publisher": "IEEE",
        "abstract": "Effective data management is critical for organizations, yet integrating diverse data sources remains challenging. Data governance plays a key role in ensuring data quality, security, and consistency. Without governance, integration becomes complex, costly, and time-consuming. A crucial aspect of governance is the evaluation of data value, often done through market-based, economic, and dimensional models. However, existing dimensional frameworks lack formal validation, and tools for comprehensive evaluation of datasets and ontologies prior to integration are scarce. This paper introduces DaVe (Data Value Evaluation framework), a formal framework designed to assess the value of datasets and ontologies before integration, focusing on metrics like data quality, coherence, and consistency, while accounting for project-specific constraints. Built on an algebraic foundation, DaVe estimates the potential value of integrated datasets, reducing risks and speeding up the integration process. Its effectiveness is demonstrated through a meteorological case study, highlighting its ability to assist integrators in evaluating and comparing ontologies, with promising implications for future data-driven projects.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Measurement",
                "Data integration",
                "Organizations",
                "Data integrity",
                "Interoperability",
                "Standards organizations",
                "Ontologies",
                "Data governance",
                "Soft sensors",
                "Resource description framework"
            ],
            "Author Keywords": [
                "Data Management",
                "Data Value Assessment",
                "Data Value Evaluation",
                "Dimensional Model",
                "Ontology Integration"
            ]
        },
        "Field": "data",
        "title": "DaVe: Data Value Evaluation Framework for Seamless Data Integration",
        "link": "https://ieeexplore.ieee.org/document/10745492/"
    },
    {
        "authors": [
            "Jie Liu",
            "Yijia Cao",
            "Yong Li",
            "Yixiu Guo",
            "Wei Deng"
        ],
        "locations": [],
        "published_in": "Published in: CSEE Journal of Power and Energy Systems ( Early Access )",
        "date_of_publication": "21 December 2020",
        "doi": "10.17775/CSEEJPES.2020.04080",
        "publisher": "CSEE",
        "abstract": "In order to improve the data quality, the big data cleaning method of distribution network was studied in this paper. First, the Local Outlier Factor (LOF) algorithm based on DBSCAN clustering was used to detect outliers. However, due to the difficulty in determining the LOF threshold, a method of dynamically calculating the threshold based on the transformer districts and time was proposed. Besides, the LOF algorithm combines the statistical distribution method to reduce the \"misjudgment rate\". Aiming at the diversity and complexity of data missing forms in power big data, this paper improved the Random Forest imputation algorithm, which can be applied to various forms of missing data, especially the blocked missing data and even some horizontal or vertical data completely missing. The data in this paper were from real data of 44 transformer districts of a certain 10kV line in distribution network. Experimental results showed that outlier detection was accurate and suitable for any shape and multidimensional power big data. The improved Random Forest imputation algorithm was suitable for all missing forms, with higher imputation accuracy and better model stability. By comparing the network loss prediction between the data using this data cleaning method and the data removing outliers and missing values, it was found that the accuracy of network loss prediction had been improved by nearly 4 percentage points using the data cleaning method mentioned in this paper. Additionally, as the proportion of bad data increased, the difference between the prediction accuracy of cleaned data and that of uncleaned data was greater.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Cleaning",
                "Distribution networks",
                "Big Data",
                "Prediction algorithms",
                "Clustering algorithms",
                "Data models",
                "Anomaly detection"
            ],
            "Author Keywords": [
                "Data cleaning",
                "Outliers detection",
                "missing data imputation",
                "LOF",
                "DBSCAN",
                "Random Forest"
            ]
        },
        "Field": "data",
        "title": "A big data cleaning method based on improved CLOF and Random Forest for distribution network",
        "link": "https://ieeexplore.ieee.org/document/9299499/"
    },
    {
        "authors": [
            "Tailan Yuan",
            "Wen Xiong",
            "Siyuan Liu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "03 October 2024",
        "doi": "10.1109/TBDATA.2024.3474215",
        "publisher": "IEEE",
        "abstract": "Data quality is a fundamental challenge for downstream data mining tasks. While numerous studies have addressed data quality issues in various contexts, there is a notable lack of systematic research on data quality in metro systems. Metro systems generate a vast volume of multisource heterogeneous datasets daily, and many data mining tasks have been developed for operational and management purposes. Therefore, investigating data quality problems in metro systems is crucial. In this paper, we systematically explore data quality issues in metro systems. First, we present a comprehensive analysis method to examine data quality problems such as missing data, noise, and weak semantics. Second, we design five metrics to measure data quality and propose a set of quality improvement approaches. These approaches include a travel pattern-based missing value imputation method, a heuristic trajectory noise filtering method, and a data semantics enhancement method. Additionally, we develop an automated pipeline solution where the data quality enhancement algorithms are seamlessly integrated with the data processing pipeline. Finally, we provide a case study to illustrate the significant benefits of our data quality improvement methods. We conducted extensive experiments to validate our methods on a set of large-scale dataset collected from a metro system, which includes smart card data, Wi-Fi signal data, and electronic fence data. The results indicate that (1) the proposed imputation method surpasses other baselines by 26.47% to 44.82%; (2) the proposed noise filtering method outperforms other baselines by an average of 12.22%; and (3) the proposed data semantics enrichment method exceeds the baseline method by 37.34% in terms of maximum accuracy.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data integrity",
                "Wireless fidelity",
                "Trajectory",
                "Smart cards",
                "Noise",
                "Big Data",
                "Semantics",
                "Pipelines",
                "Imputation",
                "Filtering"
            ],
            "Author Keywords": [
                "Data quality",
                "data semantics enrichment",
                "missing data imputation",
                "noise filtering",
                "metro system"
            ]
        },
        "Field": "data",
        "title": "Large-Scale Data Quality Challenges, Framework and Evaluation in Metro Systems",
        "link": "https://ieeexplore.ieee.org/document/10705079/"
    },
    {
        "authors": [
            "Abdul Majeed",
            "Seong Oun Hwang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "13 August 2024",
        "doi": "10.1109/TBDATA.2024.3442534",
        "publisher": "IEEE",
        "abstract": "Recently, data has ousted oil as the most economical resource in the world, but most companies are reluctant to share customer/user data in pure form and on a large scale due to privacy concerns. Many innovative technologies (e.g., federated learning, split learning) are employed to meet the growing demand for privacy preservation. Despite these technologies, acquiring personal data in order to optimize utility, and then sharing it on a large scale, is still very challenging. Thanks to the rapid development of artificial intelligence (AI), a relatively new and promising solution to resolve these challenges is to generate synthetic data (SD) by mirroring the original dataset's properties. SD is a promising solution to address growing privacy demands as well as the utility/analytics requirements of many industry stakeholders. In this paper, we propose and implement an SD generation method from a real dataset containing both numerical and categorical attributes by using an improved conditional generative adversarial network (CGAN), and we quantify the feasibility of SD on technical and theoretical grounds. We provide a detailed analysis of SD in original and anonymized forms with the help of multiple use cases, whereas prior research simply assumed that privacy issues in SD are small because AI models do not overfit or SD has a poor connection with real data. We provide insights into the characteristics of SD (distributions, value frequencies, correlations, etc.) produced by the CGAN in relation to the real data. To the best of our knowledge, this is the pioneering work that provides an experiment-based analysis of the quality, privacy, and utility of SD in relation to a real benchmark dataset",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Artificial intelligence",
                "Data privacy",
                "Privacy",
                "Generative adversarial networks",
                "Biomedical imaging",
                "Data augmentation"
            ],
            "Author Keywords": [
                "synthetic data",
                "generative adversarial networks",
                "privacy",
                "utility",
                "federated learning",
                "privacy-enhancing technology"
            ]
        },
        "Field": "data",
        "title": "Moving Conditional GAN Close to Data: Synthetic Tabular Data Generation and its Experimental Evaluation",
        "link": "https://ieeexplore.ieee.org/document/10634770/"
    },
    {
        "authors": [
            "Ruikun Luo",
            "Qiang He",
            "Feifei Chen",
            "Song Wu",
            "Hai Jin",
            "Yun Yang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Parallel and Distributed Systems ( Early Access )",
        "date_of_publication": "07 November 2024",
        "doi": "10.1109/TPDS.2024.3493953",
        "publisher": "IEEE",
        "abstract": "With its advantages in ensuring low data retrieval latency and reducing backhaul network traffic, edge computing is becoming a backbone solution for many latency-sensitive applications. An increasingly large number of data is being generated at the edge, stretching the limited capacity of edge storage systems. Improving resource utilization for edge storage systems has become a significant challenge in recent years. Existing solutions attempt to achieve this goal through data placement optimization, data partitioning, data sharing, etc. These approaches overlook the data redundancy in edge storage systems, which produces substantial storage resource wastage. This motivates the need for an approach for data deduplication at the edge. However, existing data deduplication methods rely on centralized control, which is not always feasible in practical edge computing environments. This paper presents Ripple, the first approach that enables edge servers to deduplicate their data in a decentralized manner. At its core, it builds a data index for each edge server, enabling them to deduplicate data without central control. With Ripple, edge servers can 1) identify data duplicates; 2) remove redundant data without violating data retrieval latency constraints; and 3) ensure data availability after deduplication. The results of trace-driven experiments conducted in a testbed system demonstrate the usefulness of Ripple in practice. Compared with the state-of-the-art approach, Ripple improves the deduplication ratio by up to 16.79% and reduces data retrieval latency by an average of 60.42%",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Servers",
                "Redundancy",
                "Cloud computing",
                "Distributed databases",
                "Web sites",
                "Video on demand",
                "Metadata",
                "Memory",
                "Low latency communication",
                "Indexes"
            ],
            "Author Keywords": [
                "Edge computing",
                "data redundancy",
                "data retrieval latency",
                "data deduplication",
                "data index"
            ]
        },
        "Field": "data",
        "title": "Ripple: Enabling Decentralized Data Deduplication at the Edge",
        "link": "https://ieeexplore.ieee.org/document/10747114/"
    },
    {
        "authors": [
            "Xiaoming Wang",
            "Jianwei Li",
            "Zhiquan Liu",
            "Quan Tang",
            "Xixian Wang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "20 September 2024",
        "doi": "10.1109/JIOT.2024.3464760",
        "publisher": "IEEE",
        "abstract": "Cross-modal search with deep learning shows an attractive potential on heterogeneous datasets due to its accuracy and effectiveness. Usually, it has to aggregate and train large amounts of data to make precise predictions, which is feasible in the single-user environment and plaintext areas. However, the challenge lies in maintaining search accuracy within a multiuser environment while simultaneously safeguarding user data privacy. In this paper, we address these challenges by centering on the development of secure cross-modal search techniques that are supported by federated learning. To our knowledge, this marks the first endeavor to execute cross-modal encrypted data search through the auspices of federated learning. Our approach specifically employs a secure and reliable federated learning technique to extract key features from diverse heterogeneous data, ensuring precise model training in a distributed data environment. Consequently, while the data is encrypted, it achieves the protection of data privacy and simultaneously enhances the efficiency and accuracy of cross-modal search. To further enhance retrieval efficiency, we propose a tag classification algorithm that employs homomorphic encryption and locality-sensitive hashing. Furthermore, we design a secure method for calculating Euclidean distance that utilizes the k-nearest neighbor algorithm. This method efficiently identifies the result nearest to the query data, thereby enhancing the accuracy of the search results. Both theoretical analysis and experimental evaluation demonstrate that our proposed scheme not only protects user data privacy, but also has high accuracy and efficiency.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Accuracy",
                "Feature extraction",
                "Data privacy",
                "Federated learning",
                "Data models",
                "Semantics",
                "Hash functions"
            ],
            "Author Keywords": [
                "Cross-modal search",
                "Federated learning",
                "Encrypted data search"
            ]
        },
        "Field": "data",
        "title": "Enabling Secure Cross-Modal Search over Encrypted Data via Federated Learning",
        "link": "https://ieeexplore.ieee.org/document/10684761/"
    },
    {
        "authors": [
            "Tao Chen",
            "Yanrong Guo",
            "Shijie Hao",
            "Richang Hong"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Affective Computing ( Early Access )",
        "date_of_publication": "26 September 2024",
        "doi": "10.1109/TAFFC.2024.3469189",
        "publisher": "IEEE",
        "abstract": "While deep learning techniques have shown promising performance in the Major Depressive Disorder (MDD) detection task, they still face limitations in real-world scenarios. Specifically, given the data scarcity, some efforts have resorted to aggregating data from different domains to expand the data volume. However, their effectiveness is currently limited by the domain gap and data privacy. Additionally, the class imbalance issue is particularly severe in our application, leading to biased classifying performance accordingly. To address these challenges, we propose Data-Free Domain Incremental Learning for the MDD detection (DIL-MDD) task, accommodating multiple feature distributions by only accessing well-trained models from previous domains and the data in the current domain. Specifically, DIL-MDD consists of two key modules: Adaptive Class-tailored Threshold Learning (ACTL) and Data-Free Domain Alignment (DFDA). The first module measures the discrepancy between the outputs of two sequential domains, based on which we learn a class-tailored threshold adaptively. Building on this, we differentiate between samples that either exhibit similarities or dissimilarities with the previous domain, where this similar sample set is identified to investigate the feature distribution of the historical data. The second module imposes an alignment constraint to narrow the gap between these two sample sets, thereby exploring the expertise of the previous domain. To validate the effectiveness of the proposed method, we conduct extensive experiments on the public MDD datasets, i.e. , DAIC-WOZ, MODMA, and CMDC. We also apply our method to another mental health condition, Autism Spectrum Disorder (ASD), to further demonstrate its applicability. Finally, the ablation studies validate the superiority of the proposed modules.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Adaptation models",
                "Incremental learning",
                "Feature extraction",
                "Electronics packaging",
                "Computational modeling",
                "Affective computing",
                "Predictive models",
                "Mental health",
                "Training"
            ],
            "Author Keywords": [
                "MDD/ASD detection",
                "data-free domain incremental learning",
                "catastrophic forgetting",
                "class imbalance",
                "data-free domain alignment"
            ]
        },
        "Field": "data",
        "title": "Leaving None Behind: Data-Free Domain Incremental Learning for Major Depressive Disorder Detection",
        "link": "https://ieeexplore.ieee.org/document/10696948/"
    },
    {
        "authors": [
            "Linchang Xiao",
            "Xianzhi Zhang",
            "Di Wu",
            "Miao Hu",
            "Yipeng Zhou",
            "Shui Yu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Services Computing ( Early Access )",
        "date_of_publication": "28 August 2024",
        "doi": "10.1109/TSC.2024.3451187",
        "publisher": "IEEE",
        "abstract": "The publicly released machine learning (ML) models are susceptible to malicious attacks ( e.g. , gradient leakage attacks), which may expose sensitive training data of data-sharing platforms to untrusted third-parties. To preserve the privacy of training data, differential privacy (DP) is exploited to limit the amount of leaked privacy with a predefined budget, which in fact is a non-recoverable resource. Considering DP, allocating privacy budgets to ML queries is a non-trivial but crucial problem because a certain amount of non-recoverable privacy budget will be consumed if a datablock is assigned to a query once. Meanwhile, both datablocks and ML queries are continuously generated, which further complicates the problem. Most existing works simply relied on greedy-based algorithms to make myopic allocation decisions, far away from the optimal decision. In this paper, we propose a novel H istory-aware P rivacy B udget A llocation (HPBA) algorithm for data-sharing platforms to address the above challenges. Different from existing works, HPBA leverages historical query records to approximate global ML query patterns so as to overcome the drawback of shortsighted greedy-based algorithms. Moreover, the performance of HPBA is theoretically guaranteed by competitive analysis. A lightweight version called S-HPBA is proposed to further reduce computation overhead by using fewer historical records. Experimental results demonstrate that, compared to the state-of-the-art baselines, HPBA and S-HPBA improve the average performance by 32.8% and 16.2% in terms of model accuracy, respectively.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Resource management",
                "Privacy",
                "Training",
                "Data models",
                "Computational modeling",
                "Differential privacy",
                "Training data"
            ],
            "Author Keywords": [
                "data-sharing platforms",
                "differential privacy",
                "budget allocation",
                "online algorithm"
            ]
        },
        "Field": "data",
        "title": "History-Aware Privacy Budget Allocation for Model Training on Evolving Data-Sharing Platforms",
        "link": "https://ieeexplore.ieee.org/document/10654304/"
    },
    {
        "authors": [
            "Zhiguang Zhou",
            "Haoxuan Wang",
            "Zhendong Yang",
            "Yuanyuan Chen",
            "Xiaohui Chen",
            "Ying Lai"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "11 November 2024",
        "doi": "10.1109/TBDATA.2024.3495499",
        "publisher": "IEEE",
        "abstract": "Voronoi diagram is commonly used to visualize geographical point dataset with a collection of plane-partitioned facets. As the size of the geographical point dataset increases, facets are densely distributed, and present different sizes and irregular shapes, leading to overdrawing and confusion problems, and hampering the visual perception of Voronoi diagram and insightful exploration of geographical point data. In this paper, we propose a novel Voronoi diagram generation framework to visualize and explore large-scale geographical point datasets. Firstly, an attribute-based blue noise sampling model is designed to select a subset of points to generate the simplified Voronoi diagram, retaining both the spatial distribution and attribute relationship of the original large-scale geographical points. Then a couple of optimization schemes are integrated into the sampling model to replace the representative points, aiming to enhance the visual perception of Voronoi diagram, such as shape balance and color characterization. Furthermore, we implement an interactive online Voronoi diagram generation tool, GeoVoronoi, enabling users to generate meaningful facets according to their requirements. Quantitative comparisons, case studies and user studies based on real-world datasets have demonstrated the effectiveness of our proposed method in the generation of credible Voronoi diagram and in-depth exploration of geographical point datasets.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Visualization",
                "Image color analysis",
                "Geospatial analysis",
                "Shape",
                "Visual perception",
                "Optimization",
                "Graphical models",
                "Distribution functions",
                "Big Data"
            ],
            "Author Keywords": [
                "Geographical visualization",
                "voronoi diagram",
                "spatial attribute association",
                "sampling"
            ]
        },
        "Field": "data",
        "title": "GeoVoronoi: A Voronoi Diagram Generation System for Large-scale Geographical Point Data via Spatial Attribute Association",
        "link": "https://ieeexplore.ieee.org/document/10750044/"
    },
    {
        "authors": [
            "Himanshu Kubba"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Engineering Management Review ( Early Access )",
        "date_of_publication": "02 September 2024",
        "doi": "10.1109/EMR.2024.3452682",
        "publisher": "IEEE",
        "abstract": "Enterprise Resource Planning (ERP) implementation necessitates efficient data conversion, traditionally characterized by labor-intensive tasks like validation checks, field mapping, and transformations. While effective, these methods are time-consuming and costly. With the advent of Generative Artificial Intelligence (Gen AI), data conversion has been revolutionized, significantly reducing manual intervention. Traditional methods, often labor-intensive and costly, are replaced by automated Gen AI solutions. This innovation not only reduces technical effort and business involvement but also accelerates project timelines and lowers costs. This paper explores the implementation of a Gen AI-driven solution that automates data extraction, validation, and mapping, enhancing accuracy and efficiency. Utilizing advanced technologies such as SQL, Python pandas, and PyTorch, this approach reimagines the workflow, enabling faster and more reliable ERP implementations with minimal disruption. By harnessing the power of machine learning and neural networks, the system evolves continuously, offering a scalable and robust solution for modern enterprises navigating the complexities of digital transformation. The adoption of Gen AI in data conversion thus represents a pivotal advancement, enabling faster, more reliable ERP implementations and fostering greater operational resilience and adaptability.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data conversion",
                "Organizations",
                "Neural networks",
                "Generative AI",
                "Data models",
                "Data mining",
                "Accuracy"
            ],
            "Author Keywords": [
                "ERP SaaS",
                "Data Conversion",
                "Data Mapping",
                "Generative Artificial Intelligence",
                "Gen AI",
                "PyTorch"
            ]
        },
        "Field": "data",
        "title": "Data Conversion in ERP SaaS Implementation with Generative AI",
        "link": "https://ieeexplore.ieee.org/document/10663228/"
    },
    {
        "authors": [
            "Yunpeng Xiao",
            "Xufeng Li",
            "Tun Li",
            "Rong Wang",
            "Yucai Pang",
            "Guoyin Wang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "12 March 2024",
        "doi": "10.1109/TBDATA.2024.3375150",
        "publisher": "IEEE",
        "abstract": "Vertical federated learning can aggregate participant data features. To address the issue of insufficient overlapping data in vertical federated learning, this study presents a generative adversarial network model that allows distributed data augmentation. First, this study proposes a distributed generative adversarial network FeCGAN for multiple participants with insufficient overlapping data, considering the fact that the generative adversarial network can generate simulation samples. This network is suitable for multiple data sources and can augment participants' local data. Second, to address the problem of learning divergence caused by different local distributions of multiple data sources, this study proposes the aggregation algorithm FedKL. It aggregates the feedback of the local discriminator to interact with the generator and learns the local data distribution more accurately. Finally, given the problem of data waste caused by the unavailability of nonoverlapping data, this study proposes a data augmentation method called VFeDA. It uses FeCGAN to generate pseudo features and expands more overlapping data, thereby improving the data use. Experiments showed that the proposed model is suitable for multiple data sources and can generate high-quality data.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Federated learning",
                "Generative adversarial networks",
                "Data models",
                "Data augmentation",
                "Generators",
                "Distributed databases",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Vertical Federated Learning",
                "Data Augmentation",
                "Generative Adversarial Networks",
                "Multiple Data Sources"
            ]
        },
        "Field": "data",
        "title": "A Distributed Generative Adversarial Network for Data Augmentation under Vertical Federated Learning",
        "link": "https://ieeexplore.ieee.org/document/10463181/"
    },
    {
        "authors": [
            "Altaf Hussain",
            "Tanveer Hussain",
            "Waseem Ullah",
            "Samee Ullah Khan",
            "Min Je Kim",
            "Khan Muhammad",
            "Javier Del Ser",
            "Sung Wook Baik"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "01 November 2024",
        "doi": "10.1109/TBDATA.2024.3489414",
        "publisher": "IEEE",
        "abstract": "Deep-learning-based human activity recognition (HAR) methods have significantly transformed a wide range of domains over recent years. However, the adoption of Big Data techniques in industrial applications remains challenging due to issues such as generalized weight optimization, diverse viewpoints, and the complex spatiotemporal features of videos. To address these challenges, this work presents an industrial HAR framework consisting of two main phases. First, a squeeze bottleneck attention block (SBAB) is introduced to enhance the learning capabilities of the backbone model for contextual learning, which allows for the selection and refinement of an optimal feature vector. In the second phase, we propose an effective sequential temporal convolution network (STCN), which is designed in parallel fashion to mitigate the issues of exploding and vanishing gradients associated with sequence learning. The high-dimensional spatiotemporal feature vectors from the STCN undergo further refinement through our proposed SBAB in a sequential manner, to optimize the features for HAR and enhance the overall performance. The efficacy of the proposed framework is validated through extensive experiments on six datasets, including data from industrial and general activities.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Videos",
                "Surveillance",
                "Computational modeling",
                "Big Data",
                "Human activity recognition",
                "Data mining",
                "Streams",
                "Spatiotemporal phenomena",
                "Data models"
            ],
            "Author Keywords": [
                "Industrial Surveillance System",
                "Big Data Analysis",
                "Artificial Intelligence",
                "Big Data Performance Analyses",
                "Convolutional Neural Networks",
                "Deep Learning"
            ]
        },
        "Field": "data",
        "title": "Big Data Analysis for Industrial Activity Recognition Using Attention-Inspired Sequential Temporal Convolution Network",
        "link": "https://ieeexplore.ieee.org/document/10740027/"
    },
    {
        "authors": [
            "Muhammad Rizwan",
            "Ammar Hawbani",
            "Wang Xingfu",
            "Adeel Anjum",
            "Pelin Angin",
            "Yigit Sever",
            "Sanchuan Chen",
            "Liang Zhao",
            "Ahmed Al-Dubai"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "11 November 2024",
        "doi": "10.1109/TBDATA.2024.3495497",
        "publisher": "IEEE",
        "abstract": "A data publishing deal conducted with anonymous microdata can preserve the privacy of people. However, anonymizing data with multiple records of an individual (1:M dataset) is still a challenging problem. After anonymizing the 1:M microdata, the vertical correlation can be exploited to launch privacy attacks. In this paper, a novel privacy preserving model lc, ls-ANGEL is proposed. To validate the new model, two privacy attacks are presented, namely, a Vertical correlation attack (Vc0) and a Vulnerable sensitive attribute attack (Vsa) on 1:M datasets, which breach the privacy of individuals. Furthermore, the proposed model is examined through High-Level Petri Nets (HLPNs). Our experiments on three real-world datasets;“INFORMS”,“YOUTUBE”, and “IMDb” demonstrate that the proposed model outperforms the state-of-the-art models. Our practices and lessons learned in this work can direct future concrete steps towards Multiple Sensitive Attributes, where we can expand the proposed model to dynamic datasets",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data privacy",
                "Privacy",
                "Partitioning algorithms",
                "Mathematical models",
                "Big Data",
                "Information integrity",
                "Information filtering",
                "Data models",
                "Correlation",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Internet of Things",
                "Big Data",
                "electronic health records",
                "privacy of data",
                "k-anonymity",
                "1:M microdata"
            ]
        },
        "Field": "data",
        "title": "An Enhanced and Robust Data Publishing Scheme for Private and Useful 1:M Microdata",
        "link": "https://ieeexplore.ieee.org/document/10748377/"
    },
    {
        "authors": [
            "Shiqing Sang",
            "Fangfang Qu",
            "Pengcheng Nie"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "21 May 2021",
        "doi": "10.1109/ACCESS.2021.3082519",
        "publisher": "IEEE",
        "abstract": "Ensemble deep learning can combine strengths of neural network and ensemble learning and gradually becomes a new emerging research direction. However, the existing methods either lack theoretical support or demand large integrated models. To solve these problems, in this paper, Ensembles of Gradient Boosting Recurrent Neural Network (EGB-RNN) is proposed, which combines the gradient boosting ensemble framework with three types of recurrent neural network models, namely Minimal Gated Unit (MGU), Gated Recurrent Unit (GRU) and Long Short-Term Memory (LSTM). RNN model is used as base learner to integrate an ensemble learner, through the way of gradient boosting. Meanwhile, for ensuring the ensemble model fit data better, Step Iteration Algorithm is designed to find an appropriate learning rate before models being integrated. Contrast trials are carried out on four time series data sets. Experimental results demonstrate that with the number of integration increasing, the performance of three types of EGB-RNN models tend to converge and the best EGB-RNN model and the best degree of ensemble vary with data sets. It is also shown in statistical results that the designed EGB-RNN models perform better than six baselines.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Boosting",
                "Data models",
                "Predictive models",
                "Time series analysis",
                "Deep learning",
                "Computational modeling",
                "Support vector machines"
            ],
            "Author Keywords": [
                "Gradient boosting",
                "LSTM",
                "GRU",
                "MGU",
                "Ensemble learning",
                "Time series data prediction"
            ]
        },
        "Field": "data",
        "title": "Ensembles of Gradient Boosting Recurrent Neural Network for Time Series Data Prediction",
        "link": "https://ieeexplore.ieee.org/document/9438681/"
    },
    {
        "authors": [
            "Yun Wang",
            "Zhangjie Guan",
            "Yuchen He",
            "Lijuan Qian",
            "Jiusun Zeng",
            "Jun Wang",
            "Lingjian Ye"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Industrial Informatics ( Early Access )",
        "date_of_publication": "22 October 2024",
        "doi": "10.1109/TII.2024.3476522",
        "publisher": "IEEE",
        "abstract": "Due to operating condition drift, environmental changes, and system oscillations, industrial processes often exhibit nonstationary characteristics that involve both stable long-term trend and fluctuant short-term dynamics. In this article, a novel multiscale gated structure model (MGSM) is proposed for nonstationary process soft sensing, which includes long-term memory chain (stable and low frequency) and short-term dynamic chain (respond to fluctuations). The information decomposed from input data is introduced into the MGSM to learn long-term dependency relationships and dynamic behavior in the nonstationary process. In addition, a novel two-dimensional random missing function is designed to handle randomly missing data, which fully considers the data missing in variable-wise and time-wise dimensions. The proposed model is further constructed for the soft sensing of nonstationary processes with random missing data. Finally, application studies to the Tennessee Eastman process and a thermal power generating process show that the proposed method has significant advantages in the quality prediction of nonstationary process.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Market research",
                "Logic gates",
                "Data models",
                "Soft sensors",
                "Feature extraction",
                "Adaptation models",
                "Informatics",
                "Deep learning",
                "Data mining",
                "Process control"
            ],
            "Author Keywords": [
                "Long-term trends",
                "nonstationary processes",
                "random missing data",
                "short-term dynamics",
                "soft sensing"
            ]
        },
        "Field": "data",
        "title": "A Novel Multiscale Gated Structure Model for Soft Sensing of Nonstationary Process With Randomly Missing Data",
        "link": "https://ieeexplore.ieee.org/document/10729278/"
    },
    {
        "authors": [
            "Junjun Si",
            "Jin Yang",
            "Yang Xiang",
            "Li Li",
            "Bo Tu",
            "Rongqing Zhang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "12 February 2024",
        "doi": "10.1109/TBDATA.2024.3362195",
        "publisher": "IEEE",
        "abstract": "Trajectory clustering is a cornerstone task in the field of trajectory mining. With the proliferation of deep learning, deep trajectory clustering has been widely researched to mine mobility patterns from massive unlabeled trajectories. Nevertheless, existing methods mostly ignore trajectories' temporal regularities, which are essential for mining fine-grained mobility patterns for applications including traveling group identification, transportation mode discovering, social security emergency, etc. To fill this gap, we propose ConDTC, a contrastive deep trajectory clustering method targeting for fine-grained mobility pattern mining. Specifically, we first design a spatial-temporal trajectory representation learning method which can capture both spatial and temporal regularities of trajectories synchronously. The proposed trajectory representation model can be used as a pre-trained model to serve various downstream trajectory mining tasks. Then, we construct a contrastive trajectory clustering module which optimizes trajectory representations and clustering performance simultaneously. Experimental results on three datasets validate that ConDTC can identify fine-grained mobility patterns by clustering trajectories with similar spatial-temporal mobility patterns together while separating those with different mobility patterns apart. Actually, ConDTC outperforms all state-of-the-art competitors substantially in terms of effectiveness, efficiency and robustness.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Trajectory",
                "Clustering methods",
                "Representation learning",
                "Data mining",
                "Task analysis",
                "Self-supervised learning",
                "Big Data"
            ],
            "Author Keywords": [
                "trajectory clustering",
                "trajectory representation learning",
                "trajectory mining",
                "spatial-temporal data mining"
            ]
        },
        "Field": "data",
        "title": "ConDTC: Contrastive Deep Trajectory Clustering for Fine-grained Mobility Pattern Mining",
        "link": "https://ieeexplore.ieee.org/document/10433249/"
    },
    {
        "authors": [
            "Qiang He",
            "Guobiao Zhang",
            "Jiawei Wang",
            "Ruikun Luo",
            "Xiaohai Dai",
            "Yuchong Hu",
            "Feifei Chen",
            "Hai Jin",
            "Yun Yang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Parallel and Distributed Systems ( Early Access )",
        "date_of_publication": "07 November 2024",
        "doi": "10.1109/TPDS.2024.3493034",
        "publisher": "IEEE",
        "abstract": "In the edge computing environment, app vendors can distribute popular data from the cloud to edge servers to provide low-latency data retrieval. A key problem is how to distribute these data from the cloud to edge servers cost-effectively. Under current schemes, a file is divided into some data blocks for parallel transmissions from the cloud to target edge servers. Edge servers can then combine received data blocks to reconstruct the file. While this method expedites the data distribution process, it presents potential drawbacks. It is sensitive to transmission delays and transmission failures caused by runtime exceptions like network fluctuations and server failures. This paper presents EdgeHydra, the first edge data distribution scheme that tackles this challenge through fault tolerance based on erasure coding. Under EdgeHydra, a file is encoded into data blocks and parity blocks for parallel transmission from the cloud to target edge servers. An edge server can reconstruct the file upon the receipt of a sufficient number of these blocks without having to wait for all the blocks in transmission. It also innovatively employs a leaderless block supplement mechanism to ensure the receipt of sufficient blocks for individual target edge servers. These improve the robustness of the data distribution process significantly. Extensive experiments show that EdgeHydra can tolerate delays and failures in individual transmission links effectively, outperforming the state-of-the-art scheme by up to 50.54% in distribution time.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Servers",
                "Delays",
                "Costs",
                "Encoding",
                "Runtime",
                "Fluctuations",
                "Fault tolerant systems",
                "Fault tolerance",
                "Steiner trees",
                "Edge computing"
            ],
            "Author Keywords": [
                "Data distribution",
                "distributed transmission",
                "edge data caching",
                "erasure coding"
            ]
        },
        "Field": "data",
        "title": "EdgeHydra: Fault-Tolerant Edge Data Distribution Based on Erasure Coding",
        "link": "https://ieeexplore.ieee.org/document/10746622/"
    },
    {
        "authors": [
            "Jalal Mostafa",
            "Denis Tcherniakhovski",
            "Suren Chilingaryan",
            "Matthias Balzer",
            "Andreas Kopmann",
            "Jürgen Becker"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Nuclear Science ( Early Access )",
        "date_of_publication": "30 August 2024",
        "doi": "10.1109/TNS.2024.3452469",
        "publisher": "IEEE",
        "abstract": "A growing number of detectors produce data rates of more than 100 Gbit/s, which often necessitate softwaredefined data processing to operate. Because of its simplicity, the User Datagram protocol (UDP) offers a straightforward method for integrating such detectors with online computing resources that host the data processing software. Nevertheless, conventional technologies – such as POSIX sockets – are either ineffective or difficult to apply on detector boards based on Field Programmable Gateway Arrays (FPGAs). The new Linux AF_XDP sockets are a novel method that uses zero-copy methods to target high data speeds. In this paper, we present ”DQDK” a novel data acquisition framework based on AF_XDP and UDP for readout systems with more than 100 Gbit/s. We evaluate our framework for the TRItium Sterile Anti-Neutrino (TRISTAN) detector whose rates are expected to reach 200 Gbit/s. We describe our experience developing a TRISTAN detector readout system using AF_XDP.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data acquisition",
                "Detectors",
                "Software",
                "Protocols",
                "Linux",
                "Sockets",
                "Field programmable gate arrays"
            ],
            "Author Keywords": [
                "AF_XDP",
                "data acquisition",
                "high-throughput detectors",
                "RDMA",
                "UDP",
                "zero-copy networking"
            ]
        },
        "Field": "data",
        "title": "100 Gbit/s UDP Data Acquisition on Linux Using AF_XDP: The TRISTAN Detector",
        "link": "https://ieeexplore.ieee.org/document/10659873/"
    },
    {
        "authors": [
            "Yuxiang Yang",
            "Yuling Chen",
            "Zhiquan Liu",
            "Chaoyue Tan",
            "Yun Luo"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "21 October 2024",
        "doi": "10.1109/JIOT.2024.3483809",
        "publisher": "IEEE",
        "abstract": "Blockchain enhances the security and interoperability of Internet of Vehicles (IoV) systems by serving as a secure and decentralized platform for data sharing. The rapid growth of IoV data makes it challenging to store the entire blockchain on edge nodes with limited storage resources due to the blockchain’s immutability. Redactable blockchain represents a potential solution for enabling the controlled modification of data on blocks. However, current redactable blockchain schemes suffer from high computational overhead and lack support for stateful redaction and consistency checking. In this paper, we propose a secure and efficient decentralized chameleon hash scheme (CHSTS) based on Schnorr threshold signatures. CHSTS allows t-out-of-n edge nodes to collaborate with the transaction proposer to compute chameleon hash collisions, enabling modification and deletion of block data without breaking the hash links between the blocks. We then construct a redactable blockchain utilizing CHSTS to alleviate the storage limitations of edge nodes. To ensure consistency checking and stateful redaction of the redactable blockchain, we design a novel modification verification mechanism based on vector commitments. Finally, we provide detailed security analysis of the CHSTS scheme and integrate the proposed scheme into Hyperledger Fabric to evaluate the redactable blockchain through extensive experiments. The results demonstrate that our scheme incurs less computational overhead compared to the state-of-the-art chameleon hash schemes. Furthermore, our scheme maintains close efficiency compared to immutable blockchain, incurring negligible storage overhead.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Blockchains",
                "Security",
                "Reliability",
                "Vectors",
                "Public key",
                "Big Data",
                "Vehicular ad hoc networks",
                "Internet of Vehicles",
                "Hash functions",
                "Fabrics"
            ],
            "Author Keywords": [
                "IoV",
                "Schnorr threshold signature",
                "chameleon hash",
                "redactable blockchain"
            ]
        },
        "Field": "data",
        "title": "Verifiable and Redactable Blockchain for Internet of Vehicles Data Sharing",
        "link": "https://ieeexplore.ieee.org/document/10726583/"
    },
    {
        "authors": [
            "Dongdong Cheng",
            "Ya Li",
            "Shuyin Xia",
            "Guoyin Wang",
            "Jinlong Huang",
            "Sulan Zhang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )",
        "date_of_publication": "11 August 2023",
        "doi": "10.1109/TNNLS.2023.3300916",
        "publisher": "IEEE",
        "abstract": "Density peaks clustering algorithm (DP) has difficulty in clustering large-scale data, because it requires the distance matrix to compute the density and\nδ\n-distance for each object, which has\nO(\nn\n2\n)\ntime complexity. Granular ball (GB) is a coarse-grained representation of data. It is based on the fact that an object and its local neighbors have similar distribution and they have high possibility of belonging to the same class. It has been introduced into supervised learning by Xia et al. to improve the efficiency of supervised learning, such as support vector machine,\nk\n-nearest neighbor classification, rough set, etc. Inspired by the idea of GB, we introduce it into unsupervised learning for the first time and propose a GB-based DP algorithm, called GB-DP. First, it generates GBs from the original data with an unsupervised partitioning method. Then, it defines the density of GBs, instead of the density of objects, according to the centers, radius, and distances between its members and centers, without setting any parameters. After that, it computes the distance between the centers of GBs as the distance between GBs and defines the\nδ\n-distance of GBs. Finally, it uses GBs’ density and\nδ\n-distance to plot the decision graph, employs DP algorithm to cluster them, and expands the clustering result to the original data. Since there is no need to calculate the distance between any two objects and the number of GBs is far less than the scale of a data, it greatly reduces the running time of DP algorithm. By comparing with\nk\n-means, ball\nk\n-means, DP, DPC-KNN-PCA, FastDPeak, and DLORE-DP, GB-DP can get similar or even better clustering results in much less running time without setting any parameters. The source code is available at https://github.com/DongdongCheng/GB-DP.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Clustering algorithms",
                "Partitioning algorithms",
                "Approximation algorithms",
                "Supervised learning",
                "Big Data",
                "Time complexity",
                "Kernel"
            ],
            "Author Keywords": [
                "Clustering",
                "density peaks (DPs)",
                "granular balls (GBs)",
                "large scale"
            ]
        },
        "Field": "data",
        "title": "A Fast Granular-Ball-Based Density Peaks Clustering Algorithm for Large-Scale Data",
        "link": "https://ieeexplore.ieee.org/document/10215064/"
    },
    {
        "authors": [
            "Athanasios Koukosias",
            "Christos Anagnostopoulos",
            "Kostas Kolomvatsos"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Knowledge and Data Engineering ( Early Access )",
        "date_of_publication": "23 October 2024",
        "doi": "10.1109/TKDE.2024.3485531",
        "publisher": "IEEE",
        "abstract": "Context-aware data selectivity in Edge Computing (EC) requires nodes to efficiently manage the data collected from Internet of Things (IoT) devices, e.g., sensors, for supporting real-time and data-driven pervasive analytics. Data selectivity at the network edge copes with the challenge of deciding which data should be kept at the edge for future analytics tasks under limited computational and storage resources. Our challenge is to efficiently learn the access patterns of data-driven tasks (analytics) and predict which data are relevant, thus, being stored in nodes' local datasets. Task patterns directly indicate which data need to be accessed and processed to support end-users' applications. We introduce a task workload-aware mechanism which adopts one-class classification to learn and predict the relevant data requested by past tasks. The inherent uncertainty in learning task patterns, identifying inliers and eliminating outliers is handled by introducing a lightweight fuzzy inference estimator that dynamically adapts nodes' local data filters ensuring accurate data relevance prediction. We analytically describe our mechanism and comprehensively evaluate and compare against baselines and approaches found in the literature showcasing its applicability in pervasive EC.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Filters",
                "Peer-to-peer computing",
                "Sensors",
                "Distributed databases",
                "Internet of Things",
                "Data models",
                "Uncertainty",
                "Real-time systems",
                "Predictive models",
                "Edge computing"
            ],
            "Author Keywords": [
                "Edge Computing",
                "Data Filter",
                "Data Selectivity",
                "One-Class Support Vector Machines",
                "Fuzzy Inference"
            ]
        },
        "Field": "data",
        "title": "Task-Aware Data Selectivity in Pervasive Edge Computing Environments",
        "link": "https://ieeexplore.ieee.org/document/10730754/"
    },
    {
        "authors": [
            "Yizhang Zou",
            "Xuegang Hu",
            "Peipei Li",
            "Jun Hu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "03 September 2024",
        "doi": "10.1109/TBDATA.2024.3453760",
        "publisher": "IEEE",
        "abstract": "Multi-label stream classification aims to address the challenge of dynamically assigning multiple labels to sequentially-arrived instances. In real situations, only partial labels of instances can be observed due to the expensive human annotations, and the problem of label distribution changes arises from multiple labels in a streaming mode, but few existing works jointly consider such challenges. Motivated by this, we propose the problem of weak multi-label stream classification (WMSC) and an online classification algorithm robust to weak labels. Specifically, we incrementally update the margin-based model using information from both the past model and the current incoming instance with partially observed labels. To increase the robustness to weak labels, we first adjust the classification margin of negative labels using the label causality matrix, which is constructed by the conditional probability of label pairs. Secondly, we introduce the label prototype matrix to regulate the margin by controlling the weighting parameter of the slack term. Additionally, to handle the potential distribution changes in labels, we utilize the instance-specific threshold via online thresholding to perform binary classification, which is formulated as a regression problem. Finally, theoretical analysis and empirical experimental results are presented to demonstrate the effectiveness of WMSC in classifying unobserved streaming instances.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Vectors",
                "Robustness",
                "Prototypes",
                "Big Data",
                "Real-time systems",
                "Data models",
                "Correlation"
            ],
            "Author Keywords": [
                "multi-label",
                "stream classification",
                "weak labels",
                "large margin"
            ]
        },
        "Field": "data",
        "title": "Weak Multi-Label Data Stream Classification Under Distribution Changes in Labels",
        "link": "https://ieeexplore.ieee.org/document/10663953/"
    },
    {
        "authors": [
            "Alaa Tharwat",
            "Wolfram Schenck"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )",
        "date_of_publication": "26 January 2024",
        "doi": "10.1109/TNNLS.2024.3352279",
        "publisher": "IEEE",
        "abstract": "Recently, the massive growth of IoT devices and Internet data, which are widely used in many applications, including industry and healthcare, has dramatically increased the amount of free unlabeled data collected. However, this unlabeled data is useless if we want to learn supervised machine learning models. The expensive and time-consuming cost of labeling makes the problem even more challenging. Here, the active learning (AL) technique provides a solution by labeling small but highly informative and representative data, which guarantees a high degree of generalizability over space and improves classification performance with data we have never seen before. The task is more difficult when the active learner has no predefined knowledge, such as initial training data, and when the obtained data is incomplete (i.e., contains missing values). In previous studies, the missing data should first be imputed. Then, the active learner selects from the available unlabeled data, regardless of whether the points were originally observed or imputed. However, selecting inaccurate imputed data points would negatively affect the active learner and prevent it from selecting informative and/or representative points, thus reducing the overall classification performance of the prediction models. This motivated us to introduce a novel query selection strategy that accounts for imputation uncertainty when querying new points. For this purpose, we first introduce a novel multiple imputation method that considers feature importance in selecting the most promising feature groups for missing values estimation. This multiple imputation method provides the ability to quantify the imputation uncertainty of each imputed data point. Furthermore, in each of the two phases of the proposed active learner (exploration and exploitation), imputation uncertainty is taken into account to reduce the probability of selecting points with high imputation uncertainty. We tested the effectiveness of the propos...",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Uncertainty",
                "Labeling",
                "Data models",
                "Training data",
                "Costs",
                "Predictive models",
                "Search problems"
            ],
            "Author Keywords": [
                "Active learning (AL)",
                "imputation uncertainty",
                "missing data",
                "multiple imputation"
            ]
        },
        "Field": "data",
        "title": "Active Learning for Handling Missing Data",
        "link": "https://ieeexplore.ieee.org/document/10415057/"
    },
    {
        "authors": [
            "Xumeng Wang",
            "Shuangcheng Jiao",
            "Chris Bryan"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "10 September 2024",
        "doi": "10.1109/TVCG.2024.3456304",
        "publisher": "IEEE",
        "abstract": "Differential privacy ensures the security of individual privacy but poses challenges to data exploration processes because the limited privacy budget incapacitates the flexibility of exploration and the noisy feedback of data requests leads to confusing uncertainty. In this study, we take the lead in describing corresponding exploration scenarios, including underlying requirements and available exploration strategies. To facilitate practical applications, we propose a visual analysis approach to the formulation of exploration strategies. Our approach applies a reinforcement learning model to provide diverse suggestions for exploration strategies according to the exploration intent of users. A novel visual design for representing uncertainty in correlation patterns is integrated into our prototype system to support the proposed approach. Finally, we implemented a user study and two case studies. The results of these studies verified that our approach can help develop strategies that satisfy the exploration intent of users.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Uncertainty",
                "Data visualization",
                "Data privacy",
                "Visualization",
                "Noise",
                "Privacy",
                "Pipelines"
            ],
            "Author Keywords": [
                "Differential privacy",
                "Visual data analysis",
                "Data exploration",
                "Visualization for uncertainty illustration"
            ]
        },
        "Field": "data",
        "title": "Defogger: A Visual Analysis Approach for Data Exploration of Sensitive Data Protected by Differential Privacy",
        "link": "https://ieeexplore.ieee.org/document/10670438/"
    },
    {
        "authors": [
            "Ruikun Luo",
            "Qiang He",
            "Mengxi Xu",
            "Feifei Chen",
            "Song Wu",
            "Jing Yang",
            "Yuan Gao",
            "Hai Jin"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Parallel and Distributed Systems ( Early Access )",
        "date_of_publication": "07 November 2024",
        "doi": "10.1109/TPDS.2024.3493959",
        "publisher": "IEEE",
        "abstract": "The emergence of mobile edge computing (MEC) in distributed systems has sparked increased attention toward edge data management. A conflict arises from the disparity between limited edge resources and the continuously expanding data requests for data storage, making the reduction of data storage costs a critical objective. Despite the extensive studies of edge data deduplication as a data reduction technique, existing deduplication methods encounter numerous challenges in MEC environments. These challenges stem from disparities between edge servers and cloud data center edge servers, as well as uncertainties such as user mobility, leading to insufficient robustness in deduplication decision-making. Consequently, this paper presents a robust optimization-based approach for the edge data deduplication problem. By accounting for uncertainties including the number of data requirements and edge server failures, we propose two distinct solving algorithms: uEDDE-C, a two-stage algorithm based on column-and-constraint generation, and uEDDE-A, an approximation algorithm to address the high computation overhead of uEDDE-C. Our method facilitates efficient data deduplication in volatile edge network environments and maintains robustness across various uncertain scenarios. We validate the performance and robustness of uEDDE-C and uEDDE-A through theoretical analysis and experimental evaluations. The extensive experimental results demonstrate that our approach significantly reduces data storage cost and data retrieval latency while ensuring reliability in real-world MEC environments.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Servers",
                "Uncertainty",
                "Cloud computing",
                "Data centers",
                "Memory",
                "Robustness",
                "Resource management",
                "Optimization methods",
                "Hardware",
                "Distributed databases"
            ],
            "Author Keywords": [
                "Mobile edge computing",
                "edge data deduplication",
                "uncertainties",
                "robust optimization"
            ]
        },
        "Field": "data",
        "title": "Edge Data Deduplication under Uncertainties: A Robust Optimization Approach",
        "link": "https://ieeexplore.ieee.org/document/10747105/"
    },
    {
        "authors": [
            "Chunpu Huang",
            "Yuanyuan Zhang",
            "Jinbo Xiong",
            "Renwan Bi",
            "Youliang Tian"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "16 October 2024",
        "doi": "10.1109/JIOT.2024.3481263",
        "publisher": "IEEE",
        "abstract": "In mobile crowdsensing applications, the single type data is inadequate to reflect the complexities of the real world and meet precise task requirements. Currently, there are few works that focus on mixed data in the context of mobile crowdsensing, and there is no work considering the credit issues of sensing platform. The privacy, fairness, and reliability of assessing the quality of mixed data remain unguaranteed. Therefore, we design a high-efficiency and privacy-preserving mixed data quality assessment scheme which adopts a dual-server architecture, designs secure k-prototype clustering for quality assessment, and conducts anomaly detection to eliminate anomalous data. Furthermore, we design a fair and reliable allocation mechanism to fairly allocate reward to users based on fixed and floating reward mechanisms for incentivizing rational users to submit high-quality mixed data. To prevent payment defaults by the sensing platform, we design verifiable credential to restrict them, ensuring payment fairness and transactional reliability. Finally, through theoretical analysis and experimental evaluation, we demonstrate the effectiveness and security of the proposed scheme. The results indicate that in terms of efficiency, the time overhead of mixed data quality assessment has been significantly reduced by three orders of magnitude compared to existing schemes.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Sensors",
                "Reliability",
                "Data integrity",
                "Quality assessment",
                "Data privacy",
                "Reliability engineering",
                "Privacy",
                "Resource management",
                "Crowdsensing",
                "Mobile computing"
            ],
            "Author Keywords": [
                "Mobile crowdsensing",
                "privacy-preserving",
                "mixed data",
                "quality assessment"
            ]
        },
        "Field": "data",
        "title": "Achieving Efficient Privacy-Preserving Mixed Data Quality Assessment in Mobile Crowdsensing",
        "link": "https://ieeexplore.ieee.org/document/10720108/"
    },
    {
        "authors": [
            "Sunita Dhote",
            "S. Baskar",
            "P. Mohamed Shakeel",
            "Tejas Dhote"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "20 February 2023",
        "doi": "10.1109/TBDATA.2023.3244015",
        "publisher": "IEEE",
        "abstract": "Distributed cloud technologies enable mobile healthcare applications to support end users constantly. Data from electronic health records is made available through combination of user needs and heuristic mining. Because of inefficient data storage and reorganization, service and recommendation failures occur prematurely. A Distributed Data Analytics and Organization Model (DDAOM) is established in this article as a solution to the inefficiency of managing large amounts of data. Using this method, errors caused by performing several computations or storing large amounts of data in the medical field are minimized. Data organization and mining under predetermined schedules or factors provide information relevant to user services. One-to-many computations with varying input and output data allocations (for services) are executed in federated learning. The local input from several edges may be handled by allocating storage in a decentralized manner. The federated learning system uses the memory of past states to direct the allocation. Differentiating the states is necessary to allocate services and prevent mining in certain areas. With the help of realistic learning iterations, state management is maintained, guaranteeing the smooth deployment of services. Delays in storage and mining, uneven service provisioning, and service backlogs are used to evaluate the effectiveness of the suggested model.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Cloud computing",
                "Medical services",
                "Data mining",
                "Computational modeling",
                "Big Data",
                "Medical diagnostic imaging",
                "Data models"
            ],
            "Author Keywords": [
                "Cloud Computing",
                "Data Mining",
                "Federated Learning",
                "Healthcare Applications",
                "Scheduling"
            ]
        },
        "Field": "data",
        "title": "Cloud Computing Assisted Mobile Healthcare Systems Using Distributed Data Analytic Model",
        "link": "https://ieeexplore.ieee.org/document/10049210/"
    },
    {
        "authors": [
            "Raushan Myrzashova",
            "Saeed Hamood Alsamhi",
            "Ammar Hawbani",
            "Edward Curry",
            "Mohsen Guizani",
            "Xi Wei"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Sustainable Computing ( Early Access )",
        "date_of_publication": "04 June 2024",
        "doi": "10.1109/TSUSC.2024.3409329",
        "publisher": "IEEE",
        "abstract": "Medical healthcare centers are envisioned as a promising paradigm to handle vast data for various disease diagnoses using artificial intelligence. Traditional Machine Learning algorithms have been used for years, putting the sensitivity of patients' medical data privacy at risk. Collaborative data training, where multiple hospitals (nodes) train and share encrypted federated models, solves the issue of data leakage and unites resources of small and large hospitals from distant areas. This study introduces an innovative framework that leverages blockchain-based Federated Learning to identify 15 distinct lung diseases, ensuring the preservation of privacy and security. The proposed model has been trained on the NIH Chest Ray dataset (112 120 X-Ray images), tested, and evaluated, achieving test accuracy of 92.86%, a latency of 43.518625 ms, and a throughput of 10034017 bytes/s. Furthermore, we expose our framework blockchain to stringent empirical tests against leading cyber threats to evaluate its robustness. With resilience metrics consistently nearing 87% against three evaluated cyberattacks, the proposed framework demonstrates significant robustness and potential for healthcare applications. To the best of our knowledge, this is the first paper on the practical implementation of blockchain-empowered FL with such data and several diseases, including multiple disease coexistence detection.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Medical services",
                "Data privacy",
                "Security",
                "Data models",
                "Predictive models",
                "Federated learning",
                "Analytical models"
            ],
            "Author Keywords": [
                "Blockchain",
                "Federated Learning",
                "Data sharing",
                "Remote Healthcare",
                "Cybersecurity",
                "Adversarial Attacks",
                "Multi-Label",
                "X-Ray",
                "Lung Disease"
            ]
        },
        "Field": "data",
        "title": "Safeguarding Patient Data-Sharing: Blockchain-Enabled Federated Learning in Medical Diagnostics",
        "link": "https://ieeexplore.ieee.org/document/10547311/"
    },
    {
        "authors": [
            "Chuan Lin",
            "Guangjie Han",
            "Chang Lu",
            "Syed Bilal Hussain Shah",
            "Yu Zhang",
            "Feng Wang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Computational Social Systems ( Early Access )",
        "date_of_publication": "21 October 2024",
        "doi": "10.1109/TCSS.2024.3476321",
        "publisher": "IEEE",
        "abstract": "The rapid evolution of the Internet of Underwater Things (IoUT) has led to the widespread adoption of autonomous underwater vehicle (AUV)-assisted underwater acoustic sensor networks (UASNs) for various applications such as marine environment monitoring and resource exploration. This article introduces an energy-balanced data collection scheme tailored for AUV-supported UASNs. The proposed scheme combines a node clustering method based on a social welfare function and an intelligent path planning strategy for the AUV. The node clustering approach integrates canopy and K-means algorithms for initial node clustering, followed by reclustering using an enhanced hierarchical clustering algorithm. To balance energy distribution, Atkinson’s social welfare function is employed to select and rotate cluster heads (CHs) within each cluster. To address limited CH memory constraints, a lossless compression technique is introduced to reduce data storage requirements at the CHs. Moreover, the article introduces the use of the deep Q-network (DQN) technique for AUV path planning, considering multiple pertinent factors simultaneously. Simulation results demonstrate that the proposed data collection scheme effectively reduces energy consumption, prolongs network lifespan, and enhances data collection efficiency when compared to recent research endeavors.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data collection",
                "Energy consumption",
                "Clustering algorithms",
                "Path planning",
                "Underwater acoustics",
                "Routing protocols",
                "Robot sensing systems",
                "Signal to noise ratio",
                "Internet",
                "Data centers"
            ],
            "Author Keywords": [
                "Data compression",
                "deep Q network (DQN)",
                "hierarchical clustering",
                "Internet of Underwater Things (IoUT)"
            ]
        },
        "Field": "data",
        "title": "How to Perform Energy-Balanced Underwater Data Collection in AUV-Aided UASNs: A Social Welfare-Based Node Clustering Approach",
        "link": "https://ieeexplore.ieee.org/document/10726566/"
    },
    {
        "authors": [
            "Chixuan Wei",
            "Jidong Yuan",
            "Yi Zhang",
            "Zhongyang Yu",
            "Yanze Liu",
            "Haiyang Liu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "08 November 2024",
        "doi": "10.1109/TBDATA.2024.3495509",
        "publisher": "IEEE",
        "abstract": "Time series are often complex and rich in information but sparsely labeled and therefore challenging to model. Existing contrastive learning methods conduct augmentations and maximize their similarity. However, they ignore the similarity of adjacent timestamps and suffer from the problem of sampling bias. In this paper, we propose a self-supervised framework for learning generalizable representations of time series, called $\\mathbf {R}$ anking n $\\mathbf {E}$ ighborhood and cla $\\mathbf {S}$ s prototyp $\\mathbf {E}$ contr $\\mathbf {A}$ stive $\\mathbf {L}$ earning (RESEAL). It exploits information about similarity ranking to learn an embedding space, ensuring that positive samples are ranked according to their temporal order. Additionally, RESEAL introduces a class prototype contrastive learning module. It contrasts time series representations and their corresponding centroids as positives against truly negative pairs from different clusters, mitigating the sampling bias issue. Extensive experiments conducted on several multivariate and univariate time series tasks (i.e., classification, anomaly detection, and forecasting) demonstrate that our representation framework achieves significant improvement over existing baselines of self-supervised time series representation",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Time series analysis",
                "Contrastive learning",
                "Prototypes",
                "Big Data",
                "Representation learning",
                "Forecasting",
                "Time-frequency analysis",
                "Semantics",
                "Data augmentation",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Multivariate time series",
                "representation learning",
                "contrastive learning"
            ]
        },
        "Field": "data",
        "title": "Ranking Neighborhood and Class Prototype Contrastive Learning for Time Series",
        "link": "https://ieeexplore.ieee.org/document/10748408/"
    },
    {
        "authors": [
            "Shuqi Qin",
            "Shenghao Liu",
            "Shengjie Ye",
            "Xiaoxuan Fan",
            "Minmin Cheng",
            "Yuanyuan He",
            "Xianjun Deng",
            "Jong Hyuk Park"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Consumer Electronics ( Early Access )",
        "date_of_publication": "19 August 2024",
        "doi": "10.1109/TCE.2024.3445629",
        "publisher": "IEEE",
        "abstract": "Anomalies within data flows in the Internet of Things environment can potentially result in security vulnerabilities in consumer electronics. Therefore, it is crucial to effectively detect anomaly data to safeguard the reliability and continuous functionality of consumer electronics. Existing related works either learn from unlabeled data using unsupervised methods or leverage the limited labeled data to improve detection performance by semi-supervised methods. However, these methods usually overfit specific types of known anomalies or ignore the uncertainty when model training. To this end, we design a novel approach to jointly optimize the end-to-end detection of labeled and unlabeled anomalies. Specifically, the anomaly data detection problem investigated is first reformulated as a Markov decision process. Then, a partially labeled anomaly data detection approach (PANDA) based on prioritized deep deterministic policy gradient is proposed, which considers uncertainty when the agent makes decisions and can learn from the labeled known anomalies while continuously exploring and detecting prospective anomalies in unlabeled data. Extensive experiments on 13 datasets show that PANDA improves the AUC-ROC and AUC-PR by 3.0%-10.3% and 10.0%-73.5% and its robustness under the impact of anomaly contamination rates compared with four state-of-the-art competing methods.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Consumer electronics",
                "Uncertainty",
                "Training",
                "Security",
                "Aerospace electronics",
                "Detectors",
                "Deep reinforcement learning"
            ],
            "Author Keywords": [
                "Consumer Electronics Security",
                "Anomaly Data Detection",
                "Deep Reinforcement Learning"
            ]
        },
        "Field": "data",
        "title": "A Partially Labeled Anomaly Data Detection Approach Based on Prioritized Deep Reinforcement Learning for Consumer Electronics Security",
        "link": "https://ieeexplore.ieee.org/document/10638746/"
    },
    {
        "authors": [
            "Xu Wang",
            "Bin Dai",
            "Qiguang Miao",
            "Yiming Nie",
            "Erke Shang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Intelligent Vehicles ( Early Access )",
        "date_of_publication": "20 February 2024",
        "doi": "10.1109/TIV.2024.3367720",
        "publisher": "IEEE",
        "abstract": "This paper introduces a data augmentation method based on control theory and rule constraints, aiming to address the insufficient coverage issue in existing vehicle trajectory datasets. Grounded in control theory, the method combines the motion and safety rules of driving vehicles for data augmentation. It exhibits high interpretability, credibility, a minimal and controllable set of parameters, while maintaining physical feasibility. Additionally, a one-step Markov Decision Process is introduced to model the car following task as a short-term decision problem, adapting to unpredictable variations in the generated trajectories. Experimental results demonstrate that the proposed rule-constrained data augmentation method significantly enhances the model's performance in addressing car following issues, showcasing strong adaptability and generalization capabilities.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Automobiles",
                "Data models",
                "Trajectory",
                "Mathematical models",
                "Adaptation models",
                "Data augmentation",
                "Behavioral sciences"
            ],
            "Author Keywords": [
                "Car Following",
                "Deep Reinforcement Learning",
                "Data Augmentation",
                "One-step MDP"
            ]
        },
        "Field": "data",
        "title": "An Efficient Deep Reinforcement Learning-based Car-following Method via Rule-constrained Data Augmentation",
        "link": "https://ieeexplore.ieee.org/document/10440425/"
    },
    {
        "authors": [
            "Bohong Wang",
            "Yingying Wang",
            "Qinglai Guo",
            "Yanxi Lin",
            "Yang Yu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "21 October 2024",
        "doi": "10.1109/JIOT.2024.3483929",
        "publisher": "IEEE",
        "abstract": "With the increase in data volume, more types of data are being used and shared, especially in the power Internet of Things (IoT). However, the processes of data sharing may lead to unexpected information leakage because of the ubiquitous relevance among the different data, thus it is necessary for data owners to conduct preventive audits for data applications before data sharing to avoid the risk of key information leakage. Considering that the same data may play completely different roles in different application scenarios, data owners should know the expected data applications of the data buyers in advance and provide modified data that are less relevant to the private information of the data owners and more relevant to the nonprivate information that the data buyers need. In this paper, data sharing in the power IoT is regarded as the background, and the mutual information of the data and their implicit information is selected as the data feature parameter to indicate the relevance between the data and their implicit information or the ability to infer the implicit information from the data. Therefore, preventive audits should be conducted based on changes in the data feature parameters before and after data sharing. The probability exchange adjustment method is pro-posed as the theoretical basis of preventive audits under simplified consumption, and the corresponding optimization models are constructed and extended to more practical scenarios with multivari-ate characteristics. Finally, case studies are used to validate the effectiveness of the proposed preventive audits.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Electricity",
                "Internet of Things",
                "Mutual information",
                "Data privacy",
                "Big Data applications",
                "Uncertainty",
                "Smart meters",
                "Resource management",
                "Renewable energy sources",
                "Real-time systems"
            ],
            "Author Keywords": [
                "Preventive audits",
                "Internet of Things (IoT)",
                "privacyutility trade-off",
                "data sharing"
            ]
        },
        "Field": "data",
        "title": "Preventive Audits for Data Applications Before Data Sharing in the Power IoT",
        "link": "https://ieeexplore.ieee.org/document/10726588/"
    },
    {
        "authors": [
            "Yueyang Pi",
            "Yiqing Shi",
            "Shide Du",
            "Yang Huang",
            "Shiping Wang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "30 May 2024",
        "doi": "10.1109/TBDATA.2024.3407545",
        "publisher": "IEEE",
        "abstract": "Active learning, as a technique, aims to effectively label specific data points while operating within a designated query budget. Nevertheless, the majority of unsupervised active learning algorithms are based on shallow linear representation and lack sufficient interpretability. Furthermore, certain diversity-based methods face challenges in selecting samples that adequately represent the entire data distribution. Inspired by these reasons, in this paper, we propose an unsupervised active learning method on orthogonal projections to construct a deep neural network model. By optimizing the orthogonal projection process, we establish the connection between projection and active learning, consequently enhancing the interpretability of the proposed method. The proposed method can efficiently project the feature space onto a spanned subspace, deriving an indicator matrix while calculating the projection loss. Moreover, we consider the redundancy among samples to ensure both data point diversity and enhancement of clustering-based algorithms. Through extensive comparative experiments on six public datasets, the results demonstrate that the proposed method can effectively select more informative and representative samples and improve performance by up to 11%.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Redundancy",
                "Clustering algorithms",
                "Big Data",
                "Vectors",
                "Fitting",
                "Dimensionality reduction"
            ],
            "Author Keywords": [
                "Active learning",
                "machine learning",
                "deep learning",
                "orthogonal projection",
                "differentiable networks"
            ]
        },
        "Field": "data",
        "title": "Unsupervised Projected Sample Selector for Active Learning",
        "link": "https://ieeexplore.ieee.org/document/10542380/"
    },
    {
        "authors": [
            "Bita Fatemipour",
            "Zhe Zhang",
            "Marc St-Hilaire"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Network and Service Management ( Early Access )",
        "date_of_publication": "01 August 2024",
        "doi": "10.1109/TNSM.2024.3437165",
        "publisher": "IEEE",
        "abstract": "Data centers have undergone significant expansions in recent years, as cloud service providers seek to improve the quality of service and reduce operational costs. Cloud providers are investing heavily in inter-data center wide-area networks, which help to transport traffic between geographically distributed data centers. However, efficient workload management in complex large-scale networks with a dynamic environment is challenging. In this regard, researchers have developed various solutions to address different challenges for data transfer in inter-data center networks. In this paper, we present a comprehensive review of recent strategies and optimization schemes proposed in the literature to optimize data transfer in geographically distributed data centers. This review paper examines the challenges of data delivery and classifies recent existing solutions for addressing the issues based on communication patterns, objectives, proposed communication frameworks, and evaluation methods. In this study, we provide valuable insights into the current challenges and identify several promising research directions that require significant research endeavors in the future. The findings of this study are useful for researchers and practitioners interested in optimizing data transfer in inter-data center networks.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Cloud computing",
                "Data centers",
                "Optimization",
                "Costs",
                "Reviews",
                "Data transfer",
                "Surveys"
            ],
            "Author Keywords": [
                "Geo-distributed data centers",
                "Inter-data-center traffic",
                "Replica management",
                "Resource management",
                "Traffic engineering",
                "Data center networks",
                "Workload management",
                "Literature review",
                "Survey"
            ]
        },
        "Field": "data",
        "title": "A Survey on Replica Transfer Optimization Schemes in Geographically Distributed Data Centers",
        "link": "https://ieeexplore.ieee.org/document/10620251/"
    },
    {
        "authors": [
            "Yepeng Ding",
            "Junwei Yu",
            "Shaowen Li",
            "Hiroyuki Sato",
            "Maro G. Machizawa"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Network and Service Management ( Early Access )",
        "date_of_publication": "29 August 2024",
        "doi": "10.1109/TNSM.2024.3451995",
        "publisher": "IEEE",
        "abstract": "Data aggregation management is paramount in data-driven distributed systems. Conventional solutions premised on centralized networks grapple with security challenges concerning authenticity, confidentiality, integrity, and privacy. Recently, distributed ledger technology has gained popularity for its decentralized nature to facilitate overcoming these challenges. Nevertheless, insufficient identity management introduces risks like impersonation and unauthorized access. In this paper, we propose Degator, a data aggregation management framework that leverages self-sovereign identity and functions in decentralized networks to address security concerns and mitigate identity-related risks. We formulate fully decentralized aggregation protocols for data persistence and acquisition in Degator. Degator is compatible with existing data persistence methods, and supports cost-effective data acquisition minimizing dependency on distributed ledgers. We also conduct a formal analysis to elucidate the mechanism of Degator to tackle current security challenges in conventional data aggregation management. Furthermore, we showcase the applicability of Degator through its application in the management of decentralized neuroscience data aggregation and demonstrate its scalability via performance evaluation.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data aggregation",
                "Blockchains",
                "Soft sensors",
                "Security",
                "Data models",
                "Data privacy",
                "Distributed ledger"
            ],
            "Author Keywords": [
                "Data aggregation",
                "self-sovereign identity",
                "blockchain",
                "decentralized network",
                "Internet of Things",
                "data security"
            ]
        },
        "Field": "data",
        "title": "Data Aggregation Management With Self-Sovereign Identity in Decentralized Networks",
        "link": "https://ieeexplore.ieee.org/document/10659216/"
    },
    {
        "authors": [
            "Haoyu Liao",
            "Tong-yu Liu",
            "Jianmei Guo",
            "Bo Huang",
            "Dingyu Yang",
            "Jonathan Ding"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Parallel and Distributed Systems ( Early Access )",
        "date_of_publication": "08 November 2024",
        "doi": "10.1109/TPDS.2024.3494879",
        "publisher": "IEEE",
        "abstract": "The paper focuses on an understudied yet fundamental problem: existing methods typically average the utilization of multiple hardware threads to evaluate the available CPU resources. However, the approach could underestimate the actual usage of the underlying physical core for Simultaneous Multi-Threading (SMT) processors, leading to an overestimation of remaining resources. The overestimation propagates from microarchitecture to operating systems and cloud schedulers, which may misguide scheduling decisions, exacerbate CPU overcommitment, and increase Service Level Agreement (SLA) violations. To address the potential overestimation problem, we propose an SMT-aware and purely data-driven approach named Remaining CPU (RCPU) that reserves more CPU resources to restrict CPU overcommitment and prevent SLA violations. RCPU requires only a few modifications to the existing cloud infrastructures and can be scaled up to large data centers. Extensive evaluations in the data center proved that RCPU contributes to a reduction of SLA violations by 18% on average for 98% of all latency-sensitive applications. Under a benchmarking experiment, we prove that RCPU increases the accuracy by 69% in terms of Mean Absolute Error (MAE) compared to the state-of-the-art",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Hardware",
                "Data centers",
                "Cloud computing",
                "Servers",
                "Processor scheduling",
                "Program processors",
                "Monitoring",
                "Message systems",
                "Benchmark testing",
                "Accuracy"
            ],
            "Author Keywords": [
                "Cloud computing",
                "data center",
                "latency-sensitive applications",
                "microarchitecture",
                "QoS",
                "SMT interference"
            ]
        },
        "Field": "data",
        "title": "Retrospecting Available CPU Resources: SMT-Aware Scheduling to Prevent SLA Violations in Data Centers",
        "link": "https://ieeexplore.ieee.org/document/10748366/"
    },
    {
        "authors": [
            "Zhilin Zhao",
            "Longbing Cao",
            "Chang-Dong Wang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )",
        "date_of_publication": "14 November 2023",
        "doi": "10.1109/TNNLS.2023.3330475",
        "publisher": "IEEE",
        "abstract": "The integrity of training data, even when annotated by experts, is far from guaranteed, especially for non-independent and identically distributed (non-IID) datasets comprising both in-and out-of-distribution samples. In an ideal scenario, the majority of samples would be in-distribution, while samples that deviate semantically would be identified as out-of-distribution and excluded during the annotation process. However, experts may erroneously classify these out-of-distribution samples as in-distribution, assigning them labels that are inherently unreliable. This mixture of unreliable labels and varied data types makes the task of learning robust neural networks notably challenging. We observe that both in-and out-of-distribution samples can almost invariably be ruled out from belonging to certain classes, aside from those corresponding to unreliable ground-truth labels. This opens the possibility of utilizing reliable complementary labels that indicate the classes to which a sample does not belong. Guided by this insight, we introduce a novel approach, termed gray learning (GL), which leverages both ground-truth and complementary labels. Crucially, GL adaptively adjusts the loss weights for these two label types based on prediction confidence levels. By grounding our approach in statistical learning theory, we derive bounds for the generalization error, demonstrating that GL achieves tight constraints even in non-IID settings. Extensive experimental evaluations reveal that our method significantly outperforms alternative approaches grounded in robust statistics.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Noise measurement",
                "Task analysis",
                "Complexity theory",
                "Training data",
                "Neural networks",
                "Metalearning"
            ],
            "Author Keywords": [
                "Complementary label",
                "generalization",
                "gray learning (GL)",
                "non-independent and identically distributed (Non-IID) data",
                "out-of-distribution data"
            ]
        },
        "Field": "data",
        "title": "Gray Learning From Non-IID Data With Out-of-Distribution Samples",
        "link": "https://ieeexplore.ieee.org/document/10316586/"
    },
    {
        "authors": [
            "Zhouxuan Peng",
            "Dan Feng",
            "Jianxi Chen",
            "Jing Hu",
            "Yachun Liu",
            "Jinlei Hu",
            "Jintong Zhang",
            "Tianyu Wan",
            "Zuoning Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems ( Early Access )",
        "date_of_publication": "16 November 2023",
        "doi": "10.1109/TCAD.2023.3333284",
        "publisher": "IEEE",
        "abstract": "Data migration strategies (DMS) improve the overall performance of hybrid memory systems by migrating frequently accessed (hot) data to faster memory. However, designing an efficient DMS is challenging since the key metrics of DMS -hot data selection, migration granularity, and migration frequency -are sensitive to access patterns of workloads. Most existing strategies focus on only one of these metrics and often overlook the crucial impact of access patterns, resulting in sub-optimal performance and unnecessary migration traffic. In this paper, we propose AdaptHM, a fully access-pattern-aware Adaptive data migration strategy for Hybrid Memory systems. AdaptHM achieves adaptability on all three metrics through its unique multi-level data framework. First, AdaptHM adopts a group-level competition policy to select hot blocks, which responds faster to access patterns than threshold-based policies. Second, AdaptHM enables segment-level dynamic migration granularity by decoupling migration from remapping, which shows better access pattern resilience than existing schemes with fixed-size global migration granularity. Third, AdaptHM adjusts the migration frequency at set-level by periodically assessing the migration benefit, avoiding unnecessary migrations. Experimental results demonstrate that AdaptHM improves the performance by an average of 12.78% and reduces energy consumption by up to 37.24% compared to the state-of-the-art scheme.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Memory management",
                "Frequency modulation",
                "Metadata",
                "Behavioral sciences",
                "Degradation",
                "Bandwidth",
                "Nonvolatile memory"
            ],
            "Author Keywords": [
                "Heterogeneous Memory Systems",
                "Non-Volatile Memory",
                "Data Migration Strategy"
            ]
        },
        "Field": "data",
        "title": "AdaptHM: A Fully Adaptive Data Migration Strategy for Hybrid Memory Systems",
        "link": "https://ieeexplore.ieee.org/document/10319752/"
    },
    {
        "authors": [
            "Yangyang Long",
            "Changgen Peng",
            "Yuling Chen",
            "Weijie Tan",
            "Jing Sun"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "26 August 2024",
        "doi": "10.1109/JIOT.2024.3449412",
        "publisher": "IEEE",
        "abstract": "Fair data trading is a complex process that is often hindered by a fundamental issue of trust between data suppliers and collectors. This mistrust can lead to an impasse: data collectors hesitate to pay upfront without the data in hand, while data suppliers hold back the data until they are assured of payment. Though enlisting a trusted third party may mitigate these issues, it also presents distinct security challenges that must be carefully considered. Observing that the blockchain technique has great potential to improve security, efficiency and transparency of data trading, we present a blockchain-based fair data trading scheme, called BFFDT, which allows the data seller trade its data in part with an interested purchaser through a smart contract for revenue. In BFFDT, the data publisher first generates the authenticated tags based on the data fields and corresponding attribute values, then encrypts the corresponding attribute values individually and generates a dynamic Merkle Hash Tree (D-MHT) to ensure the consistency of the attributes and attribute values. In addition, we design an innovative pairing-based proxy re-encryption mechanism to transmit the ciphertext of a symmetric key to the purchaser’s public key via a re-encryption key without any third-party intermediary, and verifies the re-encryption key using the verifiable commitment. Furthermore, the BFFDT is formally proven to be secure against the deceitful actions of both the fraudulent seller and buyer, and the experimental outcomes further confirm that BFFDT offers high efficiency and practical applicability.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data privacy",
                "Blockchains",
                "Smart contracts",
                "Servers",
                "Internet of Things",
                "Cloud computing",
                "Access control"
            ],
            "Author Keywords": [
                "Blockchain",
                "proxy re-encryption",
                "smart contract",
                "fair data trading",
                "verifiable commitment"
            ]
        },
        "Field": "data",
        "title": "BFFDT: Blockchain-based Fair and Fine-Grained Data Trading Using Proxy Re-Encryption and Verifiable Commitment",
        "link": "https://ieeexplore.ieee.org/document/10646357/"
    },
    {
        "authors": [
            "Lin Gao",
            "Jing Lu",
            "Zekai Shao",
            "Ziyue Lin",
            "Shengbin Yue",
            "Chiokit Ieong",
            "Yi Sun",
            "Rory James Zauner",
            "Zhongyu Wei",
            "Siming Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "10 September 2024",
        "doi": "10.1109/TVCG.2024.3456145",
        "publisher": "IEEE",
        "abstract": "Large Language Models (LLMs) have shown great potential in intelligent visualization systems, especially for domainspecific applications. Integrating LLMs into visualization systems presents challenges, and we categorize these challenges into three alignments: domain problems with LLMs, visualization with LLMs, and interaction with LLMs. To achieve these alignments, we propose a framework and outline a workflow to guide the application of fine-tuned LLMs to enhance visual interactions for domain-specific tasks. These alignment challenges are critical in education because of the need for an intelligent visualization system to support beginners' self-regulated learning. Therefore, we apply the framework to education and introduce Tailor-Mind, an interactive visualization system designed to facilitate self-regulated learning for artificial intelligence beginners. Drawing on insights from a preliminary study, we identify self-regulated learning tasks and fine-tuning objectives to guide visualization design and tuning data construction. Our focus on aligning visualization with fine-tuned LLM makes Tailor-Mind more like a personalized tutor. Tailor-Mind also supports interactive recommendations to help beginners better achieve their learning goals. Model performance evaluations and user studies confirm that Tailor-Mind improves the self-regulated learning experience, effectively validating the proposed framework.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Data models",
                "Education",
                "Adaptation models",
                "Tutorials",
                "Large language models",
                "Knowledge based systems"
            ],
            "Author Keywords": [
                "Fine-tuned large language model",
                "visualization system",
                "self-regulated learning",
                "intelligent tutorial system"
            ]
        },
        "Field": "data",
        "title": "Fine-Tuned Large Language Model for Visualization System: A Study on Self-Regulated Learning in Education",
        "link": "https://ieeexplore.ieee.org/document/10670435/"
    },
    {
        "authors": [
            "Nathaniel Kang",
            "Dongeun Min",
            "Yonghun Cho",
            "Dong-Whan Ko",
            "Hyun Hak Kim",
            "Joon Yeon Choeh",
            "Jongho Im"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "04 October 2024",
        "doi": "10.1109/TBDATA.2024.3474211",
        "publisher": "IEEE",
        "abstract": "The accurate prediction of industry trends has become increasingly challenging because of unforeseen events. To address this challenge, this study proposes a deep learning approach to generate an economic sentiment index by integrating Natural Language Processing (NLP) models and image-clustering techniques. We first employ sampling techniques to create standardized online news datasets. Feature engineering techniques from the Korean Bidirectional Encoder Representations from Transformers (KoBERT) model are then used to generate relevance and sentiment scores for the textual data. Further, to enhance visualization and clustering, we transform the textual data into joint plot images, which are grouped into distinct clusters based on news categories. Finally, using Multi-criteria Decision Analysis, the various scores and cluster information are synthesized to generate the final economic sentiment index. This approach improves visualization and enhances the interpretability of the generated index. The proposed algorithm is applied to construct a new economic sentiment index for the Information and Communications Technology (ICT) industry in South Korea.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Economics",
                "Indexes",
                "Biological system modeling",
                "Industries",
                "Accuracy",
                "Sentiment analysis",
                "Surveys",
                "Real-time systems",
                "Deep learning",
                "Data models"
            ],
            "Author Keywords": [
                "data fusion",
                "deep learning",
                "economic index",
                "Forecasting",
                "KoBERT"
            ]
        },
        "Field": "data",
        "title": "Online News-Based Economic Sentiment Index",
        "link": "https://ieeexplore.ieee.org/document/10705082/"
    },
    {
        "authors": [
            "Wei Tang",
            "Xiaojun Zhang",
            "Dawu Gu",
            "Chao Huang",
            "Jingting Xue",
            "Xiangyu Liang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Cloud Computing ( Early Access )",
        "date_of_publication": "19 August 2024",
        "doi": "10.1109/TCC.2024.3445430",
        "publisher": "IEEE",
        "abstract": "Encrypted medical data outsourced to cloud servers can be used for personal health certification, health monitoring, and medical research. These data are essential to support the development of the medical industry. However, the traditional peer-to-peer data-sharing paradigm can lead to data abuse by malicious data analysis centers. Moreover, the encryption used to protect users' outsourced privacy restricts the flexibility of data retrieval. Based on the modified double trapdoor cryptosystem, we propose an authorized data retrieval scheme over aggregated encrypted medical data (ADR-AED) in cloud-assisted e-healthcare systems. In ADR-AED, patients can access and decrypt personal data and authorize the data analysis center (DAC) to retrieve corresponding data. Specifically, we design an authorized retrieval-test mechanism for a group of patients to DAC. This allows DAC to extract valuable information from a threshold number of authorized users. Additionally, each patient can flexibly retrieve finegrained medical data in different periods and submit them to a doctor for diagnostic analysis. The security analysis and performance evaluation demonstrate the feasibility of ADRAED in the deployment of cloud-assisted e-healthcare systems",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Medical diagnostic imaging",
                "Cloud computing",
                "Cryptography",
                "Medical services",
                "Encryption",
                "Data privacy",
                "Data analysis"
            ],
            "Author Keywords": [
                "Data abuse",
                "Flexibility",
                "Double trapdoor cryptosystem",
                "E-healthcare systems",
                "Authorized retrieval-test mechanism"
            ]
        },
        "Field": "data",
        "title": "Enabling Authorized Fine-Grained Data Retrieval over Aggregated Encrypted Medical Data in Cloud-Assisted E-health Systems",
        "link": "https://ieeexplore.ieee.org/document/10639478/"
    },
    {
        "authors": [
            "Yuxin Guo",
            "Deyu Bo",
            "Cheng Yang",
            "Zhiyuan Lu",
            "Zhongjian Zhang",
            "Jixi Liu",
            "Yufei Peng",
            "Chuan Shi"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "06 November 2024",
        "doi": "10.1109/TBDATA.2024.3489412",
        "publisher": "IEEE",
        "abstract": "The history of artificial intelligence (AI) has witnessed the significant impact of high-quality data on various deep learning models, such as ImageNet for AlexNet and ResNet. Recently, instead of designing more complex neural architectures as model-centric approaches, the attention of AI community has shifted to data-centric ones, which focuses on better processing data to strengthen the ability of neural models. Graph learning, which operates on ubiquitous topological data, also plays an important role in the era of deep learning. In this survey, we comprehensively review graph learning approaches from the data-centric perspective, and aim to answer three crucial questions: (1) when to modify graph data , (2) what part of the graph data needs modification to unlock the potential of various graph models, and (3) how to safeguard graph models from problematic data influence. Accordingly, we propose a novel taxonomy based on the stages in the graph learning pipeline, and highlight the processing methods for different data structures in the graph data, i.e., topology, feature and label. Furthermore, we analyze some potential problems embedded in graph data and discuss how to solve them in a data-centric manner. Finally, we provide some promising future directions for data-centric graph learning.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Training",
                "Topology",
                "Surveys",
                "Taxonomy",
                "Reviews",
                "Pipelines",
                "Data structures",
                "Chemicals",
                "Bridges"
            ],
            "Author Keywords": [
                "Data-centric learning",
                "graph neural network"
            ]
        },
        "Field": "data",
        "title": "Data-Centric Graph Learning: A Survey",
        "link": "https://ieeexplore.ieee.org/document/10746390/"
    },
    {
        "authors": [
            "Zheng Wei",
            "Huamin Qu",
            "Xian Xu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "10 September 2024",
        "doi": "10.1109/TVCG.2024.3456330",
        "publisher": "IEEE",
        "abstract": "Data videos increasingly becoming a popular data storytelling form represented by visual and audio integration. In recent years, more and more researchers have explored many narrative structures for effective and attractive data storytelling. Meanwhile, the Hero's Journey provides a classic narrative framework specific to the Hero's story that has been adopted by various mediums. There are continuous discussions about applying Hero's Journey to data stories. However, so far, little systematic and practical guidance on how to create a data video for a specific story type like the Hero's Journey, as well as how to manipulate its sound and visual designs simultaneously. To fulfill this gap, we first identified 48 data videos aligned with the Hero's Journey as the common storytelling from 109 high-quality data videos. Then, we examined how existing practices apply Hero's Journey for creating data videos. We coded the 48 data videos in terms of the narrative stages, sound design, and visual design according to the Hero's Journey structure. Based on our findings, we proposed a design space to provide practical guidance on the narrative, visual, and sound custom design for different narrative segments of the hero's journey (i.e., Departure, Initiation, Return) through data video creation. To validate our proposed design space, we conducted a user study where 20 participants were invited to design data videos with and without our design space guidance, which was evaluated by two experts. Results show that our design space provides useful and practical guidance for data storytellers effectively creating data videos with the Hero's Journey.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Videos",
                "Data visualization",
                "Visualization",
                "Bars",
                "Voting",
                "Rhythm",
                "Guidelines"
            ],
            "Author Keywords": [
                "The Hero's Journey",
                "Narrative Structure",
                "Narrative Visualization",
                "Data Visualization",
                "Data Videos"
            ]
        },
        "Field": "data",
        "title": "Telling Data Stories with the Hero's Journey: Design Guidance for Creating Data Videos",
        "link": "https://ieeexplore.ieee.org/document/10670568/"
    },
    {
        "authors": [
            "Jian-Qiang Qiu",
            "Chun-Yang Zhang",
            "C. L. Philip Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Artificial Intelligence ( Early Access )",
        "date_of_publication": "18 October 2024",
        "doi": "10.1109/TAI.2024.3483201",
        "publisher": "IEEE",
        "abstract": "Pre-trained language models (PLMs) have shown remarkable performance on question answering (QA) tasks, but they usually require fine-tuning that depends on a substantial quantity of QA pairs. Therefore, improving the performance of PLMs in scenarios with only a small number of training examples, also known as a few-shot setting, is of great practical significance. Current mitigation strategies for the few-shot QA task largely rely on pre-training a QA task-specific language model from scratch, overlooking the potential of foundational PLMs to generate QA pairs, particularly in the few-shot setting. To address this issue, we propose a prompt-based QA data augmentation method aimed at automating the creation of high-quality QA pairs. It employs the prompt-based fine-tuning method, adapting the question generation process of PLMs to the few-shot setting. Additionally, we introduce a dynamic text filling training strategy. This strategy simulates the progressive human learning process, the...",
        "issn": {
            "Electronic ISSN": "2691-4581"
        },
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Artificial intelligence",
                "Question generation",
                "Question answering (information retrieval)",
                "Predictive models",
                "Data models",
                "Data augmentation",
                "Vectors",
                "Diffusion tensor imaging",
                "Prompt engineering"
            ],
            "Author Keywords": [
                "Question answering",
                "prompt learning",
                "few-shot learning",
                "data augmentation"
            ]
        },
        "Field": "data",
        "title": "Prompt Learning for Few-Shot Question Answering via Self-Context Data Augmentation",
        "link": "https://ieeexplore.ieee.org/document/10723112/"
    },
    {
        "authors": [
            "Bridger Herman",
            "Cullen D. Jackson",
            "Daniel F. Keefe"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "10 September 2024",
        "doi": "10.1109/TVCG.2024.3456377",
        "publisher": "IEEE",
        "abstract": "Inspired by recent advances in digital fabrication, artists and scientists have demonstrated that physical data encodings (i.e., data physicalizations) can increase engagement with data, foster collaboration, and in some cases, improve data legibility and analysis relative to digital alternatives. However, prior empirical studies have only investigated abstract data encoded in physical form (e.g., laser cut bar charts) and not continuously sampled spatial data fields relevant to climate and medical science (e.g., heights, temperatures, densities, and velocities sampled on a spatial grid). This paper presents the design and results of the first study to characterize human performance in 3D spatial data analysis tasks across analogous physical and digital visualizations. Participants analyzed continuous spatial elevation data with three visualization modalities: (1) 2D digital visualization; (2) perspective-tracked, stereoscopic “fishtank” virtual reality; and (3) 3D printed data physicalization. Their tasks included tracing paths downhill, looking up spatial locations and comparing their relative heights, and identifying and reporting the minimum and maximum heights within certain spatial regions. As hypothesized, in most cases, participants performed the tasks just as well or better in the physical modality (based on time and error metrics). Additional results include an analysis of open-ended feedback from participants and discussion of implications for further research on the value of data physicalization. All data and supplemental materials are available at https://osf.io/7xdq4/.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Spatial databases",
                "Three-dimensional displays",
                "Data analysis",
                "Bars",
                "Encoding",
                "Virtual reality"
            ],
            "Author Keywords": [
                "Data physicalization",
                "virtual reality",
                "evaluation"
            ]
        },
        "Field": "data",
        "title": "Touching the Ground: Evaluating the Effectiveness of Data Physicalizations for Spatial Data Analysis Tasks",
        "link": "https://ieeexplore.ieee.org/document/10670479/"
    },
    {
        "authors": [
            "Zihao Lu",
            "Junli Wang",
            "Changjun Jiang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "13 August 2024",
        "doi": "10.1109/TBDATA.2024.3442551",
        "publisher": "IEEE",
        "abstract": "In federated learning (FL), multiple parties collaborate to train a global model by aggregating their local models while keeping private training sets isolated. One problem hindering effective model aggregation is data heterogeneity. Federated ensemble distillation tackles this problem by using fused local-model knowledge to train the global model rather than directly averaging model parameters. However, most existing methods fuse all knowledge indiscriminately, which makes the global model inherit some data-heterogeneity-caused flaws from local models. While knowledge filtering is a potential coping method, its implementation in FL is challenging due to the lack of public data for knowledge validation. To address this issue, we propose a novel data-free approach (FedKFD) that synthesizes credible labeled data to support knowledge filtering and distillation. Specifically, we construct a prediction capability description to characterize the samples where a local model makes correct predictions. FedKFD explores the intersection of local-model-input space and prediction capability descriptions with a conditional generator to synthesize consensus-labeled proxy data. With these labeled data, we filter for relevant local-model knowledge and further train a robust global model through distillation. The theoretical analysis and extensive experiments demonstrate that our approach achieves improved generalization, superior performance, and compatibility with other FL efforts.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Predictive models",
                "Generators",
                "Training",
                "Servers",
                "Big Data",
                "Federated learning"
            ],
            "Author Keywords": [
                "Federated learning",
                "knowledge distillation",
                "knowledge filtering",
                "data synthesis"
            ]
        },
        "Field": "data",
        "title": "Data-Free Knowledge Filtering and Distillation in Federated Learning",
        "link": "https://ieeexplore.ieee.org/document/10634815/"
    },
    {
        "authors": [
            "Prakash Tekchandani",
            "Abhishek Bisht",
            "Ashok Kumar Das",
            "Neeraj Kumar",
            "Marimuthu Karuppiah",
            "Pandi Vijayakumar",
            "Youngho Park"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "29 April 2024",
        "doi": "10.1109/TBDATA.2024.3394700",
        "publisher": "IEEE",
        "abstract": "With the rise of Big data generated by Internet of Things (IoT) smart devices, there is an increasing need to leverage its potential while protecting privacy and maintaining confidentiality. Privacy and confidentiality in big data aims to enable data analysis and machine learning on large-scale datasets without compromising the dataset sensitive information. Usually current big data analytics models either efficiently achieves privacy or confidentiality. In this article, we aim to design a novel blockchain-enabled secured collaborative machine learning approach that provides privacy and confidentially on large scale datasets generated by IoT devices. Blockchain is used as secured platform to store and access data as well as to provide immutability and traceability. We also propose an efficient approach to obtain robust machine learning model through use of cryptographic techniques and differential privacy in which the data among involved parties is shared in a secured way while maintaining privacy and confidentiality of the data. The experimental evaluation along with security and performance analysis show that the proposed approach provides accuracy and scalability without compromising the privacy and security.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Blockchains",
                "Big Data",
                "Security",
                "Privacy",
                "Differential privacy",
                "Machine learning"
            ],
            "Author Keywords": [
                "Internet of Things (IoT)",
                "Differential privacy",
                "Collaborative model learning",
                "Blockchain",
                "Big data analytics",
                "Security"
            ]
        },
        "Field": "data",
        "title": "Blockchain-Enabled Secure Collaborative Model Learning using Differential Privacy for IoT-Based Big Data Analytics",
        "link": "https://ieeexplore.ieee.org/document/10509745/"
    },
    {
        "authors": [
            "Weilong Ding",
            "Tianpu Zhang",
            "Honghao Gao",
            "Qi Yu",
            "Jianwu Wang",
            "Zhuofeng Zhao"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Consumer Electronics ( Early Access )",
        "date_of_publication": "18 June 2024",
        "doi": "10.1109/TCE.2024.3415615",
        "publisher": "IEEE",
        "abstract": "The proliferation of Internet of Things (IoT) and the adoption of Edge Computing paradigms have led to a substantial increase in data volume. Data imbalance is inevitable in distributed environment composed of edge nodes, due to inherent diversity in processing capabilities, network connectivity, and geographical distribution. In specific highway domain, such edge derived data makes predictive precision of crucial traffic flow hard to guarantee. First, data imbalance would deteriorate the predictive performance at certain locations. Second, various spatial dependencies existed in highway network have not been sufficiently explored. To address these challenges in highway domain, we propose a novel method for daily traffic flow prediction on imbalanced data. On the one hand, a pre-processing strategy is presented to normalize traffic flow data in long-tail distribution. The data is collected from highway electronics through edge nodes. On the other hand, a multi-graph convolution model is designed to capture spatio-temporal features in distinct physical, statistical and latent perspectives. Incorporating external characteristics like meteorological and calendar features, prediction can be achieved precisely. Through extensive experiments and case studies conducted on a Chinese provincial highway, our method demonstrates a significant improvement of predictive accuracy than baselines and outstanding effects in a practical project.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Road transportation",
                "Data models",
                "Topology",
                "Accuracy",
                "Network topology",
                "Internet of Things",
                "Deep learning"
            ],
            "Author Keywords": [
                "Traffic flow prediction",
                "Data imbalance",
                "Spatio-temporal features",
                "Multi-graph fusion",
                "Graph convolutional network"
            ]
        },
        "Field": "data",
        "title": "Multi-Graph Spatio-Temporal Convolution for Traffic Flow Prediction Focusing on Edge Derived Imbalanced Data From Highway Electronics",
        "link": "https://ieeexplore.ieee.org/document/10560034/"
    },
    {
        "authors": [
            "Xiao Ke",
            "Qiuqin Chen",
            "Hao Liu",
            "Wenzhong Guo"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Circuits and Systems for Video Technology ( Early Access )",
        "date_of_publication": "30 July 2024",
        "doi": "10.1109/TCSVT.2024.3435977",
        "publisher": "IEEE",
        "abstract": "Few-shot object detection achieves rapid detection of novel-class objects by training detectors with a minimal number of novel-class annotated instances. Transfer learning-based few-shot object detection methods have shown better performance compared to other methods such as meta-learning. However, when training with base-class data, the model may gradually bias towards learning the characteristics of each category in the base-class data, which could result in a decrease in learning ability during fine-tuning on novel classes, and further overfitting due to data scarcity. In this paper, we first find that the generalization performance of the base-class model has a significant impact on novel class detection performance and proposes a generalization feature extraction network framework to address this issue. This framework perturbs the base model during training to encourage it to learn generalization features and solves the impact of changes in object shape and size on overall detection performance, improving the generalization performance of the base model. Additionally, we propose a feature-level data augmentation method based on self-distillation to further enhance the overall generalization ability of the model. Our method achieves state-of-the-art results on both the COCO and PASCAL VOC datasets, with a 6.94% improvement on the PASCAL VOC 10-shot dataset.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Data models",
                "Object detection",
                "Training",
                "Adaptation models",
                "Computational modeling",
                "Shape"
            ],
            "Author Keywords": [
                "Transfer learning",
                "few-shot learning",
                "object detection",
                "data augmentation",
                "self-distillation"
            ]
        },
        "Field": "data",
        "title": "GFENet: Generalization Feature Extraction Network for Few-Shot Object Detection",
        "link": "https://ieeexplore.ieee.org/document/10614626/"
    },
    {
        "authors": [
            "Susan Helser",
            "Mark Hwang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Technology and Society ( Early Access )",
        "date_of_publication": "01 October 2024",
        "doi": "10.1109/TTS.2024.3465935",
        "publisher": "IEEE",
        "abstract": "This research provides an in-depth exploration of the intersection of cybersecurity, artificial intelligence (AI), and big data (CAB) across six sectors in manufacturing and public service. It highlights the transformative potential of these technologies in reshaping industries and enhancing efficiency while also underscoring the challenges they present, particularly in data protection and privacy. To put these challenges in context, a security model consisting of three dimensions (security goal, security control, and data state) is developed and applied to six sectors. The resultant models represent a major step toward more effective risk assessment in practice. They should also inspire research efforts to further advance CAB more effectively and responsibly.",
        "issn": {
            "Electronic ISSN": "2637-6415"
        },
        "keywords": {
            "IEEE Keywords": [
                "Computer security",
                "Artificial intelligence",
                "Security",
                "Big Data",
                "Manufacturing",
                "Data models",
                "Autonomous vehicles",
                "Ransomware",
                "Computer hacking",
                "Real-time systems"
            ],
            "Author Keywords": [
                "Computer security",
                "artificial intelligence",
                "big data",
                "big data applications",
                "smart cities",
                "smart devices",
                "privacy",
                "data protection"
            ]
        },
        "Field": "data",
        "title": "AI and Big Data: Synergies and Cybersecurity Challenges in Key Sectors",
        "link": "https://ieeexplore.ieee.org/document/10701531/"
    },
    {
        "authors": [
            "Xiao Jiang",
            "Yiyuan Xie",
            "Yushu Zhang",
            "Yichen Ye",
            "Fang Xu",
            "Lili Li",
            "Ye Su",
            "Zhuang Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Circuits and Systems for Video Technology ( Early Access )",
        "date_of_publication": "12 September 2024",
        "doi": "10.1109/TCSVT.2024.3459024",
        "publisher": "IEEE",
        "abstract": "Reversible data hiding in encrypted image (RDHEI) is a powerful security technology that aims to hide data into the encrypted image without any distortions of data extraction and image recovery. Most existing RDHEI methods using vacated room-based data embedding algorithms face challenges in improving embedding capacity and security. In this paper, we develop a novel data hiding strategy via fusion based on reservoir computing (RC) system, upon which a new RDHEI scheme is further proposed. In the proposed scheme, the original image is first encrypted by the stream cipher-based encryption algorithm using the secret keys generated by an optical chaotic system. Then, by means of the RC system, the generated encrypted image can be fused with the secret data to produce the final masked image. Unlike the existing data embedding algorithms based on vacating rooms, the RC-based fusion strategy allows for hiding secret data comparable to the volume of the cover image into the encrypted image so that a higher embedding capacity can be greatly afforded. Moreover, the proposed strategy involves a chaotic transformation via the reservoir of RC system during data hiding, producing a masked image that is completely different from the encrypted image, thus the security is greatly enhanced. Experimental results show the contributions in improving the embedding capacity and security, and also demonstrate the superiority of the proposed scheme compared to some existing RDHEI methods.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Cryptography",
                "Optical imaging",
                "Encryption",
                "Stimulated emission",
                "Correlation",
                "Data integration",
                "Termination of employment"
            ],
            "Author Keywords": [
                "Reversible data hiding in encrypted image",
                "optical chaotic system",
                "reservoir computing",
                "data fusion strategy"
            ]
        },
        "Field": "data",
        "title": "Reversible Data Hiding in Encrypted Images Using Reservoir Computing Based Data Fusion Strategy",
        "link": "https://ieeexplore.ieee.org/document/10679220/"
    },
    {
        "authors": [
            "Jie Chen",
            "Shengxiang Yang",
            "Conor Fahy",
            "Zhu Wang",
            "Yinan Guo",
            "Yingke Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )",
        "date_of_publication": "27 October 2023",
        "doi": "10.1109/TNNLS.2023.3325556",
        "publisher": "IEEE",
        "abstract": "Data stream clustering can be performed to discover the patterns underlying continuously arriving sequences of data. A number of data stream clustering algorithms for finding clusters in arbitrary shapes and handling outliers, such as density-based clustering algorithms, have been proposed. However, these algorithms are often limited in their ability to construct and merge microclusters by measuring the Euclidean distances between high-dimensional data objects, e.g., transferring valuable knowledge from historical landmark windows to the current landmark window, and exploiting evolving subspace structures adaptively. We propose an online sparse representation clustering (OSRC) method to learn an affinity matrix for evaluating the relationships among high-dimensional data objects in evolving data streams. We first introduce a low-dimensional projection (LDP) into sparse representation to adaptively reduce the potential negative influence associated with the noise and redundancy contained in high-dimensional data. Then, we take advantage of the\nl\n2,1\n-norm optimization technique to choose the appropriate number of representative data objects and form a specific dictionary for sparse representation. The specific dictionary is integrated into sparse representation to adaptively exploit the evolving subspace structures of the high-dimensional data objects. Moreover, the data object representatives from the current landmark window can transfer valuable knowledge to the next landmark window. The experimental results based on a synthetic dataset and six benchmark datasets validate the effectiveness of the proposed method compared to that of state-of-the-art methods for data stream clustering.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Streams",
                "Clustering algorithms",
                "Dictionaries",
                "Sparse matrices",
                "Heuristic algorithms",
                "Optimization",
                "Data models"
            ],
            "Author Keywords": [
                "Clustering",
                "data stream",
                "high-dimensional data",
                "sparse representation",
                "subspace structure"
            ]
        },
        "Field": "data",
        "title": "Online Sparse Representation Clustering for Evolving Data Streams",
        "link": "https://ieeexplore.ieee.org/document/10298256/"
    },
    {
        "authors": [
            "Guanqi Fang",
            "Rong Pan",
            "Yizi Wang",
            "Haili He",
            "Weiqin Yu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Reliability ( Early Access )",
        "date_of_publication": "14 October 2024",
        "doi": "10.1109/TR.2024.3471796",
        "publisher": "IEEE",
        "abstract": "For many industrial products, accelerated degradation tests (ADTs) serve as an efficient approach to their reliability prediction. Modeling and analyzing the ADT data involves assessing the accelerating effect brought by stress variables, as well as accounting for multiple variation sources. In many situations, in addition to unit-to-unit variabilities seen in both the initial performance levels and degradation rates, an intriguing observation is that these two factors exhibit a strong correlation. Motivated by a real application of optical media, this article proposes a general Wiener process for modeling such ADT data, and it provides a closed-form lifetime distribution. An expectation-maximization algorithm is developed to infer the unknown parameters. An extension to the Bayesian approach under Stan framework is made to enable practitioners to seamlessly incorporate prior domain knowledge into their analysis. Simulation studies and a case application demonstrate the good performance of the proposed methodology.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Degradation",
                "Correlation",
                "Stress",
                "Bayes methods",
                "Vectors",
                "Inspection",
                "Data models",
                "Life estimation",
                "Analytical models",
                "Temperature control"
            ],
            "Author Keywords": [
                "Accelerated degradation test (ADT)",
                "Bayesian inference",
                "expectation-maximization (EM) algorithm",
                "initiation-growth correlation",
                "random effects",
                "Wiener process"
            ]
        },
        "Field": "data",
        "title": "Exploring Initiation-Growth Correlation in Accelerated Degradation Testing Data: Both Classical and Bayesian Approaches",
        "link": "https://ieeexplore.ieee.org/document/10716210/"
    },
    {
        "authors": [
            "Guipeng Lan",
            "Shuai Xiao",
            "Jiachen Yang",
            "Jiabao Wen",
            "Meng Xi"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Journal of Biomedical and Health Informatics ( Early Access )",
        "date_of_publication": "30 October 2023",
        "doi": "10.1109/JBHI.2023.3327485",
        "publisher": "IEEE",
        "abstract": "In the decade, artificial intelligence has achieved great popularity and applications in medicine and healthcare. Various AI-based algorithms have shown astonishing performance. However, in various data-driven smart healthcare algorithms, the problem of incomplete dataset remains a huge challenge. In this paper, we propose a data completeness enhancement algorithm based on generative AI (i.e., GenAI-DAA) to solve the problems of the in-sufficient data for model training, the data imbalance, and the biases of the training samples. We first construct the cognitive field of the generative models and effectively understand the state of incomplete cognition in generative models. Secondly, on this basis, we propose a quest algorithm for abnormal samples in the cognitive field based on local outlier factor. By fine-grained value evaluation, abnormal samples are given more refined attention. Finally, integrating the above process through multiple cognitive adjustments, GenAI-DAA gradually improves the cognitive ability. GenAI-DAA can be summarized as “Quest−→Estimate−→Tune-up”. We have conducted extensive experiments to demonstrate the effectiveness of our proposed algorithm, and shown widely applications to some typical data-driven smart healthcare algorithms",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Medical services",
                "Image enhancement",
                "Bioinformatics",
                "Training",
                "Cognition",
                "Training data"
            ],
            "Author Keywords": [
                "Generative AI",
                "Data completeness",
                "datadriven",
                "smart healthcare"
            ]
        },
        "Field": "data",
        "title": "Generative AI-based Data Completeness Augmentation Algorithm for Data-driven Smart Healthcare",
        "link": "https://ieeexplore.ieee.org/document/10301488/"
    },
    {
        "authors": [
            "Guangyu Yan",
            "Wei Han",
            "Chang Liu",
            "Bowang Zhang",
            "Meixuan Li"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Circuits and Systems II: Express Briefs ( Early Access )",
        "date_of_publication": "18 October 2024",
        "doi": "10.1109/TCSII.2024.3483575",
        "publisher": "IEEE",
        "abstract": "This article presents a novel simultaneous wireless power and data transfer (SWPDT) system that combines inductive and capacitive couplings, featuring full-duplex communication with high data transfer rates. Specifically, the power and forward data are transferred through inductive coupling respectively by means of the DD coils and Q coils, while the backward data is transferred through capacitive coupling by means of the stray capacitances. Because of the decoupling characteristic of the DDQ coil structure and the use of two coupling types, the interferences among the power, forward data, and backward data are relatively low. By integrating the two coupling types, a comprehensive circuit model of full-duplex data transfer is established and analyzed. Finally, a 145-W prototype is actualized with 91.4% power transfer efficiency. The forward and backward data transfer rates are 150 kbps and 600 kbps, respectively, demonstrating the feasibility of the proposed system.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data transfer",
                "Coils",
                "Couplings",
                "Capacitance",
                "Equivalent circuits",
                "Interference",
                "Circuits",
                "Integrated circuit modeling",
                "Full-duplex system",
                "Topology"
            ],
            "Author Keywords": [
                "simultaneous wireless power and data transfer (SWPDT)",
                "full-duplex",
                "inductive coupling",
                "capacitive coupling",
                "data transfer rates"
            ]
        },
        "Field": "data",
        "title": "A Simultaneous Wireless Power and Full-Duplex Data Transfer System Using a Mix of Inductive and Capacitive Couplings",
        "link": "https://ieeexplore.ieee.org/document/10722032/"
    },
    {
        "authors": [
            "Siyi Lv",
            "Yanyu Huang",
            "Xinhao Li",
            "Tong Li",
            "Liang Guo",
            "Xiaofeng Chen",
            "Zheli Liu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Knowledge and Data Engineering ( Early Access )",
        "date_of_publication": "01 November 2023",
        "doi": "10.1109/TKDE.2023.3329234",
        "publisher": "IEEE",
        "abstract": "Dynamic symmetric searchable encryption (SSE) enables clients to perform searches and updates on an encrypted database outsourced to an untrusted server while preserving the privacy of data and queries. For restricting information leakage, it is very important to limit what the server can learn about the deleted data during searches after the deletion, i.e., to satisfy backward privacy. However, previous backward privacy definitions only considered the logical deletion of keywords in documents while ignoring security risks caused by the actual deletion of documents. Moreover, existing SSE schemes often depend on heavy cryptographic primitives for achieving high-level backward privacy, which greatly degrades the end-to-end performance. To this end, we define a new backward privacy notion named BP-DEL, which restricts the information leakage of the actual deletion. Moreover, we design a hybrid index structure that provides BP-DEL for SSE schemes such that they support deletions securely. Based on the hybrid index, we propose a BP-DEL construction named LUNA and design its protocols with a trusted execution environment (TEE) to maintain the index efficiently. Finally, we implement LUNA in the MySQL database by encapsulating it in UDFs. The experimental results show that LUNA has a performance much better than previous works satisfying BP-DEL.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Indexes",
                "Servers",
                "Databases",
                "Privacy",
                "Games",
                "Data privacy",
                "Protocols"
            ],
            "Author Keywords": [
                "Backward privacy",
                "dynamic symmetric searchable encryption",
                "the trusted execution environment"
            ]
        },
        "Field": "data",
        "title": "LUNA: Efficient Backward-Private Dynamic Symmetric Searchable Encryption Scheme With Secure Deletion in Encrypted Database",
        "link": "https://ieeexplore.ieee.org/document/10304297/"
    },
    {
        "authors": [
            "Yifeng Zhu",
            "Anfeng Liu",
            "Neal N Xiong",
            "Hangcheng Dong",
            "Shaobo Zhang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Services Computing ( Early Access )",
        "date_of_publication": "27 September 2024",
        "doi": "10.1109/TSC.2024.3470320",
        "publisher": "IEEE",
        "abstract": "Truth and Privacy-preserving service are two key issues for data collection in Mobile Crowd Sensing (MCS). However, most of the existing data collection studies use CRH to calculate the truth value, which is difficult to guarantee the data accuracy. The proposed privacy-preserving service methods either neglect the truth-value computation or still adopt the CRH method. To solve the challenge, we propose a Reputation and Privacy-Preserving Service based Truth Data Collection (RPPS-TDC) scheme to achieve the privacy-preserving accurate data collection for MCS. RPPS-TDC scheme consists of two steps: worker trust calculation and reputation-based truth value calculation. Firstly, data requester performs the initial weights calculation on the received data using DBCRH method. Secondly, reputation center uses the initial weights to update the reputation, which is based on the trustworthy worker inference. Finally, the workers are reweighted according to their reputation. We select workers based on trust_MaxHeap, thus obtaining more accurate data. At the same time, we give workers payments based on their trust weights. All the above operations are completed under data encryption, ensuring that only the data requesters have access to the workers' submitted data. The platform consists of mining nodes, and reputation center resides on the blockchain, thus achieving distributed computing which overcomes the shortcomings of the traditional MCS system. Extensive experiments demonstrate that RPPS-TDC is effective and outperforms previous strategies in two key performance metrics: data accuracy and compensation rationality allocation.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data privacy",
                "Sensors",
                "Blockchains",
                "Protection",
                "Accuracy",
                "Crowdsensing",
                "Mobile computing",
                "Data integrity",
                "Costs",
                "Temperature sensors"
            ],
            "Author Keywords": [
                "Mobile Crowd Sensing",
                "Data Privacy-Preserving service",
                "Reputation computing",
                "Truth data discovery",
                "Blockchain"
            ]
        },
        "Field": "data",
        "title": "RPPS-TDC: Reputation and Privacy-Preserving Services based Truth Data Collection for Blockchain-Enabled Crowdsensing",
        "link": "https://ieeexplore.ieee.org/document/10697423/"
    },
    {
        "authors": [
            "Morad Alizadeh",
            "Mahmoud Afshari",
            "Javier E. Contreras-Reyes",
            "Danial Mazarei",
            "Haitham M. Yousof"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Reliability ( Early Access )",
        "date_of_publication": "02 August 2024",
        "doi": "10.1109/TR.2024.3425278",
        "publisher": "IEEE",
        "abstract": "Threshold risk analysis based on extreme stress data assess the probability of events that exceeds a certain threshold in a dataset characterized by extreme values or stresses. This type of analysis is often used in finance, insurance, environmental science, and engineering, where understanding and managing extreme events are crucial. This article proposed the extended Gompertz (ExGo) model for analyzing Mean of Order P (MOOP\n[P]\n) and statistical threshold risk analysis based on real extreme stress data. This study examined the statistical properties of the proposed model and its efficiency. Several estimation methods (maximum likelihood, Anderson–Darling, ordinary least squares, Cramér–von Mises, weighted least squares, and right-tail Anderson–Darling), were evaluated through simulations and experiments to determine their effectiveness. The comparisons were based on bias and the root mean square error. Additionally, proposed distribution was applied to reliability and stress data, demonstrating its applicability and flexibility in modeling. This study focused on MOOP\n[P]\nanalysis using the ExGo model to determine the optimal parameter P , crucial for extreme stress data analysis in engineering and reliability contexts. Furthermore, proposed distribution is employed in various risk measurement and analysis indicators, including value-at-risk, tail-value-at-risk, tail variance, and tail mean-variance indicators, with emphasis on their application in reliability and engineering, particularly concerning change in stress data and breaking stress data.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Tail",
                "Analytical models",
                "Loss measurement",
                "Uncertainty",
                "Stress",
                "Shape",
                "Root mean square"
            ],
            "Author Keywords": [
                "Breaking stress data",
                "Gompertz (Go) distribution",
                "mean of order P",
                "stress data",
                "threshold risk analysis",
                "value-at-risk"
            ]
        },
        "Field": "data",
        "title": "The Extended Gompertz Model: Applications, Mean of Order P Assessment and Statistical Threshold Risk Analysis Based on Extreme Stresses Data",
        "link": "https://ieeexplore.ieee.org/document/10621025/"
    },
    {
        "authors": [
            "Xuelin Qian",
            "Wenxuan Wang",
            "Yu-Gang Jiang",
            "Xiangyang Xue",
            "Yanwei Fu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Pattern Analysis and Machine Intelligence ( Early Access )",
        "date_of_publication": "27 September 2024",
        "doi": "10.1109/TPAMI.2024.3469952",
        "publisher": "IEEE",
        "abstract": "Deep learning models have emerged as strong and efficient tools that can be applied to a broad spectrum of complex learning problems and many real-world applications. However, more and more works show that deep models are vulnerable to adversarial examples. Compared to vanilla attack settings, this paper advocates a more practical setting of data-free black-box attack, for which the attackers can completely not access the structures and parameters of the target model, as well as the intermediate features and any training data associated with the model. To tackle this task, previous methods generate transferable adversarial examples from a transparent substitute model to the target model. However, we found that these works have the limitations of taking static substitute model structure for different targets , only using hard synthesized examples once , and still relying on data statistics of the target model . This may potentially harm the performance of attacking the target model. To this end, we propose a novel Dynamic Routing and Knowledge Re-Learning framework (DraKe) to effectively learn a dynamic substitute model from the target model. Specifically, given synthesized training samples, a dynamic substitute structure learning strategy is proposed to adaptively generate optimal substitute model structure via a policy network according to different target models and tasks. To facilitate the substitute training, we present a graph-based structure information learning to capture the structural knowledge learned from the target model. For the inherent limitation that online data generation can only be learned once, a dynamic knowledge re-learning strategy is proposed to adjust the weights of optimization objectives and re-learn hard samples. Extensive experiments on four public image classification datasets and one face recognition benchmark are conducted to evaluate the efficacy of our Drake. We can obtain significant improvement compared with state-of-the-art ...",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Training",
                "Closed box",
                "Adaptation models",
                "Training data",
                "Computational modeling",
                "Generators",
                "Logic gates",
                "Data privacy",
                "Robustness"
            ],
            "Author Keywords": [
                "Adversarial attack",
                "data-free attack",
                "dynamic network",
                "knowledge re-learning",
                "substitute training"
            ]
        },
        "Field": "data",
        "title": "Dynamic Routing and Knowledge Re-Learning for Data-Free Black-Box Attack",
        "link": "https://ieeexplore.ieee.org/document/10697391/"
    },
    {
        "authors": [
            "Yao Zhao",
            "Youyang Qu",
            "Yong Xiang",
            "Feifei Chen",
            "Md Palash Uddin",
            "Longxiang Gao"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Services Computing ( Early Access )",
        "date_of_publication": "14 October 2024",
        "doi": "10.1109/TSC.2024.3479909",
        "publisher": "IEEE",
        "abstract": "M obile E dge C omputing (MEC) is an emerging technology, where App vendors are allowed to cache multiple data replicas on geographically distributed edge servers to serve adjacent mobile subscribers. However, this benefit introduces an extra workload for edge servers and App vendors, as they must audit the integrity of multiple data replicas periodically considering various threats caused by distributed and dynamic MEC environments. The large-scale growth of data replicas certainly is a challenge to design more efficient E dge D ata I ntegrity (EDI) verification approaches. Existing solutions are mostly limited to improving efficiency by optimizing proof generation and verification methods, while the improvement is still far from satisfactory due to adopting indiscriminate inspection philosophy (checking all data replicas without discrimination). In this paper, we make the first attempt to abstract a pre-processing phase and correspondingly study the U nreliable data R eplica S election (URS) problem. It can be seamlessly integrated into existing EDI solutions by solving the URS problem at the start of each verification round. Such pre-selection can significantly enhance overall EDI verification efficiency by incorporating the cache service Q uality o f S ervice (QoS) and verification success rate, especially in scenarios with a large number of data replicas. Specifically, we first formalize the URS problem as a constrained optimization problem, and further prove its\nNP\n-hardness. To address the problem efficiently, we transform it into an easy-to-handle form and develop a P riority-based approach named URS-P. Both theoretical analysis and experimental evaluation validate the effectiveness and efficiency of our proposed solution.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Quality of service",
                "Servers",
                "Distributed databases",
                "Inspection",
                "Monitoring",
                "Data integrity",
                "Optimization",
                "Real-time systems",
                "Accuracy",
                "Vehicle safety"
            ],
            "Author Keywords": [
                "Edge data integrity",
                "unreliable data replica",
                "selection algorithm",
                "optimization",
                "submodular function"
            ]
        },
        "Field": "data",
        "title": "Winning at the Starting Line: Unreliable Data Replica Selection for Edge Data Integrity Verification",
        "link": "https://ieeexplore.ieee.org/document/10715711/"
    },
    {
        "authors": [
            "Houda Rafi",
            "Yannick Benezeth",
            "Fan Yang Song",
            "Philippe Reynaud",
            "Emmanuel Arnoux",
            "Cedric Demonceaux"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "17 September 2024",
        "doi": "10.1109/JIOT.2024.3462302",
        "publisher": "IEEE",
        "abstract": "Recent advancements in wearable biosensor technology have significantly enhanced the precision and ease of collecting physiological data. This has proven particularly useful in monitoring stress among drivers. However, the sensitive nature of this data raises significant privacy concerns. To tackle these challenges, Federated Learning (FL) has emerged as a novel solution to safeguard data privacy by decentralizing model training to individual devices, eliminating the need for data sharing. This approach is compliant with strict privacy regulations like the GDPR (EU) and HIPAA (US), significantly reducing data breach risks and data transfer costs. Despite its benefits, Federated Learning (FL) struggles with non-independent and identically distributed (non-IID) data. This issue hampers FL model performance and adaptability by complicating convergence with a generalized model. To address this limitation, we introduce in this paper an innovative Tree-based Personalized Clustered Federated Learning (TPCFL) approach. TPCFL effectively exploits similarities in drivers’ private data characteristics to assign each driver a personalized model relying on a tree-based clustering approach. Grounded in the realm of individuals clustering in FL to address non-IID data challenges, notably recognized as Clustered Federated Learning (CFL), TPCFL is augmented with a novel tree-based clustering approach and a tailored cluster selection technique, enabling it to adeptly address core CFL challenges such as hyperparameter optimization for cluster selection and integration of new unlabeled drivers. Experiments demonstrated the superior performance of the proposed clustering method and highlighted TPCFL’s efficiency in achieving an optimal balance between personalized and generalized learning, showcasing its effectiveness on two public datasets.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Biomedical monitoring",
                "Stress",
                "Vehicles",
                "Federated learning",
                "Data models",
                "Monitoring",
                "Data privacy"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "Driver stress monitoring",
                "Physiological data",
                "Privacy preserving machine learning",
                "Federated Learning",
                "Clustered Federated Learning",
                "Non-IID data",
                "Model personalization"
            ]
        },
        "Field": "data",
        "title": "Tree-Based Personalized Clustered Federated Learning: A Driver Stress Monitoring Through Physiological Data Case Study",
        "link": "https://ieeexplore.ieee.org/document/10681457/"
    },
    {
        "authors": [
            "Guanjin Qu",
            "Huaming Wu",
            "Ruidong Li"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Network ( Early Access )",
        "date_of_publication": "15 October 2024",
        "doi": "10.1109/MNET.2024.3481262",
        "publisher": "IEEE",
        "abstract": "With the proliferation of Telematics and autonomous driving, vehicles are generating increasing volumes of data from numerous sensors. To accommodate this influx of in-vehicle data, Data Centers (DCs) play a pivotal role. These DCs must possess ample storage capacity and bandwidth to cater to the rising demand for in-vehicle data uploads. Meanwhile, ensuring the security and integrity of this data is paramount to providing reliable information when needed by car companies or users. The cold nature of in-vehicle data, with much of it remaining unused for extended periods, poses significant storage and operational challenges for DCs. In this paper, we propose a potentially viable solution by leveraging DNA molecules for information storage. We present the architecture of the new data center and its storage process. Compared to conventional approaches, utilizing DNA molecules for storing in-vehicle data can substantially reduce the operating costs of DCs, while greatly enhancing the storage lifespan and density of information. Finally, we address the practical challenges associated with implementing DNA storage and propose potential solutions to overcome them.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "DNA",
                "Data centers",
                "Costs",
                "Sequential analysis",
                "Media",
                "Telematics",
                "Sensors",
                "Security",
                "Hard disks",
                "Data privacy"
            ],
            "Author Keywords": [
                "Vehicle to Everything",
                "Data Center",
                "DNA-based Data Storage",
                "Long-term Storage",
                "Telematics"
            ]
        },
        "Field": "data",
        "title": "DNA Storage Promotes Long-term Storage of Internet of Vehicles Data",
        "link": "https://ieeexplore.ieee.org/document/10718314/"
    },
    {
        "authors": [
            "Sisi Li",
            "Guanzhong Liu",
            "Tianxiang Wei",
            "Shichao Jia",
            "Jiawan Zhang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "28 February 2024",
        "doi": "10.1109/TVCG.2024.3370654",
        "publisher": "IEEE",
        "abstract": "Obtaining high-quality labeled training data poses a significant bottleneck in the domain of machine learning. Data programming has emerged as a new paradigm to address this issue by converting human knowledge into labeling functions(LFs) to quickly produce low-cost probabilistic labels. To ensure the quality of labeled data, data programmers commonly iterate LFs for many rounds until satisfactory performance is achieved. However, the challenge in understanding the labeling iterations stems from interpreting the intricate relationships between data programming elements, exacerbated by their many-to-many and directed characteristics, inconsistent formats, and the large scale of data typically involved in labeling tasks. These complexities may impede the evaluation of label quality, identification of areas for improvement, and the effective optimization of LFs for acquiring high-quality labeled data. In this paper, we introduce EvoVis, a visual analytics method for multi-class text labeling tasks. It seamlessly integrates relationship analysis and temporal overview to display contextual and historical information on a single screen, aiding in explaining the labeling iterations in data programming. We assessed its utility and effectiveness through case studies and user studies. The results indicate that EvoVis can effectively assist data programmers in understanding labeling iterations and improving the quality of labeled data, as evidenced by an increase of 0.16 in the average F1 score when compared to the default analysis tool.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Labeling",
                "Programming",
                "Task analysis",
                "Data models",
                "Data visualization",
                "Analytical models",
                "Visual analytics"
            ],
            "Author Keywords": [
                "Visual analytics",
                "model interpretation",
                "data programming",
                "data labeling"
            ]
        },
        "Field": "data",
        "title": "EvoVis: A Visual Analytics Method to Understand the Labeling Iterations in Data Programming",
        "link": "https://ieeexplore.ieee.org/document/10452847/"
    },
    {
        "authors": [
            "Liang Chen",
            "Zhaobo Qin",
            "Yougang Bian",
            "Manjiang Hu",
            "Xiaoyan Peng"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Industrial Electronics ( Early Access )",
        "date_of_publication": "23 August 2024",
        "doi": "10.1109/TIE.2024.3440510",
        "publisher": "IEEE",
        "abstract": "The tire-road friction coefficient (TRFC) is a key parameter for precise motion control of electric-wheel vehicle. In the article, a data-driven method is proposed, focusing on multidomain feature fusion to achieve TRFC estimation under longitudinal maneuvering signal excitation. The longitudinal maneuvers encompass both the stationary maneuvers (e.g., longitudinal acceleration is around 0) and nonstationary maneuvers (e.g., all maneuvers except stationary ones). First, a scheme is introduced for analyzing vehicle states and parameters related to TRFC, which can provide the data category selection for the data-driven method. Moreover, a stochastic variational deep kernel learning framework is devised to efficiently map spatial–temporal features and assess estimation uncertainty. Subsequently, the TRFC estimation method is validated through simulations on various road surfaces. Results demonstrate the superiority of the proposed method over classical techniques, including a data-driven method and a model-driven method. Furthermore, experimental validation confirms the effectiveness of the proposed method.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Tires",
                "Estimation",
                "Vehicle dynamics",
                "Roads",
                "Wheels",
                "Force",
                "Data models"
            ],
            "Author Keywords": [
                "Data category selection",
                "data driven",
                "electric-wheel vehicle",
                "tire-road friction coefficient (TRFC)",
                "uncertainty evaluation"
            ]
        },
        "Field": "data",
        "title": "Data-Driven Tire-Road Friction Estimation for Electric-Wheel Vehicle With Data Category Selection and Uncertainty Evaluation",
        "link": "https://ieeexplore.ieee.org/document/10643991/"
    },
    {
        "authors": [
            "Wenhua Wang",
            "Quan Yang",
            "Yuzhu Liang",
            "Yang Xu",
            "Qin Liu",
            "Tian Wang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "22 May 2024",
        "doi": "10.1109/TBDATA.2024.3404104",
        "publisher": "IEEE",
        "abstract": "In the era of Big Data, artificial intelligence and information science are the key technologies to extract the value of data and enhance the competitiveness of enterprises. The characteristics of distributed, small-scale, and sparse lead to the isolated data island problem. To solve these problems, Federated Learning is proposed. However, a large number of terminal models need to be uploaded to the server in Federated Learning, especially for the actual scenario of Internet of Things. Therefore, huge communication costs are required which dramatically increases the pressure on the backbone network. Furthermore, the low quality of the local model will lead to decreased accuracy and convergence rates of the model. To overcome the above limitations, we propose heterogeneous device collaboration based federated learning (HDCFL), which constructs a three-layer structure for Federated Learning by leveraging edge computing and designs a heterogeneous device collaboration method that groups the terminals based on their computing power, communication time, and data volume to train the model. Then, we conduct a theoretical analysis of the proposed algorithm which verifies its advantage. At last, the experimental result demonstrates that the proposed algorithm consistently achieves superior performance in terms of both convergence speed and accuracy compared with state-of-the-art baselines.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Computational modeling",
                "Training",
                "Servers",
                "Federated learning",
                "Data models",
                "Adaptation models",
                "Costs"
            ],
            "Author Keywords": [
                "Big data applications",
                "edge collaboration",
                "federated learning"
            ]
        },
        "Field": "data",
        "title": "Heterogeneous Device Collaboration Based Federated Learning for Big Data Applications",
        "link": "https://ieeexplore.ieee.org/document/10536159/"
    },
    {
        "authors": [
            "Wisam Abbasi",
            "Paolo Mori",
            "Andrea Saracino"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Dependable and Secure Computing ( Early Access )",
        "date_of_publication": "14 May 2024",
        "doi": "10.1109/TDSC.2024.3400608",
        "publisher": "IEEE",
        "abstract": "This paper proposes a novel approach for multi-party collaborative data analysis problems, where analysis accuracy and divergence are required, as well as both privacy of shared data and explainability of results. The proposed approach aims at trading-off data privacy, decision explainability, and data utility by analytically relating these three measures, evaluating how they impact each other, and proposing a methodology to find the best possible trade-off among them. In particular, given a set of requirements from the participants for a collaborative analysis problem, we propose a method to properly tune the parameters of privacy-preserving mechanisms and explainability techniques to be adopted by all participants, obtaining the best trade-off . The paper is focused on deep learning-based image data analysis problems, though the approach can be generalized to other data types. The\n(ϵ,δ)\n- Differential Privacy and the Autoencoders privacy-preserving techniques have been adopted to preserve data privacy, while the SmoothGrad mechanism has been used to provide decision explainability. The proposed methodology has been validated with a set of experiments on three multi-class deep learning classifiers and three well-known image datasets, MNIST, FER, and CIFAR-10.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data privacy",
                "Privacy",
                "Data analysis",
                "Noise",
                "Artificial intelligence",
                "Codes",
                "Loss measurement"
            ],
            "Author Keywords": [
                "Data Privacy",
                "Explainable AI",
                "privacy-preserving Data Analysis",
                "Trustworthy AI"
            ]
        },
        "Field": "data",
        "title": "Trading-off Privacy, Utility, and Explainability in Deep Learning-based Image Data Analysis",
        "link": "https://ieeexplore.ieee.org/document/10530362/"
    },
    {
        "authors": [
            "Chunyi Wu",
            "Lin Li",
            "Li Zhang",
            "Chao Gao",
            "Xingchen Wu",
            "Shan Xiao"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "14 October 2024",
        "doi": "10.1109/JIOT.2024.3479285",
        "publisher": "IEEE",
        "abstract": null,
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Optimization",
                "Computational modeling",
                "Generative adversarial networks",
                "Big Data",
                "Resource management",
                "Training",
                "Multi-access edge computing",
                "Energy consumption",
                "Servers",
                "Faces"
            ],
            "Author Keywords": []
        },
        "Field": "data",
        "title": "Efficient GAN-Based Federated Optimization for Vehicular Task Offloading With Mobile Edge Computing in 6G Network",
        "link": "https://ieeexplore.ieee.org/document/10715728/"
    },
    {
        "authors": [
            "Yukai Pan",
            "Nan Wu",
            "Wei Jin"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Geoscience and Remote Sensing Letters ( Early Access )",
        "date_of_publication": "06 November 2024",
        "doi": "10.1109/LGRS.2024.3492252",
        "publisher": "IEEE",
        "abstract": "Multimodal remote sensing data (e.g., hyperspectral and light detection and ranging (LiDAR) data) provide complementary information and have therefore been widely explored for land cover classification tasks. However, due to the differences in the potential feature spaces of heterogeneous data, effectively extracting and fusing the similar information between modalities and the modality-specific discriminative information remains challenging. In this letter, we propose the multimodal feature disentangle–fusion network (DFNet), which introduces a disentanglement framework to tackle the challenges in feature extraction and fusion. Firstly, DFNet uses a dual-branch CNN-Transformer disentanglement module to decompose each modality’s features into the inter-modality shared representation and intra-modality specific representation. Secondly, we propose a joint training strategy based on contrastive learning and knowledge distillation to constrain the solution space and enhance disentangled feature representations. Additionally, we employ a gate fusion unit that uses learnable weights to measure the contributions of different modality representations. A series of experiments and ablation studies on the Houston2013 dataset demonstrate that DFNet can effectively utilize the complementary information in multimodal data.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Laser radar",
                "Contrastive learning",
                "Transformers",
                "Logic gates",
                "Data mining",
                "Training",
                "Fuses",
                "Data models",
                "Accuracy"
            ],
            "Author Keywords": [
                "Hyperspectral and LiDAR data classification",
                "multimodal fusion",
                "feature disentangle",
                "knowledge distillation"
            ]
        },
        "Field": "data",
        "title": "Multimodal Feature Disentangle–Fusion Network for Hyperspectral and LiDAR Data Classification",
        "link": "https://ieeexplore.ieee.org/document/10745631/"
    },
    {
        "authors": [
            "Qianqian Wu",
            "Qiang Liu",
            "Wenliang Zhu",
            "Zefan Wu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Network and Service Management ( Early Access )",
        "date_of_publication": "28 August 2024",
        "doi": "10.1109/TNSM.2024.3450964",
        "publisher": "IEEE",
        "abstract": "With the advancements in technologies such as 5G, Unmanned Aerial Vehicles (UAVs) have exhibited their potential in various application scenarios, including wireless coverage, search operations, and disaster response. In this paper, we consider the utilization of a group of UAVs as aerial base stations (BS) to collect data from IoT sensor devices. The objective is to maximize the volume of collected data while simultaneously enhancing the geographical fairness among these points of interest, all within the constraints of limited energy resources. Therefore, we propose a deep reinforcement learning (DRL) method based on Graph Attention Networks (GAT), referred to as “GADRL”. GADRL utilizes graph convolutional neural networks to extract spatial correlations among multiple UAVs and makes decisions in a distributed manner under the guidance of DRL. Furthermore, we employ Long Short-Term Memory to establish memory units for storing and utilizing historical information. Numerical results demonstrate that GADRL consistently outperforms four baseline methods, validating its computational efficiency.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Autonomous aerial vehicles",
                "Data collection",
                "Task analysis",
                "Energy consumption",
                "Heuristic algorithms",
                "Energy efficiency",
                "Propulsion"
            ],
            "Author Keywords": [
                "Data collection",
                "energy efficiency",
                "unmanned aerial vehicle (UAV)",
                "graph attention network",
                "deep reinforcement learning"
            ]
        },
        "Field": "data",
        "title": "Energy Efficient UAV-Aassisted IoT Data Collection: A Graph-Based Deep Reinforcement Learning Approach",
        "link": "https://ieeexplore.ieee.org/document/10654349/"
    },
    {
        "authors": [
            "Xiuhua Wang",
            "Shuai Wang",
            "Yiwei Li",
            "Fengrui Fan",
            "Shikang Li",
            "Xiaodong Lin"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Artificial Intelligence ( Early Access )",
        "date_of_publication": "21 August 2024",
        "doi": "10.1109/TAI.2024.3446759",
        "publisher": "IEEE",
        "abstract": "Federated learning (FL) is a popular distributed paradigm where enormous clients collaboratively train a machine learning (ML) model under the orchestration of a central server without knowing the clients’ private raw data. The development of effective FL algorithms faces multiple practical challenges including data heterogeneity and clients’ privacy protection. Despite that numerous attempts have been made to deal with data heterogeneity or rigorous privacy protection, none have effectively tackled both issues simultaneously. In this paper, we propose a differentially private and heterogeneity-robust FL algorithm, named DP-FedCVR to mitigate the data heterogeneity by following the client-variance-reduction strategy. Besides, it adopts a sophisticated differential privacy (DP) mechanism where the privacy-amplified strategy is applied, to achieve a rigorous privacy protection guarantee. We show that the proposed DP-FedCVR algorithm maintains its heterogeneity-robustness though DP no...",
        "issn": {
            "Electronic ISSN": "2691-4581"
        },
        "keywords": {
            "IEEE Keywords": [
                "Data privacy",
                "Convergence",
                "Data models",
                "Privacy",
                "Servers",
                "Protection",
                "Noise"
            ],
            "Author Keywords": [
                "Federated learning",
                "data heterogeneity",
                "client variance reduction",
                "differential privacy"
            ]
        },
        "Field": "data",
        "title": "Differentially Private and Heterogeneity-Robust Federated Learning with Theoretical Guarantee",
        "link": "https://ieeexplore.ieee.org/document/10643038/"
    },
    {
        "authors": [
            "He-xuan Hu",
            "Yicheng Cai",
            "Qing Meng",
            "Han Cui",
            "Qiang Hu",
            "Ye Zhang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Fuzzy Systems ( Early Access )",
        "date_of_publication": "28 May 2024",
        "doi": "10.1109/TFUZZ.2024.3406001",
        "publisher": "IEEE",
        "abstract": "Gearboxes are widely used in various types of mechanical equipment and have become an essential part of connecting various components in the machine and transmitting power. A fault in the gearbox will cause the entire mechanical equipment to stop working, causing economic losses and safety hazards. Previous fault diagnosis models for gearbox used the vibration signals of the gearbox as input features. They designed a variety of feature extraction modules to learn the information contained in the vibration signals. However, the latent features learned by previous models have poor interpretability and robustness, thus affecting model performance. In addition, the prediction results of previous fault diagnosis models used for gearbox using single-scale features are often less robust. Moreover, the fault diagnosis models used for gearbox are usually end-to-end black box models, which cannot provide interpretive information about the predicted values, and it is difficult to handle the uncertain information in the vibration signals. Therefore, we propose a multi-scale fuzzy variational autoencoder (MFVAE) using a fuzzy neural network for Big Data-based fault diagnosis in gearbox. The Big Data technology can automatically collect vibration signals from sensors and provide high-quality training samples for fault diagnosis models. The MFVAE model first uses two variational autoencoders of different sizes to extract the latent features of the gearbox vibration signal. Subsequently, the MFVAE model fuses low-level latent features and high-level latent features in proportion to form the final head features, which are used to diagnose gearbox faults. Finally, the MFVAE model inputs the head features into the prediction layer to diagnose the fault of the gearbox. The prediction layer comprises a fully connected network and a fuzzy neural network. Experimental results on the real gearbox dataset verify the outstanding performance of the MFVAE model.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Vibrations",
                "Predictive models",
                "Fault diagnosis",
                "Data models",
                "Biological system modeling",
                "Neural networks"
            ],
            "Author Keywords": [
                "Fuzzy neural network",
                "gearbox fault diagnosis",
                "multi-scale features",
                "variational autoencoder"
            ]
        },
        "Field": "data",
        "title": "MFVAE: A Multi-Scale Fuzzy Variational Autoencoder for Big Data-Based Fault Diagnosis in Gearbox",
        "link": "https://ieeexplore.ieee.org/document/10540226/"
    },
    {
        "authors": [
            "Zongxian Wang",
            "Jie Song"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Industry Applications ( Early Access )",
        "date_of_publication": "18 July 2024",
        "doi": "10.1109/TIA.2024.3430246",
        "publisher": "IEEE",
        "abstract": "As one of the most important production factors in the digital economy era, data holds significant value for social production and development. Energy enterprises possess a wealth of interconnected data resources closely linked to various industries. Therefore, effectively monetizing this invaluable data is crucial for unlocking its potential. This paper explores the process of data monetization by constructing game models that consider the data trading market involving an enterprise and a third-party platform. The findings show that enterprises and platforms can optimize their profits by adjusting the wholesale price of data and the intensity of data value mining to achieve a favorable equilibrium state. Moreover, complex dynamic characteristics occur when considering multi-period repeated games, and it is important for decision-makers to keep adjustment parameters and initial states within reasonable ranges to avoid market failure. Finally, strategic insights and recommendations are provided based on both theoretical and numerical analyses to guide enterprise decision-making.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Games",
                "Biological system modeling",
                "Pricing",
                "Analytical models",
                "Game theory",
                "Costs"
            ],
            "Author Keywords": [
                "Data monetization",
                "data trading",
                "game theory",
                "dynamic system",
                "decision making"
            ]
        },
        "Field": "data",
        "title": "Data Monetization Pathways and Complex Dynamic Game Equilibrium Analysis in the Energy Industry",
        "link": "https://ieeexplore.ieee.org/document/10603429/"
    },
    {
        "authors": [
            "Jiwoo Kim",
            "Seri Park",
            "Junsung Koh",
            "Dongha Kim"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "03 October 2024",
        "doi": "10.1109/ACCESS.2024.3472706",
        "publisher": "IEEE",
        "abstract": "There has been a growing demand to access large public datasets to extract valuable insights or enhance their services. However, this also involves risks, such as privacy breaches and unauthorized data exposure. Data synthesis has emerged as a popular technique to address privacy preservation and data usability simultaneously. Recently, numerous methods based on deep learning have been developed, while a clear understanding of their effectiveness is still insufficient, and the necessity for more efficient frameworks persists. In this study, we propose an efficient and theoretically principled method based on a deep generative model to effectively generate high-quality synthetic tabular data. First, we introduce a novel technique called C2Smap –a learnable pre-processing method that automatically transforms continuous distributions into simpler and easily generatable forms. We then develop a conditional generative model with a hierarchical structure and its corresponding learning framework, called HCIWAE, to successfully capture imbalanced categorical distributions. Combining these two components, we coin our method Synthetic data generation with C2Smap (SynC2S) . Through comprehensive experimental analyses, we demonstrate the superiority and efficiency of SynC2S in generating synthetic data compared to other recent competitors. Furthermore, as a by-product, we claim that SynC2S could be a favorable option to solve over-sampling tasks, constructing high-performance prediction models by generating synthetic data for the minority class.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Data models",
                "Synthetic data",
                "Predictive models",
                "Generative adversarial networks",
                "Deep learning",
                "Computational modeling",
                "Transforms",
                "Solid modeling"
            ],
            "Author Keywords": [
                "Synthetic data generation",
                "complex-to-simple mapping",
                "hierarchically conditional importance weighted autoencoder"
            ]
        },
        "Field": "data",
        "title": "SynC2S: An Efficient Method for Synthesizing Tabular Data with a Learnable Pre-Processing",
        "link": "https://ieeexplore.ieee.org/document/10704657/"
    },
    {
        "authors": [
            "Yuheng Zhao",
            "Yixing Zhang",
            "Yu Zhang",
            "Xinyi Zhao",
            "Junjie Wang",
            "Zekai Shao",
            "Cagatay Turkay",
            "Siming Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "04 March 2024",
        "doi": "10.1109/TVCG.2024.3368060",
        "publisher": "IEEE",
        "abstract": "Visual analytics supports data analysis tasks within complex domain problems. However, due to the richness of data types, visual designs, and interaction designs, users need to recall and process a significant amount of information when they visually analyze data. These challenges emphasize the need for more intelligent visual analytics methods. Large language models have demonstrated the ability to interpret various forms of textual data, offering the potential to facilitate intelligent support for visual analytics. We propose LEVA, a framework that uses large language models to enhance users' VA workflows at multiple stages: onboarding, exploration, and summarization. To support onboarding, we use large language models to interpret visualization designs and view relationships based on system specifications. For exploration, we use large language models to recommend insights based on the analysis of system status and data to facilitate mixed-initiative exploration. For summarization, we present a selective reporting strategy to retrace analysis history through a stream visualization and generate insight reports with the help of large language models. We demonstrate how LEVA can be integrated into existing visual analytics systems. Two usage scenarios and a user study suggest that LEVA effectively aids users in conducting visual analytics.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Visual analytics",
                "Task analysis",
                "Data analysis",
                "Grammar",
                "Codes",
                "Annotations"
            ],
            "Author Keywords": [
                "mixed-initiative",
                "interface agent",
                "large language models",
                "visual analytics"
            ]
        },
        "Field": "data",
        "title": "LEVA: Using Large Language Models to Enhance Visual Analytics",
        "link": "https://ieeexplore.ieee.org/document/10458347/"
    },
    {
        "authors": [
            "Arif Harmanci",
            "Luyao Chen",
            "Miran Kim",
            "Xiaoqian Jiang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Data Descriptions ( Early Access )",
        "date_of_publication": "17 October 2024",
        "doi": "10.1109/IEEEDATA.2024.3482283",
        "publisher": "IEEE",
        "abstract": "In order to uniformly test and benchmark secure evaluation of transformer-based models, we designed the iDASH24 Homomorphic Encryption track dataset. The dataset comprises a protein family classification model with a transformer architecture and an example dataset that is used to build and test the secure evaluation strategies. This dataset was used in the challenge period of iDASH24 Genomic Privacy Competition where the teams designed secure evaluation of the classification model using a Homomorphic Encryption scheme. Combined with the benchmarking results and companion methods, iDASH24 dataset is a unique resource that can be used to benchmark secure evaluation of neural network models.",
        "issn": {
            "Electronic ISSN": "2995-4274"
        },
        "keywords": {
            "IEEE Keywords": [
                "Benchmark testing",
                "Cryptography",
                "Protein sequence",
                "Data models",
                "Transformers",
                "Biological system modeling",
                "Neural networks",
                "Homomorphic encryption",
                "Load modeling",
                "Databases"
            ],
            "Author Keywords": [
                "Genomic Privacy",
                "Transformer Model",
                "Homomorphic Encryption"
            ]
        },
        "Field": "data",
        "title": "Descriptor: Benchmarking Secure Neural Network Evaluation Methods for Protein Sequence Classification (iDASH24)",
        "link": "https://ieeexplore.ieee.org/document/10720824/"
    },
    {
        "authors": [
            "Samuel Reinders",
            "Matthew Butler",
            "Ingrid Zukerman",
            "Bongshin Lee",
            "Lizhen Qu",
            "Kim Marriott"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "09 September 2024",
        "doi": "10.1109/TVCG.2024.3456358",
        "publisher": "IEEE",
        "abstract": "Despite the recent surge of research efforts to make data visualizations accessible to people who are blind or have low vision (BLV), how to support BLV people's data analysis remains an important and challenging question. As refreshable tactile displays (RTDs) become cheaper and conversational agents continue to improve, their combination provides a promising approach to support BLV people's interactive data exploration and analysis. To understand how BLV people would use and react to a system combining an RTD with a conversational agent, we conducted a Wizard-of-Oz study with 11 BLV participants, where they interacted with line charts, bar charts, and isarithmic maps. Our analysis of participants' interactions led to the identifcation of nine distinct patterns. We also learned that the choice of modalities depended on the type of task and prior experience with tactile graphics, and that participants strongly preferred the combination of RTD and speech to a single modality. In addition, participants with more tactile experience described how tactile images facilitated a deeper engagement with the data and supported independent interpretation. Our fndings will inform the design of interfaces for such interactive mixed-modality systems.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Graphics",
                "Data visualization",
                "Data analysis",
                "Pins",
                "Bars",
                "Water storage",
                "Three-dimensional displays"
            ],
            "Author Keywords": [
                "Accessible data visualization",
                "refreshable tactile displays",
                "conversational agents",
                "interactive data exploration",
                "Wizard of Oz study",
                "people who are blind or have low vision"
            ]
        },
        "Field": "data",
        "title": "When Refreshable Tactile Displays Meet Conversational Agents: Investigating Accessible Data Presentation and Analysis with Touch and Speech",
        "link": "https://ieeexplore.ieee.org/document/10670085/"
    },
    {
        "authors": [
            "Amjad Saleem",
            "Sahar Shah",
            "Hasnain Iftikhar",
            "Justyna Zywiołek",
            "Olayan Albalawi"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "28 October 2024",
        "doi": "10.1109/ACCESS.2024.3486927",
        "publisher": "IEEE",
        "abstract": "The Internet of Things (IoT) has revolutionized both professional and personal spheres by enabling the widespread adoption of real-time applications and seamless data transmission over long distances. However, this rapid advancement presents significant challenges, particularly regarding security. IoT devices, often constrained by limited processing capabilities, struggle to implement robust security measures, underscoring the need to address these concerns within the IoT ecosystem. This paper conducts a comprehensive survey of the latest algorithms, techniques, and concepts in IoT, including novel algorithms that have been overlooked by previous studies. The selected literature is categorized based on performance, data security, data quality, and data transmission protocols, thereby identifying opportunities for future research. Additionally, this paper offers a bibliometric overview, providing comprehensive insights that aid researchers, engineers, and scientists in selecting suitable algorithms for specific applications and considering avenues for future improvements.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Internet of Things",
                "Data integrity",
                "Protocols",
                "Cleaning",
                "Radiofrequency identification",
                "Wireless sensor networks",
                "Surveys",
                "Data communication",
                "Communication system security",
                "Standards"
            ],
            "Author Keywords": [
                "Data quality techniques",
                "IoT protocols",
                "Data quality dimensions",
                "Systematic review"
            ]
        },
        "Field": "data",
        "title": "A Comprehensive Systematic Survey of IoT Protocols: Implications for Data Quality and Performance",
        "link": "https://ieeexplore.ieee.org/document/10736640/"
    },
    {
        "authors": [
            "Shaojie Qiao",
            "Yuhe Jiang",
            "Nan Han",
            "Wei Hua",
            "Yufeng Lin",
            "Shengjie Min",
            "Xindong Wu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "21 October 2024",
        "doi": "10.1109/TBDATA.2024.3481952",
        "publisher": "IEEE",
        "abstract": "Blockchain technology makes it possible to design robust decentralized federated learning (FL). Minimizing the communication cost and storage consumption incurred is one of the essential challenges. In addition, maintaining the security and privacy of Big Data raises to be a difficult problem. Aiming to tackle these challenges, this paper presents LBFL (a Lightweight Blockchain-based FL framework) that offers three novel features. First, it employs a new committee consensus mechanism called Proof-of-Contribution, which is used to avoid the selection latency from the competition of miners and alleviate the congestion in cross-validation of parameters in an asynchronous fashion. Second, LBFL employs a role-adaptive incentive mechanism to estimate devices' workloads and identify malicious nodes effectively. Third, to cope with the excessive storage overheads incurred in full-replication, LBFL applies a new storage partition mechanism that distributes triple redundant chunks in ReedSolomon coding (RSC) evenly to participating devices with high fault tolerance and recovery efficiency. To evaluate LBFL, empirical studies are performed on the famous MNIST dataset and LBFL is compared with the state-of-the-art FL frameworks. The results demonstrate that LBFL can reduce evaluation latency and storage consumption by 69.2% and 72.1%, respectively, and the learning efficiency of LBFL is higher than the state-ofthe-art methods. In particular, important findings are obtained: the proposed role-adaptive incentive mechanism can properly identify malicious devices and switch the roles of legitimate devices to achieve good decentralization",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Blockchains",
                "Big Data",
                "Security",
                "Federated learning",
                "Consensus protocol",
                "Accuracy",
                "Training",
                "Information technology",
                "Technological innovation",
                "Software engineering"
            ],
            "Author Keywords": [
                "Big data security and privacy",
                "blockchain",
                "federated learning",
                "consensus mechanism",
                "role-adaptive incentive mechanism",
                "storage scalability"
            ]
        },
        "Field": "data",
        "title": "LBFL: A Lightweight Blockchain-based Federated Learning Framework with Proof-of-Contribution Committee Consensus",
        "link": "https://ieeexplore.ieee.org/document/10726717/"
    },
    {
        "authors": [
            "Yanmeng Wang",
            "Qingjiang Shi",
            "Tsung-Hui Chang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )",
        "date_of_publication": "01 November 2023",
        "doi": "10.1109/TNNLS.2023.3323302",
        "publisher": "IEEE",
        "abstract": "As a promising distributed learning paradigm, federated learning (FL) involves training deep neural network (DNN) models at the network edge while protecting the privacy of the edge clients. To train a large-scale DNN model, batch normalization (BN) has been regarded as a simple and effective means to accelerate the training and improve the generalization capability. However, recent findings indicate that BN can significantly impair the performance of FL in the presence of non-i.i.d. data. While several FL algorithms have been proposed to address this issue, their performance still falls significantly when compared to the centralized scheme. Furthermore, none of them have provided a theoretical explanation of how the BN damages the FL convergence. In this article, we present the first convergence analysis to show that under the non-i.i.d. data, the mismatch between the local and global statistical parameters in BN causes the gradient deviation between the local and global models, which, as a result, slows down and biases the FL convergence. In view of this, we develop a new FL algorithm that is tailored to BN, called FedTAN, which is capable of achieving robust FL performance under a variety of data distributions via iterative layer-wise parameter aggregation. Comprehensive experimental results demonstrate the superiority of the proposed FedTAN over existing baselines for training BN-based DNN models.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Convergence",
                "Training",
                "Data models",
                "Artificial neural networks",
                "Servers",
                "Computational modeling",
                "Federated learning"
            ],
            "Author Keywords": [
                "Batch normalization (BN)",
                "convergence analysis",
                "federated learning (FL)",
                "gradient deviation"
            ]
        },
        "Field": "data",
        "title": "Why Batch Normalization Damage Federated Learning on Non-IID Data?",
        "link": "https://ieeexplore.ieee.org/document/10304290/"
    },
    {
        "authors": [
            "Wei Huang",
            "Yunxiao Zhang",
            "Shangmin Guo",
            "Yuming Shang",
            "Xiangling Fu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Knowledge and Data Engineering ( Early Access )",
        "date_of_publication": "16 October 2024",
        "doi": "10.1109/TKDE.2024.3482466",
        "publisher": "IEEE",
        "abstract": "Selecting key data subsets for model training is an effective way to improve training efficiency. Existing methods generally utilize a well-trained model to evaluate samples and select crucial subsets, ignoring the fact that the sample importance changes dynamically during model training, resulting in the selected subset only being critical in a specific training epoch rather than a changing training phase. To address this issue, we attempt to evaluate the significant changes in sample importance during dynamic training and propose a novel data selection method to improve model training efficiency. Specifically, the temporal changes in sample importance are considered from three perspectives: (i) loss, the difference between the predicted labels and the true labels of samples in the current training epoch; (ii) instability, the dispersion of sample importance in the recent training phase; and (iii) inconsistency, the comparison of the changing trend in the importance of an individual sample relative to the average importance of all samples in the recent training phase. Extensive experiments demonstrate that dynamic data selection can reduce computational costs and improve model training efficiency. Additionally, we find that the difficulty level of the training task influences the data selection strategy.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Data models",
                "Computational modeling",
                "Vectors",
                "Predictive models",
                "Market research",
                "Costs",
                "Termination of employment",
                "Noise measurement",
                "Dispersion"
            ],
            "Author Keywords": [
                "Data selection",
                "Scoring criteria",
                "Model Scalability",
                "Low Computational Cost",
                "Deep learning"
            ]
        },
        "Field": "data",
        "title": "DynImpt: A Dynamic Data Selection Method for Improving Model Training Efficiency",
        "link": "https://ieeexplore.ieee.org/document/10720684/"
    },
    {
        "authors": [
            "Siwang Zhou",
            "Luyao Xu",
            "Yonghe Liu",
            "Liang Yang",
            "Keqin Li"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "05 June 2019",
        "doi": "10.1109/JIOT.2019.2921203",
        "publisher": "IEEE",
        "abstract": "Existing work on data gathering in mobile crowdsensing (MCS) usually assumes that the motion of the participants is either known or predictable via a mobility model. As such, the organizers can tell them when/where to sense, ensuring the data can be gathered from the target area with a minimized number of participants. Knowing exactly where the participants go, however, is not trivial, since the movements of the participants are in fact autonomous and random. In this paper, we investigate a common compressive data gathering framework for MCS, without trying to predict how a specific participant moves. We notice a key observation: while the participants move autonomously in the target sensing area, each trajectory itself provides a random, and thus valuable coverage for a sensing task. With compressive sensing (CS), these random trajectories can be utilized to exploit the spatio-temporal data correlation. Given this, we first introduce a novel idea of virtual sensor network to define the target sensing area, and then propose a distributed CS-based encoding algorithm to compress the data in the target area such that the number of the participants involved in data gathering can be reduced. We further propose a round-based CS reconstruction algorithm to exploit the inter-round data correlation and improve the accuracy of the data reconstruction. Experimental results using real sensor readings show that the proposed scheme achieves better performance than existing ones with dedicated sensor networks.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Sensors",
                "Data models",
                "Wireless sensor networks",
                "Distributed databases",
                "Trajectory",
                "Atmospheric measurements",
                "Particle measurements"
            ],
            "Author Keywords": [
                "compressive sensing",
                "crowdsensing",
                "data gathering",
                "sensor network."
            ]
        },
        "Field": "data",
        "title": "A Distributed Compressive Data Gathering Framework For Mobile Crowdsensing",
        "link": "https://ieeexplore.ieee.org/document/8731650/"
    },
    {
        "authors": [
            "Jincheng Li",
            "Chufan Lai",
            "Xiaoru Yuan"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "21 February 2024",
        "doi": "10.1109/TVCG.2024.3368094",
        "publisher": "IEEE",
        "abstract": "Subspace analysis of high-dimensional data is extremely challenging due to the huge exploration space. We propose Subspace-Map, a novel approach with a map metaphor for interactive exploration of various subspaces. We utilize a subspace search algorithm to identify a moderate number of potentially valuable subspaces, each visualized as a city on the map. Similar cities are clustered into provinces and countries, highlighting common data and dimensional patterns that can guide users in constructing desired subspaces. With the map, users can grasp an overview of the exploration space and explore different subspaces via recommended tour routes in more detail. We demonstrate the effectiveness of Subspace-Map through cases with real-world data, experiments with user feedback, and a comparison with state-of-the-art subspace data visualizations.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Space exploration",
                "Visualization",
                "Urban areas",
                "Data mining",
                "Clustering algorithms",
                "Reviews"
            ],
            "Author Keywords": [
                "High-Dimensional Data",
                "Subspace Analysis",
                "Map Metaphor"
            ]
        },
        "Field": "data",
        "title": "Subspace-Map: Interactive Visual Analysis for Subspace Data with a Map Metaphor",
        "link": "https://ieeexplore.ieee.org/document/10443294/"
    },
    {
        "authors": [
            "Yingchun Wang",
            "Song Guo",
            "Jingcai Guo",
            "Yuanhong Zhang",
            "Weizhan Zhang",
            "Qinghua Zheng",
            "Jie Zhang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )",
        "date_of_publication": "20 June 2024",
        "doi": "10.1109/TNNLS.2024.3409692",
        "publisher": "IEEE",
        "abstract": "Mixed-precision quantization mostly predetermines the model bit-width settings before actual training due to the non-differential bit-width sampling process, obtaining suboptimal performance. Worse still, the conventional static quality-consistent training setting, i.e., all data is assumed to be of the same quality across training and inference, overlooks data quality changes in real-world applications which may lead to poor robustness of the quantized models. In this article, we propose a novel data quality-aware mixed-precision quantization framework, dubbed DQMQ, to dynamically adapt quantization bit-widths to different data qualities. The adaption is based on a bit-width decision policy that can be learned jointly with the quantization training. Concretely, DQMQ is modeled as a hybrid reinforcement learning (RL) task that combines model-based policy optimization with supervised quantization training. By relaxing the discrete bit-width sampling to a continuous probability distribution that is encoded with few learnable parameters, DQMQ is differentiable and can be directly optimized end-to-end with a hybrid optimization target considering both task performance and quantization benefits. Trained on mixed-quality image datasets, DQMQ can implicitly select the most proper bit-width for each layer when facing uneven input qualities. Extensive experiments on various benchmark datasets and networks demonstrate the superiority of DQMQ against existing fixed/mixed-precision quantization methods.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Quantization (signal)",
                "Training",
                "Data models",
                "Data integrity",
                "Accuracy",
                "Computational modeling",
                "Optimization"
            ],
            "Author Keywords": [
                "Bit-width decision",
                "data quality",
                "model compression",
                "network quantization",
                "reinforcement learning (RL)"
            ]
        },
        "Field": "data",
        "title": "Data Quality-Aware Mixed-Precision Quantization via Hybrid Reinforcement Learning",
        "link": "https://ieeexplore.ieee.org/document/10566890/"
    },
    {
        "authors": [
            "Ambigavathi Munusamy",
            "Mainak Adhikari"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Consumer Electronics ( Early Access )",
        "date_of_publication": "04 October 2024",
        "doi": "10.1109/TCE.2024.3472118",
        "publisher": "IEEE",
        "abstract": "Nowadays, consumer electronic devices have transformed the healthcare industry from telemedicine to accurate remote patient monitoring. This digital transformation helps to monitor patients and provide timely diagnoses with minimum delay. In such time-sensitive applications, short-range communication protocols always play a crucial role from data collection to the data computation phase. However, the traditional protocols fail to handle concurrent transmissions of time-critical data from multiple sensor nodes. Due to an inefficient backoff algorithm with a predefined contention window size, these protocols could not simultaneously allocate the time slots to more than one critical sensor node over a common channel. Further, it can increase the delay when two or more sensor nodes with critical data choose the same random backoff counter values and try to access the medium along with other non-critical nodes. To mitigate all these issues, this work aims to design a novel Zippy Random Access Protocol (ZRAP) using an Emergency Lookup Table (ELT) to dynamically assign and adjust the backoff counter values and effectively minimize the backoff value conflicts among the sensor nodes. The extensive simulation results show that the proposed ZRAP outperforms the state-of-the-art random-access protocols in terms of delay, failure probability, collision rate, reliability, and throughput.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Delays",
                "Medical services",
                "Consumer electronics",
                "Data communication",
                "Standards",
                "Reliability",
                "Throughput",
                "Media Access Control",
                "IEEE 802.15 Standard",
                "Data models"
            ],
            "Author Keywords": [
                "Consumer Electronics",
                "Backoff Management",
                "Random Access Protocol",
                "Backoff Counter",
                "Healthcare Applications",
                "Critical Data Transmission"
            ]
        },
        "Field": "data",
        "title": "Zippy Random Access Protocol for Critical Data Transmission in Consumer Healthcare Applications",
        "link": "https://ieeexplore.ieee.org/document/10705108/"
    },
    {
        "authors": [
            "Hongpeng Tian",
            "Zuowei Zhang",
            "Weiping Ding"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Emerging Topics in Computational Intelligence ( Early Access )",
        "date_of_publication": "02 September 2024",
        "doi": "10.1109/TETCI.2024.3449902",
        "publisher": "IEEE",
        "abstract": "Classification of incomplete data remains a challenging task since the distribution of training and test sets may be inconsistently caused by missing values. To address such a problem, this paper investigates an incomplete data transfer calibration classification (IDTC) method based on Dempster-Shafer theory to improve the accuracy by modeling uncertainty and imprecision due to missing values. The proposed IDTC method consists of three aspects. First, incomplete samples are imputed by complete neighbors, and the trained basic classifier then classifies the test sample to obtain the preliminary result. Second, a data transfer framework is presented to map the test sample to the training set. Afterward, the mapped training samples optimize multiple calibration matrices to calibrate the preliminary classification result. The calibration matrix is learned by minimizing the deviation between the classification results of mapped training samples and the truth. Third, each calibrated classification result is considered as a piece of evidence under Dempster-Shafer theory. As a result, these pieces of evidence with different discounting factors are fused to make the final decision. Finally, the effectiveness of the proposed IDTC is widely validated on real datasets by critically comparing to other typical methods.",
        "issn": {
            "Electronic ISSN": "2471-285X"
        },
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Imputation",
                "Calibration",
                "Uncertainty",
                "Data transfer",
                "Estimation",
                "Data models"
            ],
            "Author Keywords": [
                "Classification",
                "data transfer",
                "Dempster-shafer theory",
                "incomplete data",
                "transfer calibration"
            ]
        },
        "Field": "data",
        "title": "Incomplete Data Transfer Calibration Classification",
        "link": "https://ieeexplore.ieee.org/document/10663458/"
    },
    {
        "authors": [
            "Karim Huesmann",
            "Lars Linsen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "30 September 2024",
        "doi": "10.1109/TVCG.2024.3460652",
        "publisher": "IEEE",
        "abstract": "When analyzing heterogeneous data comprising numerical and categorical attributes, it is common to treat the different data types separately or transform the categorical attributes to numerical ones. The transformation has the advantage of facilitating an integrated multi-variate analysis of all attributes. We propose a novel technique for transforming categorical data into interpretable numerical feature vectors using Large Language Models (LLMs). The LLMs are used to identify the categorical attributes' main characteristics and assign numerical values to these characteristics, thus generating a multi-dimensional feature vector. The transformation can be computed fully automatically, but due to the interpretability of the characteristics, it can also be adjusted intuitively by an end user. We provide a respective interactive tool that aims to validate and possibly improve the AI-generated outputs. Having transformed a categorical attribute, we propose novel methods for ordering and color-coding the categories based on the similarities of the feature vectors.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Vectors",
                "Data visualization",
                "Frequency measurement",
                "Encoding",
                "Image color analysis",
                "Automobiles",
                "Large language models",
                "Data models",
                "Semantics",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Categorical data visualization",
                "data transformation",
                "large language models"
            ]
        },
        "Field": "data",
        "title": "Large Language Models for Transforming Categorical Data to Interpretable Feature Vectors",
        "link": "https://ieeexplore.ieee.org/document/10700821/"
    },
    {
        "authors": [
            "Pengyu Song",
            "Jie Wang",
            "Chunhui Zhao",
            "Biao Huang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE/CAA Journal of Automatica Sinica ( Early Access )",
        "date_of_publication": "12 November 2024",
        "doi": "10.1109/JAS.2024.124902",
        "publisher": "IEEE",
        "abstract": "In recent decades, control performance monitoring (CPM) has experienced remarkable progress in research and industrial applications. While CPM research has been investigated using various benchmarks, the historical data benchmark (HIS) has garnered the most attention due to its practicality and effectiveness. However, existing CPM reviews usually focus on the theoretical benchmark, and there is a lack of an in-depth review that thoroughly explores HIS-based methods. In this article, a comprehensive overview of HIS-based CPM is provided. First, we provide a novel static-dynamic perspective on data-level manifestations of control performance underlying typical controller capacities including regulation and servo: static and dynamic properties. The static property portrays time-independent variability in system output, and the dynamic property describes temporal behavior driven by closed-loop feedback. Accordingly, existing HIS-based CPM approaches and their intrinsic motivations are classified and analyzed from these two perspectives. Specifically, two mainstream solutions for CPM methods are summarized, including static analysis and dynamic analysis, which match data-driven techniques with actual controlling behavior. Furthermore, this paper also points out various opportunities and challenges faced in CPM for modern industry and provides promising directions in the context of artificial intelligence for inspiring future research.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Benchmark testing",
                "Monitoring",
                "Data models",
                "Process control",
                "Artificial intelligence",
                "Servomotors",
                "Analytical models",
                "Regulation",
                "Data analysis",
                "Surveys"
            ],
            "Author Keywords": [
                "Control performance monitoring",
                "data-driven method",
                "historical data benchmark",
                "industrial process",
                "performance index",
                "static and dynamic analysis"
            ]
        },
        "Field": "data",
        "title": "From static and dynamic perspectives: A survey on historical data benchmarks of control performance monitoring",
        "link": "https://ieeexplore.ieee.org/document/10751760/"
    },
    {
        "authors": [
            "Li Yuan",
            "Yi Cai",
            "Jingyu Xu",
            "Qing Li",
            "Tao Wang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Knowledge and Data Engineering ( Early Access )",
        "date_of_publication": "25 October 2024",
        "doi": "10.1109/TKDE.2024.3485107",
        "publisher": "IEEE",
        "abstract": "Joint multimodal entity-relation extraction (JMERE) is a challenging task that involves two joint subtasks, i.e., named entity recognition and relation extraction, from multimodal data such as text sentences with associated images. Previous JMERE methods have primarily employed 1) pipeline models, which apply pre-trained unimodal models separately and ignore the interaction between tasks, or 2) word-pair relation tagging methods, which neglect neighboring word pairs. To address these limitations, we propose a fine-grained network for JMERE. Specifically, we introduce a fine-grained alignment module that utilizes a phrase-patch to establish connections between text phrases and visual objects. This module can learn consistent multimodal representations from multimodal data. Furthermore, we address the task-irrelevant image information issue by proposing a gate fusion module, which mitigates the impact of image noise and ensures a balanced representation between image objects and text representations. Furthermore, we design a multi-word decoder that enables ensemble prediction of tags for each word pair. This approach leverages the predicted results of neighboring word pairs, improving the ability to extract multi-word entities. Evaluation results from a series of experiments demonstrate the superiority of our proposed model over state-of-the-art models in JMERE.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Visualization",
                "Data mining",
                "Contrastive learning",
                "Feature extraction",
                "Brain modeling",
                "Tagging",
                "Semantics",
                "Predictive models",
                "Pipelines",
                "Logic gates"
            ],
            "Author Keywords": [
                "Contrastive learning",
                "entity-relation extraction",
                "multimodal",
                "pre-trained model"
            ]
        },
        "Field": "data",
        "title": "A Fine-Grained Network for Joint Multimodal Entity-Relation Extraction",
        "link": "https://ieeexplore.ieee.org/document/10736404/"
    },
    {
        "authors": [
            "Hao Ren",
            "Guowen Xu",
            "Tianwei Zhang",
            "Jianting Ning",
            "Xinyi Huang",
            "Hongwei Li",
            "Rongxing Lu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Dependable and Secure Computing ( Early Access )",
        "date_of_publication": "11 October 2024",
        "doi": "10.1109/TDSC.2024.3478786",
        "publisher": "IEEE",
        "abstract": "Fueled by its successful commercialization, the recommender system (RS) has gained widespread attention. However, as the training data fed into the RS models are often highly sensitive, it ultimately leads to severe privacy concerns, especially when data are shared among different platforms. In this paper, we follow the tune of existing works to investigate the problem of secure sparse matrix multiplication for cross-platform RSs. Two fundamental and critical issues are addressed: preserving the training data privacy and breaking the data silo problem. Specifically, we propose two concrete constructions with significantly boosted efficiency. They are designed for the sparse location insensitive case and location sensitive case, respectively. State-of-the-art cryptography building blocks including homomorphic encryption (HE) and private information retrieval (PIR) are fused into our protocols with non-trivial optimizations. As a result, our schemes can enjoy the HE acceleration technique without privacy trade-offs. We give formal security proofs for the proposed schemes and conduct extensive experiments on both real and large-scale simulated datasets. Compared with state-of-the-art works, our two schemes compress the running time roughly by\n10×\nand\n2.8×\n. They also attain up to\n15×\nand\n2.3×\ncommunication reduction without accuracy loss.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Sparse matrices",
                "Cryptography",
                "Privacy",
                "Data privacy",
                "Computational modeling",
                "Vectors",
                "Costs",
                "Accuracy",
                "Recommender systems",
                "Data models"
            ],
            "Author Keywords": [
                "2PC",
                "cross-platform recommender systems",
                "homomorphic encryption",
                "private computing"
            ]
        },
        "Field": "data",
        "title": "Efficiency Boosting of Secure Cross-Platform Recommender Systems Over Sparse Data",
        "link": "https://ieeexplore.ieee.org/document/10713997/"
    },
    {
        "authors": [
            "Xi Xiao",
            "Hailong Ma",
            "Guojun Gan",
            "Qing Li",
            "Bin Zhang",
            "Shutao Xia"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )",
        "date_of_publication": "07 June 2024",
        "doi": "10.1109/TNNLS.2024.3392211",
        "publisher": "IEEE",
        "abstract": "Data clustering is a fundamental machine learning task that seeks to categorize a dataset into homogeneous groups. However, real data usually contain noise, which poses significant challenges to clustering algorithms. In this article, motivated by how the\nk\n-means algorithm is derived from a Gaussian mixture model (GMM), we propose a robust\nk\n-means-type algorithm, named\nk\n-means-type clustering based on\nt\n-distribution (KMTD), by assuming that the data points are drawn from a special multivariate\nt\n-mixture model (TMM). Compared to the Gaussian distribution, the\nt\n-distribution has a fatter tail. The proposed algorithm is more robust to noise. Like the\nk\n-means algorithm, the proposed algorithm is simpler than those based on a full TMM. Both synthetic and actual data are used to illustrate the proposed algorithm’s performance and efficiency. The experimental results demonstrated that the proposed algorithm operates more quickly than other sophisticated algorithms and, in most cases, achieves higher accuracy than the other algorithms.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Clustering algorithms",
                "Noise",
                "Gaussian distribution",
                "Classification algorithms",
                "Machine learning algorithms",
                "Data models",
                "Task analysis"
            ],
            "Author Keywords": [
                "Data clustering",
                "$k$ -means-type algorithm",
                "noisy data"
            ]
        },
        "Field": "data",
        "title": "Robust $k$ -Means-Type Clustering for Noisy Data",
        "link": "https://ieeexplore.ieee.org/document/10551895/"
    },
    {
        "authors": [
            "Kishu Gupta",
            "Deepika Saxena",
            "Pooja Rani",
            "Jitendra Kumar",
            "Aaisha Makkar",
            "Ashutosh Kumar Singh",
            "Chung-Nan Lee"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Automation Science and Engineering ( Early Access )",
        "date_of_publication": "17 September 2024",
        "doi": "10.1109/TASE.2024.3456209",
        "publisher": "IEEE",
        "abstract": "Digital healthcare is essential to facilitate consumers to access and disseminate their medical data easily for enhanced medical care services. However, the significant concern with digitalization across healthcare systems necessitates for a prompt, productive, and secure storage facility along with a vigorous communication strategy, to stimulate sensitive digital healthcare data sharing and proactive estimation of malicious entities. In this context, this paper introduces a comprehensive quantum-based framework to overwhelm the potential security and privacy issues for secure healthcare data management. It equips quantum encryption for the secured storage and dispersal of healthcare data over the shared cloud platform by employing quantum encryption. Also, the framework furnishes a quantum feed-forward neural network unit to examine the intention behind the data request before granting access, for proactive estimation of potential data breach. In this way, the proposed framework delivers overall healthcare data management by coupling the advanced and more competent quantum approach with machine learning to safeguard the data storage, access, and prediction of malicious entities in an automated manner. Thus, the proposed IQ-HDM leads to more cooperative and effective healthcare delivery and empowers individuals with adequate custody of their health data. The experimental evaluation and comparison of the proposed IQ-HDM framework with state-of-the-art methods outline a considerable improvement up to 67.6%, in tackling cyber threats related to healthcare data security. Note to Practitioners —This paper aims to address the issue of digital healthcare data access, which requires both ease and security. Existing research either focuses solely on safe access or on high security, which often comes with high computational challenges. In this paper, we present a comprehensive approach that takes into account various challenges such as secure data storage, efficient data com...",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Medical services",
                "Encryption",
                "Data breach",
                "Quantum computing",
                "Data models",
                "Data communication",
                "Predictive models"
            ],
            "Author Keywords": [
                "Automated healthcare data security",
                "malicious entity prediction",
                "quantum encryption",
                "quantum feed forward neural network"
            ]
        },
        "Field": "data",
        "title": "An Intelligent Quantum Cyber-Security Framework for Healthcare Data Management",
        "link": "https://ieeexplore.ieee.org/document/10681488/"
    },
    {
        "authors": [
            "Charles Berret",
            "Tamara Munzner"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "04 November 2024",
        "doi": "10.1109/TVCG.2024.3486613",
        "publisher": "IEEE",
        "abstract": "We offer a new model of the sensemaking process for data analysis and visualization. Whereas past sensemaking models have been grounded in positivist assumptions about the nature of knowledge, we reframe data sensemaking in critical, humanistic terms by approaching it through an interpretivist lens. Our three-phase process model uses the analogy of an iceberg, where data is the visible tip of underlying schemas. In the Add phase, the analyst acquires data, incorporates explicit schemas from the data, and absorbs the tacit schemas of both data and people. In the Check phase, the analyst interprets the data with respect to the current schemas and evaluates whether the schemas match the data. In the Refine phase, the analyst considers the role of power, articulates what was tacit into explicitly stated schemas, updates data, and formulates findings. Our model has four important distinguishing features: Tacit and Explicit Schemas, Schemas First and Always, Data as a Schematic Artifact, and Schematic Multiplicity. We compare the roles of schemas in past sensemaking models and draw conceptual distinctions based on a historical review of schemas in different academic traditions. We validate the descriptive and prescriptive power of our model through four analysis scenarios: noticing uncollected data, learning to wrangle data, downplaying inconvenient data, and measuring with sensors. We conclude by discussing the value of interpretivism, the virtue of epistemic humility, and the pluralism this sensemaking model can foster.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Analytical models",
                "Data models",
                "Data analysis",
                "Computational modeling",
                "Data visualization",
                "Icebergs",
                "Shape",
                "Sensor phenomena and characterization",
                "Visual analytics",
                "Tuning"
            ],
            "Author Keywords": [
                "Data analysis",
                "epistemic humility",
                "process models",
                "schemas",
                "sensemaking",
                "visualization"
            ]
        },
        "Field": "data",
        "title": "Iceberg Sensemaking: A Process Model for Critical Data Analysis",
        "link": "https://ieeexplore.ieee.org/document/10741969/"
    },
    {
        "authors": [
            "Rabiah Alqudah",
            "Ching Y. Suen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "29 October 2024",
        "doi": "10.1109/ACCESS.2024.3487851",
        "publisher": "IEEE",
        "abstract": "Reticulocyte count is a routine blood test that can be an essential source of knowledge for medical doctors to diagnose and assess patients’ health condition. In fact, the automation of this blood test will reduce cost and time, in addition to protecting laboratorians’ lives, especially during pandemics and outbreaks. However, human reticulocyte data scarcity is a main challenge that slows the pace of the test automation. In this paper, a novel method that assesses the feasibility of using animal reticulocyte cells as a solution to compensate for the scarcity of human reticulocyte data is investigated. The integration of animal cells will be implemented by utilizing a data-centric artificial intelligence approach, in addition to employing multiple deep classifiers that utilize transfer learning in different experimental setups in a procedure that mimics the protocol followed in experimental medical labs. Moreover, to evaluate the effectiveness of the proposed method, three evaluation criteria have been proposed, namely, the pretraining boost, the dataset similarity boost, and the dataset size boost measures. All the experiments of this work were conducted on a public human reticulocyte dataset and the best performing model achieved 98.9%, 98.9%, 98.6% average accuracy, average macro precision, and average macro F-score respectively. Moreover, the results showed that using animals medical data holds a promising solution for human medical data scarcity, as utilizing weights that were pretrained on a medium size feline reticulocyte dataset outperformed the model that utilized weights that were pretrained on the large scale ImageNet dataset.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Blood",
                "Medical diagnostic imaging",
                "Artificial intelligence",
                "Cells (biology)",
                "Cats",
                "Transfer learning",
                "Medical services",
                "Deep learning",
                "Automation",
                "Forecasting"
            ],
            "Author Keywords": [
                "Automated blood smear analysis",
                "Computer aided diagnosis",
                "Deep learning",
                "Reticulocyte",
                "Data scarcity",
                "Data centric artificial intelligence"
            ]
        },
        "Field": "data",
        "title": "A Data-Centric Approach to Investigate the Feasibility of Utilizing Animal Medical Data as a Solution for Human Medical Data Scarcity",
        "link": "https://ieeexplore.ieee.org/document/10737335/"
    },
    {
        "authors": [
            "Lina Liu",
            "Yuntong Li"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Geoscience and Remote Sensing Letters ( Early Access )",
        "date_of_publication": "04 November 2024",
        "doi": "10.1109/LGRS.2024.3490583",
        "publisher": "IEEE",
        "abstract": "The denoising problem of multidimensional seismic data can be regarded as a low rank tensor decomposition problem. However, seismic data only has many ranks close to zero, which does not meet the definition of low rank data. Adding low rank constraints to the data will result in the loss of some features of the data. To overcome this problems, this letter proposes a nearly low rank tensor decomposition method (NLRTD) for seismic data denoising. First, differing to existing low-rank based methods, we consider a nearly low-rank approximation, which is closer to the latent low-rank structure of the clean data. Then, we exploit a simultaneously sparse and low-rank tensor representation model to enhance the capability of dictionary learning and use the ADMM algorithm to obtain denoising results. In the experiment part, we test on the 3D seismic data. Compared with the HOSVD and low-rank tensor dictionary learning methods, the method in this letter achieves better denoising results.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Tensors",
                "Noise reduction",
                "Machine learning",
                "Three-dimensional displays",
                "Dictionaries",
                "Data models",
                "Signal to noise ratio",
                "Matrix decomposition",
                "Geoscience and remote sensing",
                "Sparse approximation"
            ],
            "Author Keywords": [
                "seismic data denoising",
                "tensor decomposition",
                "dictionary learning"
            ]
        },
        "Field": "data",
        "title": "Simultaneous sparse and low rank regularization for seismic data denoising",
        "link": "https://ieeexplore.ieee.org/document/10741568/"
    },
    {
        "authors": [
            "Wei Wei",
            "Chuan Jiang",
            "Yuzhe Huang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Automation Science and Engineering ( Early Access )",
        "date_of_publication": "23 November 2023",
        "doi": "10.1109/TASE.2023.3295571",
        "publisher": "IEEE",
        "abstract": "In the era of big data, enterprises have accumulated large amounts of valuable data throughout the entire product life cycle (PLC). Such PLC data contains a wealth of design knowledge. Intelligent manufacturing seeks to establish a collaborative platform that integrates advanced data analytics and artificial intelligence into the manufacturing process, providing new opportunities for efficient and intelligent product design. Mining design knowledge from PLC data and applying it to the design stage is a critical issue that urgently needs to be addressed for data-driven product design (DDPD). To enhance the efficiency and adaptability of DDPD, this work proposes a comprehensive framework for extracting design knowledge from PLC data and utilizing the knowledge to inform the design process. A structured storage method is developed to manage PLC data with multi-source and heterogeneous characteristics. Then, human-machine collaborative pattern extraction, deep learning-based relation extraction, and other data mining techniques are used to extract knowledge from PLC data. Moreover, a product design knowledge network is constructed based on knowledge graph to achieve knowledge organization and management. Finally, a novel intelligent push method for product design knowledge, based on context navigation, is proposed as part of the framework. A case study showcases how data-driven human-machine collaborative patterns can be used to improve the flexibility and performance of product design. Note to Practitioners —Data-driven method can realize the closed-loop design of products while linking users, products and production processes to improve design efficiency. However, one of the major challenges in DDPD is the need to flexibly extract knowledge from PLC data and push them to designers. In this work, we propose a novel system that leverages human-machine collaboration and deep learning methods to realize DDPD toward intelligent manufacturing. It allows us to extract knowl...",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data mining",
                "Product design",
                "Collaboration",
                "Manufacturing",
                "Human-machine systems",
                "Knowledge engineering",
                "Atmospheric modeling"
            ],
            "Author Keywords": [
                "Data-driven design",
                "product life cycle data",
                "data mining",
                "human-machine collaboration",
                "knowledge management",
                "knowledge push"
            ]
        },
        "Field": "data",
        "title": "A Data-Driven Human–Machine Collaborative Product Design System Toward Intelligent Manufacturing",
        "link": "https://ieeexplore.ieee.org/document/10328554/"
    },
    {
        "authors": [
            "Zhaoyin Shi",
            "Long Chen",
            "Weiping Ding",
            "Xiaopin Zhong",
            "Zongze Wu",
            "Guang-Yong Chen",
            "Chuanbin Zhang",
            "Yingxu Wang",
            "C. L. Philip Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Cybernetics ( Early Access )",
        "date_of_publication": "30 May 2024",
        "doi": "10.1109/TCYB.2024.3391274",
        "publisher": "IEEE",
        "abstract": "The graph-information-based fuzzy clustering has shown promising results in various datasets. However, its performance is hindered when dealing with high-dimensional data due to challenges related to redundant information and sensitivity to the similarity matrix design. To address these limitations, this article proposes an implicit fuzzy k-means (FKMs) model that enhances graph-based fuzzy clustering for high-dimensional data. Instead of explicitly designing a similarity matrix, our approach leverages the fuzzy partition result obtained from the implicit FKMs model to generate an effective similarity matrix. We employ a projection-based technique to handle redundant information, eliminating the need for specific feature extraction methods. By formulating the fuzzy clustering model solely based on the similarity matrix derived from the membership matrix, we mitigate issues, such as dependence on initial values and random fluctuations in clustering results. This innovative approach significantly improves the competitiveness of graph-enhanced fuzzy clustering for high-dimensional data. We present an efficient iterative optimization algorithm for our model and demonstrate its effectiveness through theoretical analysis and experimental comparisons with other state-of-the-art methods, showcasing its superior performance.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "High-dimensional data",
                "Data models",
                "Optimization",
                "Manifolds",
                "Image segmentation",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Fuzzy clustering",
                "graph clustering",
                "high-dimensional data",
                "implicit model"
            ]
        },
        "Field": "data",
        "title": "IFKMHC: Implicit Fuzzy K-Means Model for High-Dimensional Data Clustering",
        "link": "https://ieeexplore.ieee.org/document/10542191/"
    },
    {
        "authors": [
            "Eric Mörth",
            "Kevin Sidak",
            "Zoltan Maliga",
            "Torsten Möller",
            "Nils Gehlenborg",
            "Peter Sorger",
            "Hanspeter Pfister",
            "Johanna Beyer",
            "Robert Krüger"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "10 September 2024",
        "doi": "10.1109/TVCG.2024.3456406",
        "publisher": "IEEE",
        "abstract": "We present Cell2Cell, a novel visual analytics approach for quantifying and visualizing networks of cell-cell interactions in three-dimensional (3D) multi-channel cancerous tissue data. By analyzing cellular interactions, biomedical experts can gain a more accurate understanding of the intricate relationships between cancer and immune cells. Recent methods have focused on inferring interaction based on the proximity of cells in low-resolution 2D multi-channel imaging data. By contrast, we analyze cell interactions by quantifying the presence and levels of specific proteins within a tissue sample (protein expressions) extracted from high-resolution 3D multi-channel volume data. Such analyses have a strong exploratory nature and require a tight integration of domain experts in the analysis loop to leverage their deep knowledge. We propose two complementary semi-automated approaches to cope with the increasing size and complexity of the data interactively: On the one hand, we interpret cell-to-cell interactions as edges in a cell graph and analyze the image signal (protein expressions) along those edges, using spatial as well as abstract visualizations. Complementary, we propose a cell-centered approach, enabling scientists to visually analyze polarized distributions of proteins in three dimensions, which also captures neighboring cells with biochemical and cell biological consequences. We evaluate our application in three case studies, where biologists and medical experts use Cell2Cell to investigate tumor micro-environments to identify and quantify T-cell activation in human tissue data. We confirmed that our tool can fully solve the use cases and enables a streamlined and detailed analysis of cell-cell interactions.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Proteins",
                "Three-dimensional displays",
                "Imaging",
                "Protein engineering",
                "Immune system",
                "Tumors",
                "Data visualization"
            ],
            "Author Keywords": [
                "Biomedical visualization",
                "3D multi-channel tissue data",
                "Direct volume rendering",
                "Quantitative analysis"
            ]
        },
        "Field": "data",
        "title": "Cell2Cell: Explorative Cell Interaction Analysis in Multi-Volumetric Tissue Data",
        "link": "https://ieeexplore.ieee.org/document/10672552/"
    },
    {
        "authors": [
            "Muhammad Aslam"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "13 September 2024",
        "doi": "10.1109/TBDATA.2024.3460529",
        "publisher": "IEEE",
        "abstract": "The manuscript introduces the mathematical representation of the neutrosophic triangular distribution, encompassing probability density functions and cumulative distribution functions. Two algorithms are introduced for the generation of random variates based on this distribution. Through simulations and a comparative examination with traditional statistical approaches, the research illustrates the versatility and resilience of the neutrosophic triangular distribution. The findings underscore its effectiveness in addressing uncertainty, particularly in scenarios with varying degrees of indeterminacy. The study emphasizes the substantial influence of uncertainty on the generation of random variates, with potential implications for decision-making and data analysis.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Uncertainty",
                "Standards",
                "Monte Carlo methods",
                "Big Data",
                "Random variables",
                "Adaptation models",
                "Mathematical models"
            ],
            "Author Keywords": [
                "Simulation",
                "classical statistics",
                "indeterminacy",
                "algorithm",
                "distribution"
            ]
        },
        "Field": "data",
        "title": "Developing Novel Algorithms for Generating Inexact Data through Triangle Distribution",
        "link": "https://ieeexplore.ieee.org/document/10679704/"
    },
    {
        "authors": [
            "Zhongsu Luo",
            "Kai Xiong",
            "Jiajun Zhu",
            "Ran Chen",
            "Xinhuan Shu",
            "Di Weng",
            "Yingcai Wu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "10 September 2024",
        "doi": "10.1109/TVCG.2024.3456328",
        "publisher": "IEEE",
        "abstract": "Understanding the input and output of data wrangling scripts is crucial for various tasks like debugging code and onboarding new data. However, existing research on script understanding primarily focuses on revealing the process of data transformations, lacking the ability to analyze the potential scope, i.e., the space of script inputs and outputs. Meanwhile, constructing input/output space during script analysis is challenging, as the wrangling scripts could be semantically complex and diverse, and the association between different data objects is intricate. To facilitate data workers in understanding the input and output space of wrangling scripts, we summarize ten types of constraints to express table space and build a mapping between data transformations and these constraints to guide the construction of the input/output for individual transformations. Then, we propose a constraint generation model for integrating table constraints across multiple transformations. Based on the model, we develop Ferry, an interactive system that extracts and visualizes the data constraints describing the input and output space of data wrangling scripts, thereby enabling users to grasp the high-level semantics of complex scripts and locate the origins of faulty data transformations. Besides, Ferry provides example input and output data to assist users in interpreting the extracted constraints and checking and resolving the conflicts between these constraints and any uploaded dataset. Ferry's effectiveness and usability are evaluated through two usage scenarios and two case studies, including understanding, debugging, and checking both single and multiple scripts, with and without executable data. Furthermore, an illustrative application is presented to demonstrate Ferry's flexibility.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Debugging",
                "Semantics",
                "Data visualization",
                "Electronic mail",
                "Data models",
                "Data mining"
            ],
            "Author Keywords": [
                "Data wrangling",
                "Visual analytics",
                "Constraints",
                "Program understanding"
            ]
        },
        "Field": "data",
        "title": "Ferry: Toward Better Understanding of Input/Output Space for Data Wrangling Scripts",
        "link": "https://ieeexplore.ieee.org/document/10670464/"
    },
    {
        "authors": [
            "Liao Huang",
            "Yue Chen",
            "Dajiang Liu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems ( Early Access )",
        "date_of_publication": "29 August 2024",
        "doi": "10.1109/TCAD.2024.3451978",
        "publisher": "IEEE",
        "abstract": "Coarse-Grained Reconfigurable Arrays (CGRAs) can provide high energy efficiency while maintaining flexibility, which is promising to keep pace with the power requirements and the frequent updates of applicants. With flexible register chains, modern CGRAs enable data reuse within the Processing Element Array (PEA) to reduce on-chip memory accesses and improve pipelining performance. However, existing works pay little attention to comprehensive loop transformations, such as affine transformation and non-affine transformation, to obtain a data reuse-friendly loop structure. Therefore, this paper proposes a data-reuse-friendly loop mapping approach using joint affine and non-affine transformations. With affine transformations, the distance of loop dependencies could be reduced and then handled by in-PEA routes. With non-affine transformations (i.e., loop unrolling), small loop kernels could be unrolled and expose more memory accesses for data reuse. To efficiently solve the loop transformation problem, we first establish a reduced polyhedral formulation and then propose a divide-and-conquer-based solution to find optimized transformations with moderate compilation time. Experimental results demonstrate that our approach can achieve a speedup up to 1.74 × compared to state-of-the-art methods.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Pipeline processing",
                "Registers",
                "Design automation",
                "Switches",
                "Data models",
                "Kernel",
                "Energy efficiency"
            ],
            "Author Keywords": [
                "CGRAs",
                "Polyhedral Model",
                "Data Reuse",
                "Loop Unrolling"
            ]
        },
        "Field": "data",
        "title": "Notice to Reader: Optimizing Data Reuse for Loop Mapping on CGRAs With Joint Affine and Non-Affine Transformations",
        "link": "https://ieeexplore.ieee.org/document/10659174/"
    },
    {
        "authors": [
            "Aaron Chester",
            "Giordano Cerizza",
            "Heather L. Crawford",
            "Ron Fox",
            "Sean N. Liddick",
            "Rebeka S. Lubna",
            "Paul Reece",
            "Tom Rockwell",
            "Jerry Vasquez"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Nuclear Science ( Early Access )",
        "date_of_publication": "18 October 2024",
        "doi": "10.1109/TNS.2024.3483555",
        "publisher": "IEEE",
        "abstract": "Real-time or nearly real-time (nearline) data processing methods are critical tools as detector technologies and data acquisition systems allow for higher data rates and volumes. The introduction of the Energy Sciences Network (ESnet), a U.S. Department of Energy (DOE) supported high-speed network for scientific research, creates opportunities to leverage the computing power of DOE facilities like the National Energy Research Scientific Computing Center (NERSC). As a first step towards realizing a DOE Office of Science Integrated Research Infrastructure (IRI) pattern, an automated workflow was developed to remotely process data obtained from a nuclear physics experiment at the Facility for Rare Isotope Beams (FRIB) at NERSC with data transferred between FRIB and NERSC over ESnet. The workflow demonstrated the ability to process one week’s worth of experimental data in approximately 90 minutes and was used successfully for nearline analysis during a recently completed FRIB experiment. A summary of the workflow development and results of recent demonstrations will be presented.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Software",
                "Pipelines",
                "Throughput",
                "Detectors",
                "Fitting",
                "Data acquisition",
                "Codes",
                "Particle beams",
                "Parallel processing",
                "Isotopes"
            ],
            "Author Keywords": [
                "Data processing",
                "ESnet",
                "Globus",
                "Superfacility workflows",
                "Workflow automation"
            ]
        },
        "Field": "data",
        "title": "High-Throughput Data Processing at FRIB Using ESnet",
        "link": "https://ieeexplore.ieee.org/document/10723091/"
    },
    {
        "authors": [
            "Wei Zhang",
            "Xiuyu Huang",
            "Andong Li",
            "Te Zhang",
            "Weiping Ding",
            "Zhaohong Deng",
            "Shitong Wang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Fuzzy Systems ( Early Access )",
        "date_of_publication": "01 November 2024",
        "doi": "10.1109/TFUZZ.2024.3489025",
        "publisher": "IEEE",
        "abstract": "Multi-view anchor graph clustering has been a prominent research area in recent years, leading to the development of several effective and efficient methods. However, three challenges are faced by current multi-view anchor graph clustering methods. First, real-world data often exhibit uncertainty and poor discriminability, leading to suboptimal anchor graphs when directly extracted from the original data. Second, most existing methods assume the presence of common information between views and primarily explore it for clustering, thus neglecting view specific information. Third, further exploration and exploitation of the learned anchor graph to enhance clustering performance remains an open research question. To address these issues, a novel dual anchor graph fuzzy clustering method is proposed in this paper. First, a novel matrix factorization based dual anchor graph learning method is proposed to address the first two issues by extracting highly discriminative hidden representations for each view and subsequently deriving both common and specific anchor graphs from these hidden representations. Then, to address the third issue, a novel anchor graph fuzzy clustering method is developed with cooperative learning to exploit and utilize the common and specific anchor graphs fully. Meanwhile, a fuzzy membership structure preservation mechanism with dual anchor graphs is constructed to enhance clustering performance. Finally, negative Shannon entropy is further introduced to adaptively adjust the view weighing. Extensive experiments on several datasets demonstrate the effectiveness of the proposed method.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Clustering methods",
                "Computer science",
                "Fuzzy systems",
                "Data mining",
                "Uncertainty",
                "Representation learning",
                "Learning systems",
                "Fuses",
                "Entropy",
                "Data models"
            ],
            "Author Keywords": [
                "multi-view data",
                "dual anchor graph learning",
                "common information",
                "specific information",
                "fuzzy clustering"
            ]
        },
        "Field": "data",
        "title": "Dual Anchor Graph Fuzzy Clustering for Multi-view Data",
        "link": "https://ieeexplore.ieee.org/document/10740036/"
    },
    {
        "authors": [
            "Hailin Li",
            "Di Dong",
            "Mengjie Fang",
            "Bingxi He",
            "Shengyuan Liu",
            "Chaoen Hu",
            "Zaiyi Liu",
            "Hexiang Wang",
            "Linglong Tang",
            "Jie Tian"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Journal of Biomedical and Health Informatics ( Early Access )",
        "date_of_publication": "22 October 2024",
        "doi": "10.1109/JBHI.2024.3484991",
        "publisher": "IEEE",
        "abstract": "Prognostic assessment remains a critical challenge in medical research, often limited by the lack of well-labeled data. In this work, we introduce ContraSurv, a weakly-supervised learning framework based on contrastive learning, designed to enhance prognostic predictions in 3D medical images. ContraSurv utilizes both the self-supervised information inherent in unlabeled data and the weakly-supervised cues present in censored data, refining its capacity to extract prognostic representations. For this purpose, we establish a Vision Transformer architecture optimized for our medical image datasets and introduce novel methodologies for both self-supervised and supervised contrastive learning for prognostic assessment. Additionally, we propose a specialized supervised contrastive loss function and introduce SurvMix, a novel data augmentation technique for survival analysis. Evaluations were conducted across three cancer types and two imaging modalities on three real-world datasets. The results confirmed the enhanced performance of ContraSurv over competing methods, particularly in data with a high censoring rate.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Biomedical imaging",
                "Contrastive learning",
                "Medical diagnostic imaging",
                "Feature extraction",
                "Data models",
                "Cancer",
                "Three-dimensional displays",
                "Solid modeling",
                "Radiomics",
                "Predictive models"
            ],
            "Author Keywords": [
                "Prognostic assessment",
                "Weakly-supervised learning",
                "Contrastive learning",
                "Medical image analysis"
            ]
        },
        "Field": "data",
        "title": "ContraSurv: Enhancing Prognostic Assessment of Medical Images via Data-Efficient Weakly Supervised Contrastive Learning",
        "link": "https://ieeexplore.ieee.org/document/10726795/"
    },
    {
        "authors": [
            "Ruize Shi",
            "Hong Huang",
            "Xue Lin",
            "Kehan Yin",
            "Wei Zhou",
            "Hai Jin"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "15 July 2024",
        "doi": "10.1109/TBDATA.2024.3428331",
        "publisher": "IEEE",
        "abstract": "Heterogeneous graph neural networks (HGNNs) excel at understanding heterogeneous information networks (HINs) and have demonstrated state-of-the-art performance across numerous tasks. However, previous works tend to study small datasets, which deviate significantly from real-world scenarios. More specifically, their heterogeneous message passing results in substantial memory and time overheads, as it requires aggregating heterogeneous neighbor features multiple times. To address this, we propose an Efficient Heterogeneous Graph Neural Network (EHGNN) that leverages heterogeneous personalized PageRank (HPPR) to preserve the influence between all nodes, then approximates message passing and selectively loads neighbor information for one aggregation, significantly reducing memory and time usage. In addition, we employ some lightweight techniques to ensure the performance of EHGNN. Evaluations on various HIN benchmarks in node classification and link prediction tasks unequivocally establish the superiority of EHGNN, surpassing the state-of-the-art by 11\n%\nin terms of performance. In addition, EHGNN achieves a remarkable 400\n%\nboost in training and inference speed while utilizing less memory. Notably, EHGNN can handle a 200-million-node, 1-billion-link HIN within 18 hours on a single machine, using only 170GB of memory, which is much lower than the previous minimum requirement of 600 GB. Our code is available at https://github.com/CGCL-codes/EHGNN .",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Graph neural networks",
                "Memory management",
                "Training",
                "Message passing",
                "Semantics",
                "Big Data"
            ],
            "Author Keywords": [
                "heterogeneous graph neural network",
                "heterogeneous information network",
                "efficiency"
            ]
        },
        "Field": "data",
        "title": "Efficient Learning for Billion-scale Heterogeneous Information Networks",
        "link": "https://ieeexplore.ieee.org/document/10598347/"
    },
    {
        "authors": [
            "Zhenzhong Wang",
            "Qingyuan Zeng",
            "Wanyu Lin",
            "Min Jiang",
            "Kay Chen Tan"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )",
        "date_of_publication": "22 October 2024",
        "doi": "10.1109/TNNLS.2024.3443074",
        "publisher": "IEEE",
        "abstract": "While graph neural networks (GNNs) have become the de facto standard for graph-based node classification, they impose a strong assumption on the availability of sufficient labeled samples. This assumption restricts the classification performance of prevailing GNNs on many real-world applications suffering from low-data regimes. Specifically, features extracted from scarce labeled nodes could not provide sufficient supervision for the unlabeled samples, leading to severe overfitting. We point out that leveraging subgraphs to capture long-range dependencies can augment the node representation, thus alleviating the low-data regime. To this end, we present a novel self-supervised learning (SSL) framework, called multiview subgraph neural networks ( Muse), for handling the long-range dependencies. In particular, we propose an information theory-based identification mechanism to identify two types of subgraphs from the views of input space and latent space, respectively. The former is to capture the local structure of the graph, while the latter captures the long-range dependencies among nodes. By fusing these two views of subgraphs, the learned representations can preserve the topological properties of the graph at large, including the local structure and long-range dependencies, thus maximizing their expressiveness. Theoretically, we provide the generalization error bound to show the effectiveness of capturing complementary information from multiview subgraphs. Empirically, we show a proof-of-concept of Muse on canonical node classification problems on graph data.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Manifolds",
                "Semantics",
                "Feature extraction",
                "Laplace equations",
                "Data mining",
                "Sugar",
                "Social networking (online)",
                "Skeleton",
                "Manifold learning",
                "Graph neural networks"
            ],
            "Author Keywords": [
                "Graph neural networks (GNNs)",
                "graph-based node classification",
                "low-data regime",
                "self-supervised learning (SSL)",
                "subgraph"
            ]
        },
        "Field": "data",
        "title": "Multiview Subgraph Neural Networks: Self-Supervised Learning With Scarce Labeled Data",
        "link": "https://ieeexplore.ieee.org/document/10729283/"
    },
    {
        "authors": [
            "Hao Jia",
            "Pere Marti-Puig",
            "Cesar F Caiafa",
            "Moises Serra-Serra",
            "Zhe Sun",
            "Jordi Solé-Casals"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Sensors Letters ( Early Access )",
        "date_of_publication": "30 October 2024",
        "doi": "10.1109/LSENS.2024.3488560",
        "publisher": "IEEE",
        "abstract": "The large number of greenhouse gas emissions caused by human activities, and their harmful effect on the earth's climate, have reached a point where actions are needed. Wind energy is one of the available green energies that can be used to mitigate this problem. Predictive maintenance is of vital importance to ensure continuous wind power generation and is typically based on the use of sensor data from all wind turbine systems. But in some cases, data contain outliers or are not available at all due to sensor or system failures. In this paper, we explore the use of tensor completion methods to estimate missing data in this field. Experimental results demonstrate the usefulness of the proposed tensor completion algorithms, especially the HaLRTC method, which outperforms the interpolation method used as a reference.",
        "issn": {
            "Electronic ISSN": "2475-1472"
        },
        "keywords": {
            "IEEE Keywords": [
                "Sensors",
                "Tensors",
                "Wind turbines",
                "Temperature sensors",
                "Sensor systems",
                "Pressure sensors",
                "Interpolation",
                "Wind energy",
                "SCADA systems",
                "Temperature measurement"
            ],
            "Author Keywords": [
                "Algorithms",
                "energy",
                "missing entries",
                "tensor completion",
                "wind farms"
            ]
        },
        "Field": "data",
        "title": "Exploring Tensor Completion for Missing Data Estimation in Wind Farms",
        "link": "https://ieeexplore.ieee.org/document/10738277/"
    },
    {
        "authors": [
            "Ziqiang Li",
            "Chaoyue Wang",
            "Xue Rui",
            "Chao Xue",
            "Jiaxu Leng",
            "Zhangjie Fu",
            "Bin Li"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Circuits and Systems for Video Technology ( Early Access )",
        "date_of_publication": "23 October 2024",
        "doi": "10.1109/TCSVT.2024.3485109",
        "publisher": "IEEE",
        "abstract": "Few-shot image generation aims to train generative models using a small number of training images. When there are few images available for training (e.g. 10 images), Learning From Scratch (LFS) methods often generate images that closely resemble the training data while Transfer Learning (TL) methods try to improve performance by leveraging prior knowledge from GANs pre-trained on large-scale datasets. However, current TL methods may not allow for sufficient control over the degree of knowledge preservation from the source model, making them unsuitable for setups where the source and target domains are not closely related. To address this, we propose a novel pipeline called Peer is your Pillar (PIP), which combines a target few-shot dataset with a peer dataset to create a data-unbalanced conditional generation. Our approach includes a class embedding method that separates the class space from the latent space, and we use a direction loss based on pre-trained CLIP to improve image diversity. Experiments on various few-shot datasets demonstrate the advancement of the proposed PIP, especially reduces the training requirements of few-shot image generation.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Image synthesis",
                "Training data",
                "Generators",
                "Pipelines",
                "Generative adversarial networks",
                "Semantics",
                "Transfer learning",
                "Data augmentation",
                "Circuits and systems"
            ],
            "Author Keywords": [
                "Few-shot image generation",
                "Generative adversarial networks",
                "Image synthesis"
            ]
        },
        "Field": "data",
        "title": "Peer is Your Pillar: A Data-unbalanced Conditional GANs for Few-shot Image Generation",
        "link": "https://ieeexplore.ieee.org/document/10731854/"
    },
    {
        "authors": [
            "Shaoshuai Fan",
            "Minhao Gu",
            "Hangchang Zhang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Nuclear Science ( Early Access )",
        "date_of_publication": "30 September 2024",
        "doi": "10.1109/TNS.2024.3470329",
        "publisher": "IEEE",
        "abstract": "In order to address the diverse requirements for data acquisition and online data processing in small-scale high-energy experiments, such as detector research and preliminary research experiments, this paper proposes a highly scalable software framework based on a plugin-based design concept. In the design, the data processing flow is broken down into basic data processing units. A plugin manager has been implemented based on the design pattern of dependency injection, allowing the framework to achieve management of plugins. Users are then able to freely assemble these units into customised data processing flow by configuration files. The framework permits the development of plugins for electronic interaction, thereby accommodating diverse electronic configurations and readout requirements. At present, the core functionality of this framework has been developed and has been applied in high-energy physics experiment. This framework provides a convenient solution for implementing data acquisition and online data processing software in high-energy physics experiments.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data acquisition",
                "Software",
                "Data processing",
                "Loading",
                "C++ languages",
                "Aggregates",
                "Libraries",
                "Data aggregation",
                "Software tools",
                "Production facilities"
            ],
            "Author Keywords": [
                "Data acquisition system",
                "plugin-based framework",
                "readout electronics",
                "online processing"
            ]
        },
        "Field": "data",
        "title": "A Plugin-Based Software Framework for Data Acquisition and Online Processing",
        "link": "https://ieeexplore.ieee.org/document/10699458/"
    },
    {
        "authors": [
            "Rong Gu",
            "Shulin Wang",
            "Haipeng Dai",
            "Xiaofei Chen",
            "Zhaokang Wang",
            "Wenjie Bao",
            "Jiaqi Zheng",
            "Yaofeng Tu",
            "Yihua Huang",
            "Lianyong Qi",
            "Xiaolong Xu",
            "Wanchun Dou",
            "Guihai Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE/ACM Transactions on Networking ( Early Access )",
        "date_of_publication": "10 October 2024",
        "doi": "10.1109/TNET.2024.3402561",
        "publisher": "IEEE",
        "abstract": "Nowadays, there exists a lot of cross-region data transmission demand on the cloud. It is promising to use serverless computing for data compressing to save the total data size. However, it is challenging to estimate the data transmission time and monetary cost with serverless compression. In addition, minimizing the data transmission cost is non-trivial due to the enormous parameter space. This paper focuses on this problem and makes the following contributions: 1) We propose empirical data transmission time and monetary cost models based on serverless compression. It can also predict compression information, e.g., ratio and speed using chunk sampling and machine learning techniques. 2) For single-task cloud data transmission, we propose two efficient parameter search methods based on Sequential Quadratic Programming (SQP) and Eliminate then Divide and Conquer (EDC) with proven error upper bounds. Besides, we propose a parameter fine-tuning strategy to deal with transmission bandwidth variance. 3) Furthermore, for multi-task scenarios, a parameter search method based on dynamic programming and numerical computation is proposed. We have implemented the system called Fluid-Shuttle, which includes straggler optimization, cache optimization, and the autoscaling decompression mechanism. Finally, we evaluate the performance of Fluid-Shuttle with various workloads and applications on the real-world AWS serverless computing platform. Experimental results show that the proposed approach can improve the parameter search efficiency by over 3\n×\ncompared with the state-of-art methods and achieves better parameter quality. In addition, our approach achieves higher time efficiency and lower monetary cost compared with competing cloud data transmission approaches.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data communication",
                "Costs",
                "Bandwidth",
                "Data models",
                "Serverless computing",
                "Data compression",
                "Writing",
                "Optimization",
                "Concurrent computing",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Data transmission",
                "serverless compression",
                "cloud function configuration"
            ]
        },
        "Field": "data",
        "title": "Fluid-Shuttle: Efficient Cloud Data Transmission Based on Serverless Computing Compression",
        "link": "https://ieeexplore.ieee.org/document/10713271/"
    },
    {
        "authors": [
            "Kong Li",
            "Zhe Dai",
            "Xuan Wang",
            "Yongchao Song",
            "Gwanggil Jeon"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Consumer Electronics ( Early Access )",
        "date_of_publication": "11 April 2024",
        "doi": "10.1109/TCE.2024.3387557",
        "publisher": "IEEE",
        "abstract": "Ensuring the accuracy of visual perception systems is crucial for the construction of intelligent transportation systems. However, in low-visibility traffic scenarios, the scarcity of data and the high cost of annotation make acquiring high-quality image data a significant challenge. Existing data augmentation methods often struggle to meet the requirements of both realism and diversity when generating the needed data. To address this issue, this study proposes a controllable data augmentation technique. Firstly, we improved the architecture and basic units of the Pix2Pix generator network to optimize the detail texture of generated images. Secondly, we introduced adaptive alpha channel technology to make the blending of generated images with original images more natural. Finally, by adjusting the alpha channel, we can precisely control the degree of fusion to produce augmented data that better meets actual needs. Experiments on the proposed surveillance view nighttime image dataset (SVNTI) and NuScenes dataset demonstrate that our method significantly enhances detection performance in nighttime scenarios, validating the effectiveness and potential of controllable data augmentation technology.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data augmentation",
                "Generators",
                "Data models",
                "Visualization",
                "Training",
                "Computational modeling",
                "Training data"
            ],
            "Author Keywords": [
                "Controlled generation",
                "Data augmentation",
                "Low-visibility image",
                "Pix2Pix",
                "Visual detection"
            ]
        },
        "Field": "data",
        "title": "GAN-Based Controllable Image Data Augmentation in Low-Visibility Conditions for Improved Roadside Traffic Perception",
        "link": "https://ieeexplore.ieee.org/document/10497173/"
    },
    {
        "authors": [
            "Xudong Pan",
            "Mi Zhang",
            "Yifan Yan",
            "Shengyao Zhang",
            "Min Yang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Pattern Analysis and Machine Intelligence ( Early Access )",
        "date_of_publication": "26 July 2024",
        "doi": "10.1109/TPAMI.2024.3434417",
        "publisher": "IEEE",
        "abstract": "High-quality private machine learning (ML) data stored in local data centers becomes a key competitive factor for AI corporations. In this paper, we present a novel insider attack called Matryoshka to reveal the possibility of breaking the privacy of ML data even with no exposed interface. Our attack employs a scheduled-to-publish DNN model as a carrier model for covert transmission of secret models which memorize the information of private ML data that otherwise has no interface to the outsider. At the core of our attack, we present a novel parameter sharing approach which exploits the learning capacity of the carrier model for information hiding. Our approach simultaneously achieves: (i) High Capacity – With almost no utility loss of the carrier model, Matryoshka can transmit over 10,000 real-world data samples within a carrier model which has $220\\times$ less parameters than the total size of the stolen data, and simultaneously transmit multiple heterogeneous datasets or models within a single carrier model under a trivial distortion rate, neither of which can be done with existing steganography techniques; (ii) Decoding Efficiency – once downloading the published carrier model, an outside colluder can exclusively decode the hidden models from the carrier model with only several integer secrets and the knowledge of the hidden model architecture; (iii) Effectiveness – Moreover, almost all the recovered models either have similar performance as if it is trained independently on the private data, or can be further used to extract memorized raw training data with low error; (iv) Robustness – Information redundancy is naturally implemented to achieve resilience against common post-processing techniques on the carrier before its publishing; (v) Covertness – A model inspector with different levels of prior knowledge could hardly differentiate a carrier model from a normal model.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Training",
                "Predictive models",
                "Training data",
                "Computational modeling",
                "Task analysis",
                "Data privacy"
            ],
            "Author Keywords": [
                "Training Data Privacy",
                "Deep Learning Privacy",
                "Steganography",
                "Covert Transmission",
                "AI Security"
            ]
        },
        "Field": "data",
        "title": "Matryoshka: Exploiting the Over-Parametrization of Deep Learning Models for Covert Data Transmission",
        "link": "https://ieeexplore.ieee.org/document/10612241/"
    },
    {
        "authors": [
            "Brian Belgodere",
            "Pierre Dognin",
            "Adam Ivankay",
            "Igor Melnyk",
            "Youssef Mroueh",
            "Aleksandra Mojsilovic",
            "Jiri Navratil",
            "Apoorva Nitsure",
            "Inkit Padhi",
            "Mattia Rigotti",
            "Jerret Ross",
            "Yair Schiff",
            "Radhika Vedpathak",
            "Richard A. Young"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Journal on Emerging and Selected Topics in Circuits and Systems ( Early Access )",
        "date_of_publication": "10 October 2024",
        "doi": "10.1109/JETCAS.2024.3477976",
        "publisher": "IEEE",
        "abstract": "Real-world data often exhibits bias, imbalance, and privacy risks. Synthetic datasets have emerged to address these issues by enabling a paradigm that relies on generative AI models to generate unbiased, privacy-preserving data while maintaining fidelity to the original data. However, assessing the trustworthiness of synthetic datasets and models is a critical challenge. We introduce a holistic auditing framework that comprehensively evaluates synthetic datasets and AI models. It focuses on preventing bias and discrimination, ensuring fidelity to the source data, and assessing utility, robustness, and privacy preservation. We demonstrate our framework’s effectiveness by auditing various generative models across diverse use cases like education, healthcare, banking, and human resources, spanning different data modalities such as tabular, time-series, vision, and natural language. This holistic assessment is essential for compliance with regulatory safeguards. We introduce a trustworthiness index to rank synthetic datasets based on their safeguards trade-offs. Furthermore, we present a trustworthiness-driven model selection and cross-validation process during training, exemplified with “TrustFormers” across various data types. This approach allows for controllable trustworthiness trade-offs in synthetic data creation. Our auditing framework fosters collaboration among stakeholders, including data scientists, governance experts, internal reviewers, external certifiers, and regulators. This transparent reporting should become a standard practice to prevent bias, discrimination, and privacy violations, ensuring compliance with policies and providing accountability, safety, and performance guarantees.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Synthetic data",
                "Indexes",
                "Data models",
                "Artificial intelligence",
                "Data privacy",
                "Training",
                "Robustness",
                "Circuits and systems",
                "Measurement",
                "Uncertainty"
            ],
            "Author Keywords": [
                "Trustworthy AI",
                "Synthetic Data",
                "Auditing",
                "Generative AI"
            ]
        },
        "Field": "data",
        "title": "Auditing and Generating Synthetic Data with Controllable Trust Trade-offs",
        "link": "https://ieeexplore.ieee.org/document/10713321/"
    },
    {
        "authors": [
            "Xiaomao Zhou",
            "Yujiao Hu",
            "Qingmin Jia",
            "Renchao Xie"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Sensors Journal ( Early Access )",
        "date_of_publication": "21 October 2024",
        "doi": "10.1109/JSEN.2024.3480932",
        "publisher": "IEEE",
        "abstract": "Synthetic data has emerged as a critical component in the fields of machine learning and data science, providing a solution to overcome limitations associated with real-world data, including scarcity, privacy concerns, and the high cost of acquisition. While existing generative models demonstrate promising results in synthesizing various sensor data, they are struggling to enhance performance and generalization. In this paper, we introduce a Large Language Models (LLMs) driven framework that leverages the power of LLMs in concert with various domain-specific generative models (DGMs) for general sensor data synthesis. Specifically, our method employs LLMs as the core to interpret task requests, decompose a complex task into a manageable set of sub-tasks, and delegate each sub-task to the most suitable DGM, thereby automatically constructing customized data generation pipelines. Meanwhile, DGMs contribute their expertise to generate high-fidelity, domain-relevant data, whose specialized knowledge can be further enhanced by the LLM’s broad linguistic knowledge via knowledge transfer. In addition, the integration of Diffusion Model (DM) based Reinforcement Learning (RL) is promising to enhance the framework’s ability to optimally utilize DGMs, resulting in data generation with superior quality and control flexibility. Experimental results demonstrate the effectiveness of LLMs in augmenting DGMs via knowledge transfer and in facilitating multi-modal data synthesis through collaborative interactions with diverse DGMs, which is further improved by the DM-based refinement process.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Sensors",
                "Data models",
                "Data collection",
                "Sensor phenomena and characterization",
                "Adaptation models",
                "Synthetic data",
                "Reinforcement learning",
                "Planning",
                "Pipelines",
                "Knowledge transfer"
            ],
            "Author Keywords": [
                "Sensor data synthesis",
                "Large Language Models",
                "generative models",
                "knowledge transfer",
                "Diffusion Model",
                "Reinforcement Learning"
            ]
        },
        "Field": "data",
        "title": "Cross-Domain Integration for General Sensor Data Synthesis: Leveraging LLMs and Domain-Specific Generative Models in Collaborative Environments",
        "link": "https://ieeexplore.ieee.org/document/10726709/"
    },
    {
        "authors": [
            "Jiahao Wu",
            "Wenqi Fan",
            "Jingfan Chen",
            "Shengcai Liu",
            "Qijiong Liu",
            "Rui He",
            "Qing Li",
            "Ke Tang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Knowledge and Data Engineering ( Early Access )",
        "date_of_publication": "22 October 2024",
        "doi": "10.1109/TKDE.2024.3484249",
        "publisher": "IEEE",
        "abstract": "Training recommendation models on large datasets requires significant time and resources. It is desired to construct concise yet informative datasets for efficient training. Recent advances in dataset condensation show promise in addressing this problem by synthesizing small datasets. However, applying existing methods of dataset condensation to recommendation has limitations: (1) they fail to generate discrete user-item interactions, and (2) they could not preserve users' potential preferences. To address the limitations, we propose a lightweight condensation framework tailored for recommendation ( DConRec ), focusing on condensing user-item historical interaction sets. Specifically, we model the discrete user-item interactions via a probabilistic approach and design a pre-augmentation module to incorporate the potential preferences of users into the condensed datasets. While the substantial size of datasets leads to costly optimization, we propose a lightweight policy gradient estimation to accelerate the data synthesis. Experimental results on multiple real-world datasets have demonstrated the effectiveness and efficiency of our framework. Besides, we provide a theoretical analysis of the provable convergence of DConRec. The implementation is available at: https://github.com/JiahaoWuGit/DConRec .",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Optimization",
                "Data models",
                "Training",
                "Estimation",
                "Probabilistic logic",
                "Convergence",
                "Computational modeling",
                "Costs",
                "Business process re-engineering",
                "Synthetic data"
            ],
            "Author Keywords": [
                "Recommendation",
                "dataset condensation"
            ]
        },
        "Field": "data",
        "title": "Condensing Pre-augmented Recommendation Data via Lightweight Policy Gradient Estimation",
        "link": "https://ieeexplore.ieee.org/document/10726790/"
    },
    {
        "authors": [
            "Xiaoyu Hu",
            "Lang Zhang",
            "Jinming Ge",
            "Qingyu Mu",
            "Meihua Wang",
            "Bochun Liu",
            "Jiajing Du",
            "Zihang Han",
            "Leyi Wang",
            "Hui Wang",
            "Ruilin Zhou"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing ( Early Access )",
        "date_of_publication": "04 November 2024",
        "doi": "10.1109/JSTARS.2024.3491160",
        "publisher": "IEEE",
        "abstract": "Deep convective systems (DCSs) play a crucial role in global water cycles, energy distribution, and extreme weather events. This study aims to enhance the understanding of DCSs by creating a comprehensive dataset through the fusion of multi-source A-Train satellite observations and reanalysis data. Fusing data from multiple active and passive sensors allows us to capture detailed vertical profiles and life stages of DCSs, overcoming the limitations of polar-orbiting satellites in tracking convection over time. Comparison with convection tracking data from geostationary satellites confirmed the reliability of lifecycle determination. Reanalysis data are included for each observed DCS samples, incorporating environmental conditions and aerosol data up to 36 hours before the DCS occurrence. Using the fused dataset, we examined the radiative properties of DCSs across different stages of their lifecycle and the influence of environmental factors and aerosols on them. Radiative heating rates showed distinct variations, with mature stages exhibiting the highest shortwave heating and longwave cooling rates due to denser and higher cloud tops. Our findings reveal the role of humidity in increasing cloud top heights and the influence of vertical wind shear on convection development. Additionally, aerosol impacts were notable during the mature and dissipating stages, with higher concentrations linked to increased cloud top heights and lower temperatures. This comprehensive dataset advances the understanding of DCS dynamics, aiding in the improvement of predictive models for severe weather.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Clouds",
                "Laser radar",
                "Satellites",
                "Spaceborne radar",
                "Radar",
                "Cloud computing",
                "Aerosols",
                "Meteorology",
                "Convection",
                "MODIS"
            ],
            "Author Keywords": [
                "A-train satellites",
                "cloud radiative effect",
                "data fusion",
                "deep convective system"
            ]
        },
        "Field": "data",
        "title": "Fusing Multi-Source A-Train Satellites and Reanalysis Data for a Comprehensive Deep Convective System Dataset",
        "link": "https://ieeexplore.ieee.org/document/10742418/"
    },
    {
        "authors": [
            "Nwamaka Okafor",
            "Ruchita Ingle",
            "Ugochukwu Matthew",
            "Matthew Saunders",
            "Declan Delaney"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "04 September 2024",
        "doi": "10.1109/JIOT.2024.3454241",
        "publisher": "IEEE",
        "abstract": "Advances in Internet of Things (IoT) technologies have resulted in a significant surge in the utilization of sensor devices across diverse domains for environmental sensing and monitoring. The applications of IoT sensor devices in environmental monitoring span a wide range, including the surveillance of biodiverse areas such as peatlands, forests, and oceans, as well as air quality monitoring, commercial agriculture, and the safeguarding of endangered species. This paper provides a long term evaluation of IoT sensors data quality in environmental monitoring networks, particularly focusing on peatlands. IoT sensors have the capacity to provide high resolution spatiotemporal dataset in environmental monitoring networks. Sensor data quality plays a significant role in increasing the adoption of IoT devices for environmental data gathering. However, logistics challenges(i.e., in harsh and unfavourable weather conditions) along with low-cost components limitations adds on to the data collection errors. This paper identifies specific challenges and issues related to IoT sensor data quality in different peatland ecotopes. These challenges include sensor placement and calibration, data validation and fusion, environmental interference, and the management of data gaps and uncertainties. This research work evaluates methods for improving data quality in peatland monitoring network by encompassing advanced sensor calibration techniques, data validation algorithms, machine learning approaches, data processing and data fusion strategies.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Monitoring",
                "Internet of Things",
                "Atmospheric modeling",
                "Atmospheric measurements",
                "Environmental monitoring",
                "Data integrity",
                "Ecosystems"
            ],
            "Author Keywords": [
                "Calibration",
                "Data quality",
                "Data processing",
                "Data validation",
                "IoT sensors",
                "Machine learning",
                "Peatlands"
            ]
        },
        "Field": "data",
        "title": "Assessing and Improving IoT Sensor Data Quality in Environmental Monitoring Networks: A Focus on Peatlands",
        "link": "https://ieeexplore.ieee.org/document/10664494/"
    },
    {
        "authors": [
            "Zhong Yuan",
            "Peng Hu",
            "Hongmei Chen",
            "Yingke Chen",
            "Qilin Li"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Knowledge and Data Engineering ( Early Access )",
        "date_of_publication": "21 October 2024",
        "doi": "10.1109/TKDE.2024.3484448",
        "publisher": "IEEE",
        "abstract": "Outlier Detection (OD) has attracted extensive research due to its application in many fields. The idea of neighborhood computing is one of the widely used methods in outlier analysis. Nevertheless, these methods mainly use certainty strategies to model outlier detection, so they cannot effectively handle the fuzzy information in the dataset. Moreover, they mainly focus on dealing with outlier detection in numerical data and cannot effectively find outliers in mixed-attribute data. Fuzzy information granulation theory is an effective granular computing model that allows objects to belong to a set to a certain extent (i.e., membership degree), which makes it possible to better handle uncertainty problems such as fuzziness. In this work, we propose an outlier detection model based on fuzzy neighborhoods. First, a hybrid fuzzy similarity is constructed to granulate the set of objects to form fuzzy information granules. Second, the fuzzy\nk\n-nearest neighbor is defined to describe the fuzzy local information. Then, the fuzzy neighborhood density is defined to indicate the degree of aggregation of each object. The smaller the fuzzy neighborhood density of an object, the more likely it is to be an outlier. Based on this idea, the fuzzy neighborhood deviation degree is defined to quantify the degree of outliers of objects. Finally, the fuzzy deviation degree on the set of conditional attributes is constructed to indicate the outlier scores of objects. Experimental comparisons with state-of-the-art methods show that the proposed method has a significant improvement on the AUC index and applies to three types of data.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Anomaly detection",
                "Computational modeling",
                "Data models",
                "Nearest neighbor methods",
                "Uncertainty",
                "Numerical models",
                "Measurement",
                "Kernel",
                "Data engineering",
                "Indexes"
            ],
            "Author Keywords": [
                "Granular computing",
                "fuzzy information granulation theory",
                "fuzzy neighborhood",
                "outlier detection",
                "mixed-attribute data"
            ]
        },
        "Field": "data",
        "title": "DFNO: Detecting Fuzzy Neighborhood Outliers",
        "link": "https://ieeexplore.ieee.org/document/10726700/"
    },
    {
        "authors": [
            "Md. Yunus Naseri",
            "Caitlin Snyder",
            "Katherine X. Pérez-Rivera",
            "Sambridhi Bhandari",
            "Habtamu Alemu Workneh",
            "Niroj Aryal",
            "Gautam Biswas",
            "Erin C. Henrick",
            "Erin R. Hotchkiss",
            "Manoj K. Jha",
            "Steven Jiang",
            "Emily C. Kern",
            "Vinod K. Lohani",
            "Landon T. Marston",
            "Christopher P. Vanags",
            "Kang Xia"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Education ( Early Access )",
        "date_of_publication": "05 September 2024",
        "doi": "10.1109/TE.2024.3436041",
        "publisher": "IEEE",
        "abstract": "Contribution: This article discusses a research–practice partnership (RPP) where instructors from six undergraduate courses in three universities developed data science modules tailored to the needs of their respective disciplines, academic levels, and pedagogies.\nBackground: STEM disciplines at universities are incorporating data science topics to meet employer demands for data science-savvy graduates. Integrating these topics into regular course materials can benefit students and instructors. However, instructors encounter challenges in integrating data science instruction into their course schedules.\nResearch Questions: How did instructors from multiple engineering and science disciplines working in an RPP integrate data science into their undergraduate courses?\nMethodology: A multiple case study approach, with each course as a unit of analysis, was used to identify data science topics and integration approaches.\nFindings: Instructors designed their modules to meet specific course needs, utilizing them as primary or supplementary learning tools based on their course structure and pedagogy. They selected a subset of discipline-agnostic data science topics, such as generating and interpreting visualizations and conducting basic statistical analyses. Although instructors faced challenges due to varying data science skills of their students, they valued the control they had in integrating data science content into their courses. They were uncertain about whether the modules could be adopted for use by other instructors, specifically by those outside of their discipline, but they all believed the approach for developing and integrating data science could be adapted to student needs in different situations.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data science",
                "STEM",
                "Green products",
                "Iterative methods",
                "Data visualization",
                "Collaboration",
                "Surveys"
            ],
            "Author Keywords": [
                "Data literacy",
                "data science integration",
                "modular approach",
                "research–practice partnership (RPP)",
                "STEM"
            ]
        },
        "Field": "data",
        "title": "Integrating Data Science Into Undergraduate Science and Engineering Courses: Lessons Learned by Instructors in a Multiuniversity Research–Practice Partnership",
        "link": "https://ieeexplore.ieee.org/document/10666964/"
    },
    {
        "authors": [
            "Himan Namdari",
            "Majid Moradikia",
            "Seyed Zekavat",
            "Radwin Askari",
            "Oren Mangoubi",
            "Doug Petkie"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on AgriFood Electronics ( Early Access )",
        "date_of_publication": "04 October 2024",
        "doi": "10.1109/TAFE.2024.3455238",
        "publisher": "IEEE",
        "abstract": "In this article, we investigate an intelligent ground penetrating radar (GPR) that facilitates root-zone soil moisture estimation, a key parameter in precision agriculture. To create an intelligent GPR, we must train machine learning (ML) methods applied to the GPR-received signal. This process requires a large number of labeled GPR data that would be time-consuming and labor-intensive if created via field measurements. This article uses gprMAX software to emulate drone-coupled GPR received signal to generate large-scale data for training ML models. The data are created via a 1.5 GHz Ricker waveform considering a three-layer soil consistent with a realistic soil horizon model. The approach is structured as follows: first, we generate a synthetic dataset using gprMAX. Feature engineering techniques are then employed to extract meaningful components from the GPR signals, followed by a rigorous selection process to identify the most effective ML model for soil moisture prediction. Finally, we validate our model by integrating synthetic data with real GPR data collected at the SoilX lab at Worcester Polytechnic Institute, enhancing prediction accuracy and generalization capability. Our proposed model achieves an overall average root-mean-squared error of 0.5%, and 1.56 cm for moisture and depth estimations, respectively. The proposed intelligent GPR, when installed on a drone, enables high horizontal (e.g., 10 m) and vertical (e.g., 1.5 cm) resolution and high penetration depth (beyond 2 m) megafarm root-zone 3-D moisture map creation. Thus, it offers much higher capabilities when compared to traditional methods, such as synthetic aperture radar and satellite imaging. These results facilitate efficient farming practices, such as optimizing irrigation models, for better crop yields and food security.",
        "issn": {
            "Electronic ISSN": "2771-9529"
        },
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Mathematical models",
                "Data models",
                "Soil moisture",
                "Synthetic data",
                "Moisture",
                "Radar",
                "Permittivity",
                "Training",
                "Soil measurements"
            ],
            "Author Keywords": [
                "Feature extraction",
                "gprMAX simulations",
                "ground penetration radar (GPR)",
                "machine learning (ML)",
                "root zone soil moisture estimation (SME)"
            ]
        },
        "Field": "data",
        "title": "Advancing Precision Agriculture: Machine Learning-Enhanced GPR Analysis for Root-Zone Soil Moisture Assessment in Mega Farms",
        "link": "https://ieeexplore.ieee.org/document/10705894/"
    },
    {
        "authors": [
            "Xiongtao Zhang",
            "Ji Wang",
            "Weidong Bao",
            "Yaohong Zhang",
            "Xiaomin Zhu",
            "Hao Peng",
            "Xiang Zhao"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )",
        "date_of_publication": "12 August 2024",
        "doi": "10.1109/TNNLS.2024.3405190",
        "publisher": "IEEE",
        "abstract": "Conventional federated learning (FL) assumes the homogeneity of models, necessitating clients to expose their model parameters to enhance the performance of the server model. However, this assumption cannot reflect real-world scenarios. Sharing models and parameters raises security concerns for users, and solely focusing on the server-side model neglects clients’ personalization requirements, potentially impeding expected performance improvements of users. On the other hand, prioritizing personalization may compromise the generalization of the server model, thereby hindering extensive knowledge migration. To address these challenges, we put forth an important problem: How can FL ensure both generalization and personalization when clients’ models are heterogeneous? In this work, we introduce FedTED, which leverages a twin-branch structure and data-free knowledge distillation (DFKD) to address the challenges posed by model heterogeneity and diverse objectives in FL. The employed techniques in FedTED yield significant improvements in both personalization and generalization, while effectively coordinating the updating process of clients’ heterogeneous models and successfully reconstructing a satisfactory global model. Our empirical evaluation demonstrates that FedTED outperforms many representative algorithms, particularly in scenarios where clients’ models are heterogeneous, achieving a remarkable 19.37% enhancement in generalization performance and up to 9.76% improvement in personalization performance.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Adaptation models",
                "Servers",
                "Feature extraction",
                "Training",
                "Data models",
                "Federated learning",
                "Optimization"
            ],
            "Author Keywords": [
                "Data-free distillation",
                "federated learning (FL)",
                "model heterogeneity",
                "personalization–generalization coexistence"
            ]
        },
        "Field": "data",
        "title": "Improving Generalization and Personalization in Model-Heterogeneous Federated Learning",
        "link": "https://ieeexplore.ieee.org/document/10633723/"
    },
    {
        "authors": [
            "Teerath Kumar",
            "Rob Brennan",
            "Alessandra Mileo",
            "Malika Bendechache"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "30 September 2024",
        "doi": "10.1109/ACCESS.2024.3470122",
        "publisher": "IEEE",
        "abstract": "Deep learning algorithms have exhibited impressive performance across various computer vision tasks; however, the challenge of overfitting persists, especially when dealing with limited labeled data. This survey explores the mitigation of the overfitting issue through a comprehensive examination of image data augmentation techniques, which aim to enhance dataset size and diversity by introducing varied samples. The survey exclusively focuses on these techniques, presenting an insightful overview and introducing a novel taxonomy. The discussion encompasses the strengths and limitations of these techniques. Additionally, the paper provides extensive results evaluating the impact of these techniques on prevalent computer vision tasks: image classification, object detection, and semantic segmentation. The survey concludes with an examination of challenges, limitations, and potential future research directions.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Data augmentation",
                "Taxonomy",
                "Surveys",
                "Data models",
                "Computer vision",
                "Computational modeling",
                "Training",
                "Image classification",
                "Deep learning",
                "Solid modeling"
            ],
            "Author Keywords": [
                "Computer vision",
                "Data Augmentation",
                "Deep learning",
                "Image classification",
                "Object detection",
                "Segmentation"
            ]
        },
        "Field": "data",
        "title": "Image Data Augmentation Approaches: A Comprehensive Survey and Future Directions",
        "link": "https://ieeexplore.ieee.org/document/10699340/"
    },
    {
        "authors": [
            "Jiawei Wu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Consumer Electronics ( Early Access )",
        "date_of_publication": "16 October 2024",
        "doi": "10.1109/TCE.2024.3482113",
        "publisher": "IEEE",
        "abstract": "The role of Big-data is imperative in Blockchain-based trading systems, cloud-based applications, P2P-based applications, and parallel communications. It is very important to fuse the data obtained from heterogeneous Blockchain nodes in such a way that it can provide some useful information after processing. The analysis of the data must be made without losing the useful chunks of the information especially when it involves financial transactions. By combining the data from multiple sources in a Blockchain environment, the accuracy and completeness of data can be assured. The reliability of data is also enhanced since the data can be validated easily with the cross-reference points. The integration of data allows comprehensive analysis of data and also helps in decision making. It also helps in detection of frauds by reducing the dimensionality of data. In order to improve the interaction in the data, and to enhance the data transmission rate, a new soft computing based data fusion control model has been proposed in this article for the fusion of data in Blockchain databases that supports communications over 6G channels. The proposed model comprises hardware and software components along with soft computing based smart data fusion mechanism. The proposed soft computing-based mechanism behaves smartly to process the volume of data by training the system implicitly. The fuzzy logic-based similarity matrix is also devised by calculating the similarity in the data instances to make the system more adaptive. The fusion of a Big-data in the Blockchain systems is performed on the basis of the proposed model for controlling the data interactions. The empirical results show that the proposed data fusion control model for Big-data in the Blockchain system is reliable, secure, and has lower response time. The packet loss rate is low and data transmission is high which proves the viability and robustness of the proposed fusion model for Blockchain enabled applications.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Blockchains",
                "Data models",
                "Data integration",
                "Security",
                "Analytical models",
                "Data analysis",
                "Data privacy",
                "Computational modeling",
                "Interoperability",
                "Encryption"
            ],
            "Author Keywords": [
                "Information fusion",
                "Heterogeneous database",
                "6G communications",
                "Evidence theory",
                "Security",
                "Blockchain"
            ]
        },
        "Field": "data",
        "title": "Data Fusion Mechanism as a Tool for Consumer Electronics to Enhance Security in Blockchain Enabled Applications",
        "link": "https://ieeexplore.ieee.org/document/10720076/"
    },
    {
        "authors": [
            "Yao Zhang",
            "Yun Xiong",
            "Yiheng Sun",
            "Yucheng Jin",
            "Caihua Shan",
            "Tian Lu",
            "Hui Song",
            "Shengli Sun"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Knowledge and Data Engineering ( Early Access )",
        "date_of_publication": "29 October 2024",
        "doi": "10.1109/TKDE.2024.3487625",
        "publisher": "IEEE",
        "abstract": "Risk scoring systems have been widely deployed in many applications, which assign risk scores to users according to their behavior sequences. Though many deep learning methods with sophisticated designs have achieved promising results, the black-box nature hinders their applications due to fairness, explainability, and compliance consideration. Rule-based systems are considered reliable in these sensitive scenarios. However, building a rule system is labor-intensive. Experts need to find informative statistics from user behavior sequences, design rules based on statistics and assign weights to each rule. In this paper, we bridge the gap between effective but black-box models and transparent rule models. We propose a two-stage framework, CauseRuDi, that distills the knowledge of black-box teacher models into rule-based student models. We design a Monte Carlo tree search-based statistics generation method that maximizes the correlation or dependence between the generated statistics and the teacher model's outputs. We formulate a sequential move game and a simultaneous move coalitional game to generate multiple statistics. Then statistics are composed into logical rules with our proposed neural logical networks by mimicking the outputs of teacher models. We evaluate CauseRuDi on three real-world public datasets and an industrial dataset to demonstrate its effectiveness.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Closed box",
                "Games",
                "Neural networks",
                "Data models",
                "Computational modeling",
                "Sun",
                "Space exploration",
                "Reliability",
                "Feature extraction",
                "Decision trees"
            ],
            "Author Keywords": [
                "statistics generation",
                "rule distillation",
                "sequence model explanation"
            ]
        },
        "Field": "data",
        "title": "CauseRuDi: Explaining Behavior Sequence Models by Causal Statistics Generation and Rule Distillation",
        "link": "https://ieeexplore.ieee.org/document/10737680/"
    },
    {
        "authors": [
            "Wenjiang Ouyang",
            "Qian Liu",
            "Junsheng Mu",
            "Anwer AI-Dulaimi",
            "Xiaojun Jing",
            "Qilie Liu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Systems Journal ( Early Access )",
        "date_of_publication": "06 September 2024",
        "doi": "10.1109/JSYST.2024.3450883",
        "publisher": "IEEE",
        "abstract": "Integrated sensing and communication (ISAC) has attracted great attention with the gains of spectrum efficiency and deployment costs through the coexistence of sensing and communication functions. Meanwhile, federated learning (FL) has great potential to apply to large-scale multiagent systems (LSMAS) in ISAC due to the attractive privacy protection mechanism. Nonindependent identically distribution (non-IID) is a fundamental challenge in FL and seriously affects the convergence performance. To deal with the non-IID issue in FL, a data augmentation optimization algorithm (DAOA) is proposed based on reinforcement learning (RL), where an augmented dataset is generated based on a generative adversarial network (GAN) and the local model parameters are inputted into a deep Q-network (DQN) to learn the optimal number of augmented data. Different from the existing works that only optimize the training performance, the number of augmented data is also considered to improve the sample efficiency in the article. In addition, to alleviate the high-dimensional input challenge in DQN and reduce the communication overhead in FL, a lightweight model is applied to the client based on deep separable convolution (DSC). Simulation results indicate that our proposed DAOA algorithm acquires considerable performance with significantly fewer augmented data, and the communication overhead is reduced greatly compared with benchmark algorithms.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Training",
                "Data augmentation",
                "Integrated sensing and communication",
                "Generative adversarial networks",
                "Federated learning",
                "Data privacy"
            ],
            "Author Keywords": [
                "Data augmentation",
                "deep reinforcement learning",
                "federated learning (FL)",
                "integrated sensing and communication (ISAC)",
                "large-scale multiagent systems (LSMAS)"
            ]
        },
        "Field": "data",
        "title": "Communication-Efficient Federated Learning for Large-Scale Multiagent Systems in ISAC: Data Augmentation With Reinforcement Learning",
        "link": "https://ieeexplore.ieee.org/document/10669033/"
    },
    {
        "authors": [
            "Wanxing Sheng",
            "Huaitian Zhang",
            "Ke-Yan Liu",
            "Xiaoli Meng"
        ],
        "locations": [],
        "published_in": "Published in: CSEE Journal of Power and Energy Systems ( Early Access )",
        "date_of_publication": "08 September 2023",
        "doi": "10.17775/CSEEJPES.2020.05010",
        "publisher": "CSEE",
        "abstract": "Sustainable development of Power and Energy system (PES) can effectively handle the challenges of fuel shortage, environmental pollution, climate change, energy security, etc. The data of PES presents the distinctive characteristics including large collection, wide coverage, diverse temporal and spatial scales, inconsistent sparsity, multiple structures and low value density, putting forward higher requirements for the real-time and accuracy of data analysis, and bringing great challenges to the operation analysis and coordinated control of PES. In order to realize data quality improvement and further support flexible choice of operating mode, safe and efficient coordinated control, dynamic and orderly fault recovery of sustainable PES, this paper proposes an unscented particle filter algorithm, adopting unscented Kalman filter to construct importance density function and KLD resampling to dynamically adjust the particle number. Simulation results obtained by taking an 85-node system as a benchmark for simulation verification show that compared with traditional PF algorithm and UKF algorithm, UPF algorithm has higher estimation accuracy.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Power and energy standards",
                "Data integrity",
                "Kalman filters",
                "Climate change",
                "Sampling methods",
                "Particle filters",
                "Sustainable development",
                "Power distribution networks",
                "Fuel economy"
            ],
            "Author Keywords": [
                "Power and Energy system",
                "data quality improvement",
                "particle filter",
                "unscented Kalman filter",
                "KLD resampling"
            ]
        },
        "Field": "data",
        "title": "An unscented particle filter algorithm towards data quality improvement in sustainable distribution power systems",
        "link": "https://ieeexplore.ieee.org/document/10246191/"
    },
    {
        "authors": [
            "Junhyuck Lee",
            "Yemin Kim",
            "Dongil Kang",
            "Ickhyun Song",
            "Byunghun Lee"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Biomedical Circuits and Systems ( Early Access )",
        "date_of_publication": "21 October 2024",
        "doi": "10.1109/TBCAS.2024.3483950",
        "publisher": "IEEE",
        "abstract": "This paper presents a reconfigurable bidirectional wireless power and data transceiver (RB-WPDT) integrated circuit (IC) for wearable biomedical applications. The proposed transceiver can be reconfigured as a differential class-D power amplifier or a full-wave rectifier depending on the mode signal to facilitate power transfer between devices. Additionally, the RBWPDT system supports full-duplex (FD) data transmission via a single inductive link, enabling real-time control and monitoring between devices. The proposed FD method utilizes frequency shift-keying pulse-width modulation (FSK-PWM) for downlink and load shift-keying (LSK) for uplink, achieving simultaneous bidirectional data transmission by ensuring that the FSK-PWM downlink and LSK uplink data channels operate independently with minimal interference. The measured downlink and uplink data rates are 250 kb/s and 67 kb/s, respectively. The measured overall DC-to-DC efficiency is 49%, while the power delivered to the load (PDL) is 120 mW at a 5 mm distance. The proposed chip is fabricated using a 180-nm BCD CMOS process.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data communication",
                "Wireless communication",
                "Uplink",
                "Transceivers",
                "Downlink",
                "Frequency shift keying",
                "Wireless sensor networks",
                "Full-duplex system",
                "Biomedical monitoring",
                "Wearable devices"
            ],
            "Author Keywords": [
                "Wireless power transfer (WPT)",
                "wireless power and data transfer (WPDT)",
                "reconfigurable transceiver",
                "full-duplex (FD) data transmission",
                "bidirectional wireless power and data transfer",
                "inductive link",
                "wearable device"
            ]
        },
        "Field": "data",
        "title": "A Reconfigurable Bidirectional Wireless Power and Full-Duplex Data Transceiver IC for Wearable Biomedical Applications",
        "link": "https://ieeexplore.ieee.org/document/10723737/"
    },
    {
        "authors": [
            "Matheus Wagner",
            "Mateus Lucena",
            "Josafat Leal Ribeiro",
            "Antônio Augusto Fröhlich"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "24 September 2024",
        "doi": "10.1109/ACCESS.2024.3466832",
        "publisher": "IEEE",
        "abstract": "The seismic surveys conducted by the oil and gas sector result in very large datasets, often exceeding terabytes of data, leading to high costs and technical challenges regarding storage and transmission of such large quantities of data. Therefore, data compression is crucial to address the challenges related to communication and storage demands. This paper investigates a compression strategy based on the combined application of the Discrete Cosine Transform and Principal Component Analysis and its ability to achieve higher compression ratios than the application of each of those methods alone. A theoretical motivation for the increased compression performance is presented, emphasizing that the application of Principal Component Analysis to signals in the transformed domain make the resulting signal more suitable for the posterior Thresholding, Quantization and Entropy Encoding steps. The proposed method was evaluated using a dataset containing passive seismic data collected during an oil and gas reservoir monitoring survey, achieving compression ratios of up to 1000:1 with a normalized reconstruction residue energy of less than 20%, relative to the original signal energy, for the more relevant frequency range between 0 and 20 Hz, outperforming other seismic data compression strategies considered in the literature.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Principal component analysis",
                "Discrete cosine transforms",
                "Transforms",
                "Image coding",
                "Quantization (signal)",
                "Entropy",
                "Data compression",
                "Seismic measurements"
            ],
            "Author Keywords": [
                "Data Compression",
                "Discrete Cosine Transform",
                "Passive Seismic Data",
                "Permanent Reservoir Monitoring",
                "Principal Component Analysis",
                "Seismic Data Compression"
            ]
        },
        "Field": "data",
        "title": "Combining PCA and DCT for Improved Passive Seismic Data Compression",
        "link": "https://ieeexplore.ieee.org/document/10689524/"
    },
    {
        "authors": [
            "Marvin Fuchs",
            "Hendrik Krause",
            "Timo Muscheid",
            "Lukas Scheller",
            "Luis E. Ardila-Perez",
            "Oliver Sander"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Nuclear Science ( Early Access )",
        "date_of_publication": "19 August 2024",
        "doi": "10.1109/TNS.2024.3446309",
        "publisher": "IEEE",
        "abstract": "The almost unlimited possibilities to customize the logic in an FPGA are one of the main reasons for the versatility of these devices. Partial reconfiguration exploits this capability even further by allowing to replace logic in predefined FPGA regions at runtime. This is especially relevant in heterogeneous SoCs, combining FPGA fabric with conventional processors on a single die. Tight integration and supporting frameworks like the FPGA subsystem in Linux facilitate use, for example, to dynamically load custom hardware accelerators. Although this example is one of the most common use cases for partial reconfiguration, the possible applications go far beyond. We propose to use partial reconfiguration in combination with the AXI C2C cross-chip bus to extend the resources of heterogeneous MPSoC and RFSoC devices by connecting peripheral FPGAs. With AXI C2C it is easily possible to link the programmable logic of the individual devices, but partial reconfiguration on peripheral FPGAs utilising the same channel is not officially supported. By using an AXI ICAP controller in combination with custom Linux drivers, we show that it is possible to enable the PS of the heterogeneous SoC to perform partial reconfiguration on peripheral FPGAs, and thus to seamlessly access and manage the entire multi-device system. As a result, software and FPGA firmware updates can be applied to the entire system at runtime, and peripheral FPGAs can be added and removed during operation.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Field programmable gate arrays",
                "Logic",
                "Data acquisition",
                "Hardware",
                "Data centers",
                "Runtime",
                "Qubit"
            ],
            "Author Keywords": [
                "Partial Reconfiguration",
                "Dynamic Function Exchange",
                "DFX",
                "AXI",
                "MPSoC",
                "System-on-Chip",
                "Zynq UltraScale+"
            ]
        },
        "Field": "data",
        "title": "Cross-Chip Partial Reconfiguration for the Initialisation of Modular and Scalable Heterogeneous Systems",
        "link": "https://ieeexplore.ieee.org/document/10639523/"
    },
    {
        "authors": [
            "Chunjing Xiao",
            "Shikang Pang",
            "Xovee Xu",
            "Xuan Li",
            "Goce Trajcevski",
            "Fan Zhou"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Computational Social Systems ( Early Access )",
        "date_of_publication": "19 June 2024",
        "doi": "10.1109/TCSS.2024.3403503",
        "publisher": "IEEE",
        "abstract": "A critical aspect of graph neural networks (GNNs) is to enhance the node representations by aggregating node neighborhood information. However, when detecting anomalies, the representations of abnormal nodes are prone to be averaged by normal neighbors, making the learned anomaly representations less distinguishable. To tackle this issue, we propose an unsupervised counterfactual data augmentation method for graph anomaly detection (CAGAD) that introduces a graph pointer neural network as the heterophilic node detector to identify potential anomalies whose neighborhoods are normal-node-dominant. For each identified potential anomaly, we design a graph-specific diffusion model to translate a part of its neighbors, which are probably normal, into anomalous ones. At last, we involve these translated neighbors in GNN neighborhood aggregation to produce counterfactual representations of anomalies. Through aggregating the translated anomalous neighbors, counterfactual representations become more distinguishable and further advocate detection performance. The experimental results on four datasets demonstrate that CAGAD significantly outperforms strong baselines, with an average improvement of 2.35% on F1, 2.53% on AUC-ROC, and 2.79% on AUC-PR.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Anomaly detection",
                "Vectors",
                "Graph neural networks",
                "Noise reduction",
                "Data augmentation",
                "Generators",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Counterfactual data augmentation",
                "graph anomaly detection",
                "graph neural network (GNN)",
                "representation learning"
            ]
        },
        "Field": "data",
        "title": "Counterfactual Data Augmentation With Denoising Diffusion for Graph Anomaly Detection",
        "link": "https://ieeexplore.ieee.org/document/10564850/"
    },
    {
        "authors": [
            "Jun Tang",
            "Bing Guo",
            "Yan Shen",
            "Sahil Garg",
            "Georges Kaddoum",
            "M. Shamim Hossain"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Network and Service Management ( Early Access )",
        "date_of_publication": "17 October 2024",
        "doi": "10.1109/TNSM.2024.3483013",
        "publisher": "IEEE",
        "abstract": "Low rank tensor ring based data recovery algorithms have been widely used in data-driven consumer electronics to recover missing data entries in the collecting data pre-processing stage for providing stable and reliable service. However, traditional recovery methods often fail to utilize the abundant prior knowledge of data and the non-local self-similarity of the data, thus leading to the failure to effectively capture the spatial relationships within high-dimensional data to recover them accurately. To address these problems, we present a novel Non-local Self-similarity and Low-rank Prior Knowledge based tensor ring completion method. Firstly, we incorporate the BM3D denoising operator within a Plug-and-Play framework to exploit the self-similarity in the data. Then a logarithmic determinant function is integrated to distinguish singular values in the cyclic unfolding matrix of the tensor and adopts a tensor ring completion approach based on weighted nuclear norms. Finally, in order to evaluate the effectiveness of our proposed method, we conducted a series of experiments by using the missing image dataset and the missing traffic data dataset respectively, and the experimental results show that our method achieves the highest level in terms of data recovery accuracy.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Tensors",
                "Accuracy",
                "Matrix decomposition",
                "Noise reduction",
                "Consumer electronics",
                "Deep learning",
                "Computational modeling",
                "Proposals",
                "Data mining",
                "Training"
            ],
            "Author Keywords": [
                "Tensor Ring Completion",
                "Internet of Things",
                "Data Recovery",
                "Low-rank Prior Knowledge"
            ]
        },
        "Field": "data",
        "title": "A Data Completion Algorithm Based on Low-Rank Prior Knowledge for Data-Driven Applications",
        "link": "https://ieeexplore.ieee.org/document/10720861/"
    },
    {
        "authors": [
            "Yan Wang",
            "Lianbing Deng"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "04 November 2024",
        "doi": "10.1109/ACCESS.2024.3491167",
        "publisher": "IEEE",
        "abstract": "Infrared imaging emerges as a promising technique for vision tasks within environments characterized by lowor obscured visibility. However, the scarcity of infrared datasets, particularly those comprising paired infrared-visible images, addresses significant challenges for the training of high-performance deep learning models. This paper investigates the application of generative adversarial networks (GANs) for data augmentation in infrared imaging. Our work encompasses a range of GAN models including Pix2Pix, CycleGAN, StyleGAN3, and the proposed Cycle-aided model, which incorporates vision-aided loss to enhance both model training and stability. The results demonstrate that CycleGAN encounters stability issues and is prone to mode collapse, leading to less satisfactory performance. By contrast, the Cycle-aided model that leverages pre-trained models to substantially improve both the discriminative and generative capabilities of GANs, evidenced by a 51% increase in peak signal-to-noise ratio (PSNR), a 43% increase in structural similarity index (SSIM) and an 18% decrease in the Fréchet inception distance (FID) over CycleGAN. These improvements underscore the potential of GANs to improve data augmentation practices for infrared imaging in low-visibility environments. The insights gained also pave the way for future research aimed at developing architectures and training strategies of GANS for fully exploiting the unique properties of data augmentation.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Data augmentation",
                "Data models",
                "Vectors",
                "Generators",
                "Feature extraction",
                "Training data",
                "PSNR",
                "Infrared imaging",
                "Generative adversarial networks"
            ],
            "Author Keywords": [
                "Infrared Images",
                "data augmentation",
                "generative adversarial networks"
            ]
        },
        "Field": "data",
        "title": "Enhanced Data Augmentation for Infrared Images with Generative Adversarial Networks Aided by Pretrained Models",
        "link": "https://ieeexplore.ieee.org/document/10742345/"
    },
    {
        "authors": [
            "Yusu Zhao",
            "Pengfei Zhang",
            "Yongkun Wang",
            "Yaohui Jin"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Communications Letters ( Early Access )",
        "date_of_publication": "04 May 2017",
        "doi": "10.1109/LCOMM.2017.2701369",
        "publisher": "IEEE",
        "abstract": "Network issues on data plane manifest themselves as failed rules, which can be verified by the comparison between actual and desired network behavior. Previous efforts implement this leveraging end-to-end active probing, which falls short on timely locating the exact failure points and identifying responsible rules. With the help of the out-band channel in softwaredefined network (SDN), per hop active probing can be employed to perform per device or even per rule network behavior comparison. Therefore, we present SERVE, an SDN-enabled rule verification framework that automatically identifies data plane network issues with periodic per rule network behavior comparison. By modeling network devices as multi-rooted trees with respect to pipeline processing, probes can be generated from a per device perspective in a timely manner. We evaluate the performance of SERVE and validate its effectiveness and timeliness on a small deployment with typical use cases.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Probes",
                "Performance evaluation",
                "Pipeline processing",
                "Data models",
                "Computational modeling",
                "Ports (Computers)",
                "Indexes"
            ],
            "Author Keywords": [
                "data plane network issues",
                "rule verification",
                "software-defined network",
                "multi-rooted tree model"
            ]
        },
        "Field": "data",
        "title": "SDN-enabled Rule Verification on Data Plane",
        "link": "https://ieeexplore.ieee.org/document/7919199/"
    },
    {
        "authors": [
            "Lei Zhang",
            "Yuandi Zhang",
            "Jiawangnan Lu",
            "Yunfa Xiao",
            "Guanglin Zhang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Wireless Communications Letters ( Early Access )",
        "date_of_publication": "23 September 2024",
        "doi": "10.1109/LWC.2024.3465509",
        "publisher": "IEEE",
        "abstract": "In this letter, we design a customized channel model based on ray tracing (RT) and machine learning (ML). RT is used to generate path loss for selected areas. The generated path loss is trained through the Deep Neural Network (DNN). The channel model can output the path loss by inputting the transceiver’s three-dimensional (3D) coordinates. We investigated the task of collecting data by unmanned aerial vehicle (UAV) based on the customized channel model. The time it takes for the UAV to finish collecting data generated by ground user equipment (UE) is minimized. We combine non-orthogonal multiple access (NOMA) to analyze UAVs’ optimal 3D and 2D flight trajectories and demonstrate that 3D outperforms 2D. The optimized proximal policy optimization (optimized PPO) based deep reinforcement learning (DRL) algorithm is proposed to address this issue. The UAV can adjust its speed and direction. Simulation results demonstrate the effectiveness of the proposed customized channel model and algorithm.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Autonomous aerial vehicles",
                "Channel models",
                "Loss measurement",
                "NOMA",
                "Data collection",
                "Trajectory",
                "Three-dimensional displays"
            ],
            "Author Keywords": [
                "Customized channel model",
                "data collection",
                "NOMA",
                "optimized PPO",
                "UAV communication"
            ]
        },
        "Field": "data",
        "title": "Deep Reinforcement Learning based Trajectory Design for Customized UAV-Aided NOMA Data Collection",
        "link": "https://ieeexplore.ieee.org/document/10685463/"
    },
    {
        "authors": [
            "Jieting Wang",
            "Feijiang Li",
            "Jue Li",
            "Chenping Hou",
            "Yuhua Qian",
            "Jiye Liang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )",
        "date_of_publication": "22 May 2023",
        "doi": "10.1109/TNNLS.2023.3270559",
        "publisher": "IEEE",
        "abstract": "The bagging method has received much application and attention in recent years due to its good performance and simple framework. It has facilitated the advanced random forest method and accuracy-diversity ensemble theory. Bagging is an ensemble method based on simple random sampling (SRS) method with replacement. However, SRS is the most foundation sampling method in the field of statistics, where exists some other advanced sampling methods for probability density estimation. In imbalanced ensemble learning, down-sampling, over-sampling, and SMOTE methods have been proposed for generating base training set. However, these methods aim at changing the underlying distribution of data rather than simulating it better. The ranked set sampling (RSS) method uses auxiliary information to get more effective samples. The purpose of this article is to propose a bagging ensemble method based on RSS, which uses the ordering of objects related to the class to obtain more effective training sets. To explain its performance, we give a generalization bound of ensemble from the perspective of posterior probability estimation and Fisher information. On the basis of RSS sample having a higher Fisher information than SRS sample, the presented bound theoretically explains the better performance of RSS-Bagging. The experiments on 12 benchmark datasets demonstrate that RSS-Bagging statistically performs better than SRS-Bagging when the base classifiers are multinomial logistic regression (MLR) and support vector machine (SVM).",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Bagging",
                "Ensemble learning",
                "Training",
                "Sampling methods",
                "Training data",
                "Entropy",
                "Boosting"
            ],
            "Author Keywords": [
                "Bagging",
                "fisher information",
                "generalization bound",
                "posterior probability estimation",
                "ranked set sampling"
            ]
        },
        "Field": "data",
        "title": "RSS-Bagging: Improving Generalization Through the Fisher Information of Training Data",
        "link": "https://ieeexplore.ieee.org/document/10130442/"
    },
    {
        "authors": [
            "Yuriya Nakamura",
            "Lei Jing"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "15 October 2024",
        "doi": "10.1109/ACCESS.2024.3481254",
        "publisher": "IEEE",
        "abstract": "In recent years, visual-based sign language recognition (SLR) has become an active research area with the advancement of deep learning. However, it is difficult to collect sign language data, and many datasets suffer from data lack and imbalance, leading to overfitting and reduced accuracy in machine learning. In general, data augmentation is used as a solution to the problems but model training and data augmentation are performed independently, and it is difficult to adjust the parameters for data augmentation. Therefore, we focus on visual-based SLR using skeletal data and propose an adversarial learning SLR model called Adversarial Vulnerability-Seeking Networks (AVSN), which jointly trains two independent processes, data augmentation, and machine learning. The AVSN is particularly applicable in scenarios where diverse and extensive sign language datasets are not available. For example, when developing SLR systems for lesser-known sign languages or specialized vocabularies used in specific professional contexts, AVSN can improve model performance by generating high-quality, diverse training data. The generator produces hard adversarial data intended to mislead the machine learning model, which acts as a discriminator. On the other hand, the discriminator learns from both raw and adversarial data. In other words, the generator exposes the vulnerabilities of the discriminator, and the discriminator improves its performance by learning from both types of data.We evaluated the proposed method from two aspects, the performance of the model trained by data augmentation and the quality of the data generated by data augmentation. First, we evaluated the performance of the model trained using data augmentation using common evaluation metrics such as accuracy and F-score. The proposed method achieved an improvement of 0.58% in accuracy and 0.017 in F-score compared to the model without data augmentation. Next, we quantitatively evaluated the quality of the augmented data b...",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Data augmentation",
                "Sign language",
                "Data models",
                "Adversarial machine learning",
                "Pose estimation",
                "Accuracy",
                "Training",
                "Generators",
                "Computational modeling",
                "Heating systems"
            ],
            "Author Keywords": [
                "Japanese sign language",
                "sign language recognition",
                "skeletal data",
                "adversarial learning"
            ]
        },
        "Field": "data",
        "title": "Skeleton-Based Data Augmentation for Sign Language Recognition Using Adversarial Learning",
        "link": "https://ieeexplore.ieee.org/document/10718297/"
    },
    {
        "authors": [
            "Yifei Li",
            "Wenjie Liu",
            "Gang Wang",
            "Jian Sun",
            "Lihua Xie",
            "Jie Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Automatic Control ( Early Access )",
        "date_of_publication": "10 June 2024",
        "doi": "10.1109/TAC.2024.3411832",
        "publisher": "IEEE",
        "abstract": "This paper proposes a novel approach to address the output synchronization problem for unknown heterogeneous multi-agent systems (MASs) using noisy data. Unlike existing studies that focus on noiseless data, we introduce a distributed data-driven controller that enables all heterogeneous followers to synchronize with a leader's output trajectory. To handle the noise in the state-input-output data, we develop a data-based polytopic representation for the MAS. We tackle the issue of infeasibility in the set of output regulator equations caused by the noise by seeking approximate solutions via constrained fitting error minimization. This method utilizes measured data and a noise-matrix polytope to ensure near-optimal output synchronization, in the sense of ultimately uniformly boundedness stability. Stability conditions in the form of data-dependent semidefinite programs are derived, providing stabilizing controller gains for each follower. The proposed distributed data-driven control protocol achieves near-optimal output synchronization by ensuring the convergence of the tracking error to a bounded polytope, with the polytope size positively correlated with the noise bound. Numerical tests validate the practical merits of the proposed data-driven design and theory.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Synchronization",
                "Noise",
                "Noise measurement",
                "Mathematical models",
                "Regulators",
                "Protocols",
                "Symmetric matrices"
            ],
            "Author Keywords": [
                "Data-driven control",
                "heterogeneous MAS",
                "noisy data",
                "output synchronization",
                "polytope"
            ]
        },
        "Field": "data",
        "title": "Data-driven Polytopic Output Synchronization from Noisy Data",
        "link": "https://ieeexplore.ieee.org/document/10552333/"
    },
    {
        "authors": [
            "Qiong Zhang",
            "Taochun Wang",
            "Yuan Tao",
            "Fulong Chen",
            "Dong Xie",
            "Chuanxin Zhao"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Services Computing ( Early Access )",
        "date_of_publication": "05 September 2024",
        "doi": "10.1109/TSC.2024.3455104",
        "publisher": "IEEE",
        "abstract": "With the widespread popularity of smartphones, watches, and other devices, mobile crowd sensing has garnered significant public attention. Application service providers publish crowd sensing tasks, and users actively participate in collecting relevant sensing data, which are then submitted to servers. However, these data contain users' personal privacy. Therefore, this paper proposes a trajectory privacy protection method based on differential privacy(CTDP). First, the paper conducts clustering based on the features of user trajectory data to extract feature regions of the user trajectory. Then, a personalized privacy budget allocation method is developed based on the number of trajectory points in the feature region and the user's privacy requirements for sensitive trajectory points. A set of confusion points is generated within the feature range and a score is calculated based on its similarity to the trajectory points. Subsequently, the sampling probability is calculated based on the score and privacy budget of each confusion point, and finally the confusion points are selected through random sampling. The internationally recognized real dataset Cabspotting data was used for experimental evaluation. The experimental results indicate that the method proposed in this paper exhibits excellent performance in terms of data availability while providing sufficient privacy guarantees.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Trajectory",
                "Privacy",
                "Protection",
                "Differential privacy",
                "Sensors",
                "Noise",
                "Laplace equations"
            ],
            "Author Keywords": [
                "Clustering",
                "crowd sensing",
                "differential privacy",
                "trajectory privacy"
            ]
        },
        "Field": "data",
        "title": "Trajectory Privacy Protection Method Based on Differential Privacy in Crowdsensing",
        "link": "https://ieeexplore.ieee.org/document/10666272/"
    },
    {
        "authors": [
            "Xusheng Wang",
            "Shoubin Dong",
            "Xiaorou Zheng",
            "Runuo Lu",
            "Jianxin Jia"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Geoscience and Remote Sensing ( Early Access )",
        "date_of_publication": "11 November 2024",
        "doi": "10.1109/TGRS.2024.3495765",
        "publisher": "IEEE",
        "abstract": "When applied across different scenes, hyperspectral image (HSI) classification models often struggle to generalize due to the data distribution disparities and labels’ scarcity, leading to domain shift (DS) problems. Recently, the high-level semantics from text has demonstrated the potential to address the DS problem, by improving the generalization capability of image encoders through aligning image-text pairs. However, the main challenge still lies in crafting appropriate texts that accurately represent the intricate interrelationships and the fragmented nature of land cover in HSI and effectively extracting spectral-spatial features from HSI data. This paper proposes a domain generalization method, EHSnet, to address these issues by leveraging multi-layered explicit high-level semantic (EHS) information from different types of texts to provide precisely relevant semantic information for the image encoder. A multi-layered EHS information paradigm is well-defined, aiming to extract the HSI’s intricate interrelationships and the fragmented land cover features, and a dual-residual encoder connected by a two-dimensional convolution is designed, which combines CNNs with residual structure and ViTs with short-range cross-layer connections to explore the spectral-spatial features of HSI. By aligning text features with image features in the semantic space, EHSnet improves the representation capability of the image encoder and is endowed with zero-shot generalization ability for cross-scene tasks. Extensive experiments conducted on three hyperspectral datasets, including Houston, Pavia, and XS datasets, validate the effectiveness and superiority of EHSnet, with the Kappa coefficient improved by 8.17%, 3.22%, and 3.62% across three datasets compared to the state-of-the-art methods. The code is available at https://github.com/SCUT-CCNL/EHSnet.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Feature extraction",
                "Land surface",
                "Data models",
                "Training",
                "Hyperspectral imaging",
                "Data mining",
                "Visualization",
                "Representation learning",
                "Contrastive learning"
            ],
            "Author Keywords": [
                "Hyperspectral image classification",
                "domain generalization",
                "multiple-modality",
                "visual-language model"
            ]
        },
        "Field": "data",
        "title": "Explicit High-level Semantic Network for Domain Generalization in Hyperspectral Image Classification",
        "link": "https://ieeexplore.ieee.org/document/10750220/"
    },
    {
        "authors": [
            "Zhiguang Zhou",
            "Haoxuan Wang",
            "Zhengqing Zhao",
            "Fengling Zheng",
            "Yongheng Wang",
            "Wei Chen",
            "Yong Wang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "09 October 2024",
        "doi": "10.1109/TVCG.2024.3476508",
        "publisher": "IEEE",
        "abstract": "Chart images, such as bar charts, pie charts, and line charts, are explosively produced due to the wide usage of data visualizations. Accordingly, knowledge mining from chart images is becoming increasingly important, which can benefit downstream tasks like chart retrieval and knowledge graph completion. However, existing methods for chart knowledge mining mainly focus on converting chart images into raw data and often ignore their visual encodings and semantic meanings, which can result in information loss for many downstream tasks. In this paper, we propose ChartKG , a novel knowledge graph (KG) based representation for chart images, which can model the visual elements in a chart image and semantic relations among them including visual encodings and visual insights in a unified manner.Further, we develop a general framework to convert chart images to the proposed KG-based representation. It integrates a series of image processing techniques to identify visual elements and relations, e.g., CNNs to classify charts, yolov5 and optical character recognition to parse charts, and rule-based methods to construct graphs. We present four cases to illustrate how our knowledge-graph-based representation can model the detailed visual elements and semantic relations in charts, and further demonstrate how our approach can benefit downstream applications such as semantic-aware chart retrieval and chart question answering. We also conduct quantitative evaluations to assess the two fundamental building blocks of our chart-to-KG framework, i.e., object recognition and optical character recognition. The results provide support for the usefulness and effectiveness of ChartKG .",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Visualization",
                "Data mining",
                "Knowledge graphs",
                "Semantics",
                "Data visualization",
                "Bars",
                "Question answering (information retrieval)",
                "Image coding",
                "Optical character recognition",
                "Optical imaging"
            ],
            "Author Keywords": [
                "Chart image",
                "knowledge graph",
                "semantic representation",
                "chart mining"
            ]
        },
        "Field": "data",
        "title": "ChartKG: A Knowledge-Graph-Based Representation for Chart Images",
        "link": "https://ieeexplore.ieee.org/document/10711251/"
    },
    {
        "authors": [
            "Leixian Shen",
            "Haotian Li",
            "Yun Wang",
            "Tianqi Luo",
            "Yuyu Luo",
            "Huamin Qu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "16 October 2024",
        "doi": "10.1109/TVCG.2024.3477926",
        "publisher": "IEEE",
        "abstract": "Creating data videos that effectively narrate stories with animated visuals requires substantial effort and expertise. A promising research trend is leveraging the easy-to-use natural language (NL) interaction to automatically synthesize data video components from narrative content like text narrations, or NL commands that specify user-required designs. Nevertheless, previous research has overlooked the integration of narrative content and specific design authoring commands, leading to generated results that lack customization or fail to seamlessly fit into the narrative context. To address these issues, we introduce a novel paradigm for creating data videos, which seamlessly integrates users' authoring and narrative intents in a unified format called annotated narration, allowing users to incorporate NL commands for design authoring as inline annotations within the narration text. Informed by a formative study on users' preference for annotated narration, we develop a prototype system named Data Playwright that embodies this paradigm for effective creation of data videos. Within Data Playwright, users can write annotated narration based on uploaded visualizations. The system's interpreter automatically understands users' inputs and synthesizes data videos with narration-animation interplay, powered by large language models. Finally, users can preview and fine-tune the video. A user study demonstrated that participants can effectively create data videos with Data Playwright by effortlessly articulating their desired outcomes through annotated narration.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Videos",
                "Visualization",
                "Animation",
                "Data visualization",
                "Annotations",
                "Manuals",
                "Prototypes",
                "Syntactics",
                "Large language models",
                "Digital audio broadcasting"
            ],
            "Author Keywords": [
                "Annotated narration",
                "data video",
                "intent",
                "large language model",
                "natural language"
            ]
        },
        "Field": "data",
        "title": "Data Playwright: Authoring Data Videos With Annotated Narration",
        "link": "https://ieeexplore.ieee.org/document/10720675/"
    },
    {
        "authors": [
            "Bing Cheng",
            "Liangzong He",
            "Houxuan Liu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Transportation Electrification ( Early Access )",
        "date_of_publication": "04 July 2024",
        "doi": "10.1109/TTE.2024.3422993",
        "publisher": "IEEE",
        "abstract": "Wireless power transfer (WPT) systems advantaging environment-friendly and highly efficient, and accurate parameter estimation is a premise for precise control and a guarantee for system safety. However, the conventional parameter estimation method, which is based on the primary impedance angle is easily affected by the components delay, current distortion and other issues during the detection process. Meanwhile, conventional data-driven parameter estimation requires a large number of data and dual-side commutation, resulting in higher execution costs. To address those issues, an online/offline hybrid data-driven parameters estimation method utilizing the backpropagation neural network (BPNN) is proposed for the communication-less WPT system. The primary DC input voltage and current are taken as the input variables of the BPNN model to reduce the noise of training data. Further, to overcome the difficulty of a large account of training data collection, an approximate BPNN model is built firstly by the offline training under a small sampling set. Then, online data-driven parameter estimation by monitoring the primary resonant current is implemented to optimize the built BPNN model constantly, resulting in enhancing estimation accuracy and avoiding complex wireless communication. Finally, an experimental setup is constructed to verify the feasibility of the proposed data-driven estimation method.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Parameter estimation",
                "Accuracy",
                "Impedance",
                "Estimation",
                "Mathematical models",
                "Inductance",
                "Training data"
            ],
            "Author Keywords": [
                "Wireless power transfer",
                "primary information",
                "parameters estimation",
                "backpropagation neural network",
                "data-driven algorithm"
            ]
        },
        "Field": "data",
        "title": "Hybrid Data-Driven Parameters Estimation for Communication-less WPT System with Reduced Primary Sampling Data",
        "link": "https://ieeexplore.ieee.org/document/10584555/"
    },
    {
        "authors": [
            "Zhiwei Zhao",
            "Yingguang Li",
            "Changqing Liu",
            "Xu Liu",
            "James Gao"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Industrial Informatics ( Early Access )",
        "date_of_publication": "30 September 2024",
        "doi": "10.1109/TII.2024.3453431",
        "publisher": "IEEE",
        "abstract": "In digital manufacturing, data-driven methods are promising to revolutionize various decision-making processes. However, the relationships between variables in high-dimensional data of data-driven decision-making methods are only correlations. Important causal relationships and knowledge between process variables are not considered. Therefore, existing data-driven systems are unstable, which could result in unreliable and dangerous decisions. To establish a stable decision-making model for complex processes with high-dimensional data, a causal-based decision-making framework that combined causal relationships and knowledge between key manufacturing variables was proposed. The causal relationships between state, decision, and objective data were established in the form of a direct acyclic graph formed by breaking an unexcepted loop between variables using a shadow objective variable. Then, causal knowledge of high-dimensional states was introduced to the neural network, forming a stable decision-making model. Compared with data-driven methods used in robotics and manufacturing scenarios, the proposed framework provided better and more stable decisions, particularly in noised environments.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Decision making",
                "Manufacturing",
                "Robots",
                "Correlation",
                "Mathematical models",
                "Supervised learning",
                "Robot sensing systems",
                "Noise measurement",
                "Informatics",
                "Data mining"
            ],
            "Author Keywords": [
                "Causal loop",
                "causal relationship",
                "data-driven",
                "manufacturing decision-making"
            ]
        },
        "Field": "data",
        "title": "Stable Data-Driven Manufacturing Decision-Making by Introducing Causal Relationships for High-Dimensional Data",
        "link": "https://ieeexplore.ieee.org/document/10699427/"
    },
    {
        "authors": [
            "Carter Blair",
            "Xiyao Wang",
            "Charles Perin"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "10 September 2024",
        "doi": "10.1109/TVCG.2024.3456361",
        "publisher": "IEEE",
        "abstract": "Emotion is an important factor to consider when designing visualizations as it can impact the amount of trust viewers place in a visualization, how well they can retrieve information and understand the underlying data, and how much they engage with or connect to a visualization. We conducted five crowdsourced experiments to quantify the effects of color, chart type, data trend, data variability and data density on emotion (measured through self-reported arousal and valence). Results from our experiments show that there are multiple design elements which influence the emotion induced by a visualization and, more surprisingly, that certain data characteristics influence the emotion of viewers even when the data has no meaning. In light of these findings, we offer guidelines on how to use color, scale, and chart type to counterbalance and emphasize the emotional impact of immutable data characteristics.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Image color analysis",
                "Market research",
                "Physiology",
                "Particle measurements",
                "Atmospheric measurements",
                "Shape"
            ],
            "Author Keywords": [
                "Affect",
                "Data Visualization",
                "Emotion",
                "Quantitative Study"
            ]
        },
        "Field": "data",
        "title": "Quantifying Emotional Responses to Immutable Data Characteristics and Designer Choices in Data Visualizations",
        "link": "https://ieeexplore.ieee.org/document/10673804/"
    },
    {
        "authors": [
            "Atul Jaysing Patil",
            "Ram Naresh",
            "Raj Kumar Jarial",
            "Hasmat Malik"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Dielectrics and Electrical Insulation ( Early Access )",
        "date_of_publication": "02 July 2024",
        "doi": "10.1109/TDEI.2024.3421915",
        "publisher": "IEEE",
        "abstract": "Ensuring transformer health and accurate fault diagnosis is crucial for the reliable operation of power systems. Development of data-driven techniques for fault interpretation in mineral oil filled transformers becomes challenging due to limited availability of real-world data. The research investigates on development of a novel optimized synthetic data dataset for three different ML models—K-Nearest Neighbors (KNN), Support Vector Machine (SVM), and Random Forest (RF) that maximizes the accuracy of these data driven algorithms without training with excessive data instances resulting in overfitting on the training dataset. Utilizing a dataset from 1135 diverse transformers for ML model training, the study introduces a novel two-step iterative and optimized methodology for generating a synthetic database. The integration of real and synthetic data enhances the overall efficacy of incipient fault identification using ML algorithms. To ensure robust evaluation and comparison of performance, the IEC TC 10 dataset is employed. With optimized dataset, the accuracy of the KNN model increased from 79.33 % to 90.26 % when the prior was trained only with real-world data. The verification of the generated synthetic data from the proposed method, compared to existing methods, demonstrated its superiority in dataset quality.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Fault diagnosis",
                "Power transformer insulation",
                "Training",
                "Accuracy",
                "Testing",
                "Oil insulation",
                "Data models"
            ],
            "Author Keywords": [
                "Machine Learning",
                "Synthetic Data Generation",
                "Transformer Fault Diagnosis",
                "DGA",
                "etc"
            ]
        },
        "Field": "data",
        "title": "Optimized Synthetic Data Integration with Transformer’s DGA Data for Improved ML-based Fault Identification",
        "link": "https://ieeexplore.ieee.org/document/10580982/"
    },
    {
        "authors": [
            "Elsie Lee-Robbins",
            "Arran Ridley",
            "Eytan Adar"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "02 October 2024",
        "doi": "10.1109/TVCG.2024.3467189",
        "publisher": "IEEE",
        "abstract": "Data visualization designers and clients need to communicate effectively with each other to achieve a successful project. Unlike a personal or solo project, working with a client introduces a layer of complexity to the process. Client and designer might have different ideas about what is an acceptable solution that would satisfy the goals and constraints of the project. Thus, the client-designer relationship is an important part of the design process. To better understand the relationship, we conducted an interview study with 12 data visualization designers. We develop a model of a client-designer project space consisting of three aspects: surfacing project goals , agreeing on resource allocation , and creating a successful design . For each aspect, designer and client have their own mental model of how they envision the project. Disagreements between these models can be resolved by negotiation that brings them closer to alignment. We identified three main negotiation strategies to navigate the project space: 1) expanding the project space to consider more potential options, 2) constraining the project space to narrow in on the boundaries, and 3) shifting the project space to different options. We discuss client-designer collaboration as a negotiated relationship, with opportunities and challenges for each side. We suggest ways to mitigate challenges to avoid friction from developing into conflict.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Stakeholders",
                "Resource management",
                "Data models",
                "Cognitive science",
                "Interviews",
                "Requirements engineering",
                "Encoding",
                "Data privacy",
                "Costs"
            ],
            "Author Keywords": [
                "Data visualization",
                "Design methodology",
                "Client"
            ]
        },
        "Field": "data",
        "title": "Client-Designer Negotiation in Data Visualization Projects",
        "link": "https://ieeexplore.ieee.org/document/10704568/"
    },
    {
        "authors": [
            "Qian Xiao",
            "Tianxiang Li",
            "Hongjie Jia",
            "Yunfei Mu",
            "Yu Jin",
            "Ji Qiao",
            "Tianjiao Pu",
            "Frede Blaabjerg",
            "Josep M. Guerrero"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Smart Grid ( Early Access )",
        "date_of_publication": "11 October 2024",
        "doi": "10.1109/TSG.2024.3478844",
        "publisher": "IEEE",
        "abstract": "This letter has developed an electrical circuit analogy-based maximum latency calculation (MLC) method of the internet data center (IDC) in power-communication network. Firstly, by analogy with the circuit model, the basic concepts to describe information flow are defined, including information current, information resistance, information conductivity, and information voltage. Based on these concepts, the information processing model considering both channel blocking and user priority is established. By analogy with the electrical circuit, the information flow calculation laws are introduced to calculate the maximum latency of IDCs. Verification results show that the maximum latency of IDCs in power-communication network can be accurately calculated by the proposed MLC method.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Resistance",
                "Information processing",
                "Communication networks",
                "Voltage",
                "Power systems",
                "Data centers",
                "Conductivity",
                "Smart grids",
                "Simulation",
                "Planning"
            ],
            "Author Keywords": [
                "Internet data centers",
                "electrical circuit analogy-based model",
                "maximum latency",
                "power-communication network"
            ]
        },
        "Field": "data",
        "title": "Electrical Circuit Analogy-Based Maximum Latency Calculation Method of Internet Data Centers in Power-Communication Network",
        "link": "https://ieeexplore.ieee.org/document/10714408/"
    },
    {
        "authors": [
            "Lingfeng Shen",
            "Huanran Zhang",
            "Ying Cui",
            "Xiaomin Mu",
            "Xiang Cheng",
            "Ning Wang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Sensors Letters ( Early Access )",
        "date_of_publication": "28 October 2024",
        "doi": "10.1109/LSENS.2024.3487009",
        "publisher": "IEEE",
        "abstract": "The design of timely data collection for a machine-type communication (MTC) network by unmanned-aerial-vehicle (UAV) platform is investigated. The ground-based MTC devices (MTCDs) are clustered for efficient service, and the UAV station's deployment in the three-dimensional (3-D) space is optimized. The corresponding mission time minimization problem is formulated as a coupled mixed-integer non-linear program (MINLP). For tractability, the original problem is decomposed into two subproblems respectively dealing with clustering-hovering optimization and inter-cluster UAV traveling path minimization. An alternating clustering-hovering optimization (ACH) and ant colony optimization (ACO) solution approach is proposed accordingly. Simulations are conducted to validate the superiority of the proposed ACH-ACO scheme over the scheme based on\nk\n-means clustering.",
        "issn": {
            "Electronic ISSN": "2475-1472"
        },
        "keywords": {
            "IEEE Keywords": [
                "Autonomous aerial vehicles",
                "Data collection",
                "Optimization",
                "Trajectory",
                "Sensors",
                "Nonlinear optics",
                "Minimization",
                "Line-of-sight propagation",
                "Internet of Things",
                "Indexes"
            ],
            "Author Keywords": [
                "UAV-assisted data collection",
                "clustering",
                "mission time minimization",
                "UAV 3-D deployment"
            ]
        },
        "Field": "data",
        "title": "Joint Clustering and 3-D UAV Deployment for Delay-Aware UAV-Enabled MTC Data Collection Networks",
        "link": "https://ieeexplore.ieee.org/document/10736673/"
    },
    {
        "authors": [
            "Yupei Zhang",
            "Yifei Wang",
            "Yuxin Li",
            "Yunan Xu",
            "Shuangshuang Wei",
            "Shuhui Liu",
            "Xuequn Shang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )",
        "date_of_publication": "06 December 2023",
        "doi": "10.1109/TNNLS.2023.3336957",
        "publisher": "IEEE",
        "abstract": "Acquiring big-size datasets to raise the performance of deep models has become one of the most critical problems in representation learning (RL) techniques, which is the core potential of the emerging paradigm of federated learning (FL). However, most current FL models concentrate on seeking an identical model for isolated clients and thus fail to make full use of the data specificity between clients. To enhance the classification performance of each client, this study introduces the FDRL, a federated discriminative RL model, by partitioning the data features of each client into a global subspace and a local subspace. More specifically, FDRL learns the global representation for federated communication between those isolated clients, which is to capture common features from all protected datasets via model sharing, and local representations for personalization in each client, which is to preserve specific features of clients via model differentiating. Toward this goal, FDRL in each client trains a shared submodel for federated communication and, meanwhile, a not-shared submodel for locality preservation, in which the two models partition client-feature space by maximizing their differences, followed by a linear model fed with combined features for image classification. The proposed model is implemented with neural networks and optimized in an iterative manner between the server of computing the global model and the clients of learning the local classifiers. Thanks to the powerful capability of local feature preservation, FDRL leads to more discriminative data representations than the compared FL models. Experimental results on public datasets demonstrate that our FDRL benefits from the subspace partition and achieves better performance on federated image classification than the state-of-the-art FL models.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Feature extraction",
                "Representation learning",
                "Image classification",
                "Task analysis",
                "Servers",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Dataset privacy",
                "deep representation learning (RL)",
                "federated learning (FL)",
                "image classification",
                "neural networks"
            ]
        },
        "Field": "data",
        "title": "Federated Discriminative Representation Learning for Image Classification",
        "link": "https://ieeexplore.ieee.org/document/10345648/"
    },
    {
        "authors": [
            "Ce Sun",
            "Liping Zhang",
            "Jinqi He",
            "Junchai Gao",
            "Jing Li",
            "Zhiyong Lei"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "11 August 2020",
        "doi": "10.1109/ACCESS.2020.3015774",
        "publisher": "IEEE",
        "abstract": "In the process of accuracy measurement of multi-projectile intersection target, aiming at the problem of multi-projectile target matching on two imaging planes of linear CCD(Charge Coupled Device), a Time-Dimension ICP(iterative closest point) iterative optimization data association algorithm is designed, and a data association decision algorithm based on D-S(Dempster-Shafer evidence theory) evidence reasoning is proposed. By analyzing the correlation error of multi-projectile target matching, the measure function of ICP iteration optimization is given. According to the basic principle of D-S evidential reasoning and the constraint relationship between two imaging surfaces of a multi-projectile online array camera, the design method of the basic probability assignment function of the number of data association, the mean value of absolute error and the consistency of error are given. According to D-S combination probability distribution, different data association results are reasoned and decided. By designing the distance error function from the point to the polar line, the method is extended to the area array high-speed photographic intersection measurement system. The simulation results show that the proposed algorithm can make effective judgments and give reliable data association results when the projectile data is missing, the projectile data is noisy and the projectile catches up.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Projectiles",
                "Charge coupled devices",
                "Iterative closest point algorithm",
                "Cameras",
                "Coordinate measuring machines",
                "Pattern matching"
            ],
            "Author Keywords": [
                "D-S evidence theory",
                "data association",
                "multiple projectiles targets",
                "data fusion"
            ]
        },
        "Field": "data",
        "title": "Multi-projectiles Target Data Association Algorithm Based on D-S Evidence Theory",
        "link": "https://ieeexplore.ieee.org/document/9165102/"
    },
    {
        "authors": [
            "Feiyan Wu",
            "Zhunga Liu",
            "Zuowei Zhang",
            "Jiaxiang Liu",
            "Longfei Wang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Circuits and Systems for Video Technology ( Early Access )",
        "date_of_publication": "29 October 2024",
        "doi": "10.1109/TCSVT.2024.3487867",
        "publisher": "IEEE",
        "abstract": "Multi-expert networks have shown great superiority for imbalanced data classification tasks due to their complementary and diverse. We have summarized two aspects for further explorations: (1) uncontrollable results, arising from the performance differences of individual experts and variations in sample difficulty; (2) insufficient exploration of the internal data structure. These factors result in inconsistent model performance across different data distributions, thereby impact the model’s generalization ability. To address the above issues, we propose a Collaborative Global-Local Structure Network (CGL-Net) with knowledge distillation for imbalanced data classification. Firstly, CGL-Net, as a new framework, decouples the representation learning of imbalanced data into global and local structure, enhancing the controllability of integration model in a hierarchical manner. Secondly, CGL-Net innovatively combines knowledge distillation, data augmentation, and multiple expert networks, efficiently extracting the internal structure of the data and improving robust recognition on imbalanced data. In particular, the global structure learning introduces an independent student network that integrates knowledge from diverse experts, enabling the model to achieve comprehensive and balanced performance across categories in imbalanced data. The local structure learning incorporates augmented data, allowing the model to focus on discriminative regional learning of individual objects, thereby enhances the robust representation for imbalanced data. After completing these two sequential learning stages, the model hierarchically integrates knowledge to achieve robust recognition performance on imbalanced data. Extensive experiments on six benchmark datasets demonstrate that the proposed CGL-Net significantly outperforms recent state-of-the-art methods.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Knowledge engineering",
                "Tail",
                "Data augmentation",
                "Representation learning",
                "Training",
                "Reviews",
                "Federated learning",
                "Feature extraction",
                "Circuits and systems"
            ],
            "Author Keywords": [
                "Global structure learning",
                "local structure learning",
                "knowledge distillation",
                "imbalanced data classification"
            ]
        },
        "Field": "data",
        "title": "Collaborative Global-Local Structure Network with Knowledge Distillation for Imbalanced Data Classification",
        "link": "https://ieeexplore.ieee.org/document/10737426/"
    },
    {
        "authors": [
            "Zhehao Cheng",
            "Jiaoyan Chen",
            "Jin Liu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "18 October 2024",
        "doi": "10.1109/JIOT.2024.3483298",
        "publisher": "IEEE",
        "abstract": "The Mobile Crowdsensing strategy emerges as a novel and trendy approach that arises from collecting a wide range of physical information in smart cities. In this context, assessing the quality of sensed data becomes essential to ensure that this strategy can be efficiently executed. Typically, popular data assessment strategies have focused on participants’ historical data as well as social contexts, or through online feedback to adjust quality biases. However, when faced with sensing data from more hostile environments, where sufficient supporting information is lacking and data is highly privatized, conventional assessment strategies may appear weak. Therefore, this paper introduces an innovative approach by integrating social psychology to address this issue, proposing a data quality assessment strategy termed the “Inspector Sense Model”. In this model, the responsibility for evaluating data quality is assigned to each participant, who serves as both a contributor of sensed data and an evaluator of others’ data quality. Further, this paper introduces a probabilistic statistical model to ensure the high reliability of the assessment results. In addition, this paper proposes an incentive mechanism called the “All Pay Auction” to ensure that this strategy can be implemented within the cost budget constraints. In particular, the unreliability of submission locations in the uploaded data is cleverly addressed by applying the proposed assessment strategy in reverse, significantly improving the overall data quality assessment capability of the strategy. During the experimental stage, simulation experiments were carried out utilizing temperature observations sourced from the real-world data provided by taxi drivers in Rome, and various performance metrics were analyzed. The results of these experiments demonstrate the capability of the proposed solutions to accurately assess data of unreliable quality, yielding highly precise assessment results.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data integrity",
                "Psychology",
                "Sensors",
                "Reliability",
                "Quality assessment",
                "Games",
                "Crowdsensing",
                "Data privacy",
                "Probabilistic logic",
                "Privacy"
            ],
            "Author Keywords": [
                "Mobile Crowdsensing",
                "Data Quality Assessment",
                "Probability of Credibility",
                "Psychology Effect",
                "All Pay Auction"
            ]
        },
        "Field": "data",
        "title": "Utilizing Social Psychology Solutions to Enhance the Quality Assessment Ability of Unreliable Data in Mobile Crowdsensing",
        "link": "https://ieeexplore.ieee.org/document/10722875/"
    },
    {
        "authors": [
            "Wen Mo",
            "Anfeng Liu",
            "Neal N. Xiong",
            "Houbing Song"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Services Computing ( Early Access )",
        "date_of_publication": "25 July 2024",
        "doi": "10.1109/TSC.2024.3433541",
        "publisher": "IEEE",
        "abstract": "Mobile Crowd Sensing (MCS) has emerged as a novel paradigm in massive data collection, which leverages many individual mobile devices (called workers) to collect data. MCS platform utilizes the collected data to construct various services for service requesters, thus obtaining profit based on the data values contributed by workers. However, untrustworthy data would greatly reduce the data value, leading to a decline in platform profit, so it is crucial for the platform to recruit high-trust workers and collect truthful data, thereby providing high-quality service and obtaining high profit. To address this problem, we propose a Maximize Profit Scheme, called MPS, for MCS platforms, which consider that the data value declines as data trust decreases and discounts over time. MPS scheme is the first work that systematically addresses the impact of untruthful data on the platform profit, which is not well addressed in previous research. First, we utilize historical data of trusted workers as truthful data to identify the truth of data, which is a low-cost method. Then, a trust-discounting and time-discounting value model is proposed, which is more practical than previous methods. Based on the proposed value model, we propose a novel worker recruitment strategy combined with a trust-related and time-dependent reward threshold, which prioritizes workers with high trust and low latency, thereby promoting the data value of workers and maximizing the platform's profit. By comparing the MPS with existing schemes, the experimental results show that our MPS can achieve better performance in terms of total profit.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Costs",
                "Task analysis",
                "Sensors",
                "Data collection",
                "Recruitment",
                "Data models",
                "Low latency communication"
            ],
            "Author Keywords": [
                "Mobile Crowd Sensing",
                "maximize profit",
                "truth discovery services",
                "data truth discovery",
                "trust and time-discounting"
            ]
        },
        "Field": "data",
        "title": "MPS: A Truth Discovery Service Scheme by Using History Data to Maximize Profit for Mobile Crowd Sensing",
        "link": "https://ieeexplore.ieee.org/document/10609554/"
    },
    {
        "authors": [
            "Peng Chen",
            "Xiongxiong He",
            "Jinhui Zhu",
            "Sheng Li"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Automation Science and Engineering ( Early Access )",
        "date_of_publication": "04 June 2024",
        "doi": "10.1109/TASE.2024.3407825",
        "publisher": "IEEE",
        "abstract": "In the magnetic actuation system, MAC (Magnetically Actuated Capsule) motion is disturbed by gastrointestinal resistance, and dynamic constraints exist between MAC and EPM (External Permanent Magnet), leading to control difficulties. This paper presents a data-driven control method for magnetic actuation system. Firstly, a data-driven modeling approach is proposed for addressing the modeling challenges, relying solely on MAC visual positioning input and EPM position output data. Secondly, To effectively track rapidly changing MAC desired trajectories, determining the upper bound of system inputs through analysis of the magnetic field relationship, and integrating it with adaptive parameter reset conditions, enables the establishment of dynamic constraints for the MAC system. Finally, dynamic compensation is applied to account for non-linear resistance terms and inaccuracies in data model representation. A dual-visual positioning experimental platform simulating the gastrointestinal environment is established to validate the proposed algorithm’s effectiveness in MAC trajectory tracking under different conditions. Note to Practitioners —This article aims to design a data-driven method that incorporates dynamic constraint relationships between MAC and EPM, enabling capsules to move rapidly within the gastrointestinal system. This paper aims to increase control speed, enabling the energy to be primarily used for capturing the lesion area rather than during motion, and improving MAC tracking for desired trajectory accuracy. To validate the algorithm’s effectiveness under various resistances and driving forces, a dual-camera positioning system is designed and tested on a simulated gastrointestinal platform. In future work, we plan to replace the external camera with an internal capsule camera for MAC localization and design a medical system that actively utilizes patient lesion data to drive WCE for examinations.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Gastrointestinal tract",
                "Force",
                "Resistance",
                "Dynamics",
                "Robots",
                "Permanent magnets",
                "Magnetic resonance imaging"
            ],
            "Author Keywords": [
                "Magnetically actuated capsule",
                "data-driven adaptive control",
                "dynamic input constraints",
                "dual-visual positioning experimental platform"
            ]
        },
        "Field": "data",
        "title": "Data-Driven Control for Magnetic Actuation Capsule: Dynamic Compensation and Input Constraints",
        "link": "https://ieeexplore.ieee.org/document/10547708/"
    },
    {
        "authors": [
            "Charuka Herath",
            "Xiaolan Liu",
            "Sangarapillai Lambotharan",
            "Yogachandran Rahulamathavan"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "04 November 2024",
        "doi": "10.1109/JIOT.2024.3491034",
        "publisher": "IEEE",
        "abstract": "Federated Learning (FL) is a decentralized approach for collaborative model training on edge devices. This distributed method of model training offers advantages in privacy, security, regulatory compliance, and cost-efficiency. Our emphasis in this research lies in addressing statistical complexity in FL, especially when the data stored locally across devices is not identically and independently distributed (non-IID). We have observed an accuracy reduction of up to approximately 10% to 30%, particularly in skewed scenarios where each edge device trains with only 1 class of data. This reduction is attributed to weight divergence, quantified using the Euclidean distance between device-level class distributions and the population distribution, resulting in a bias term (δk). As a solution, we present a method to improve convergence in FL by creating a global subset of data on the server and dynamically distributing it across devices using a Dynamic Data queue-driven Federated Learning (DDFL). Next, we leverage Data Entropy metrics to observe the process during each training round and enable reasonable device selection for aggregation. Furthermore, we provide a convergence analysis of our proposed DDFL to justify their viability in practical FL scenarios, aiming for better device selection, a non-sub-optimal global model, and faster convergence. We observe that our approach results in a substantial accuracy boost of approximately 5% for the MNIST dataset, around 18% for CIFAR-10, and 20% for CIFAR-100 with a 10% global subset of data, outperforming the state-of-the-art (SOTA) aggregation algorithms.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Convergence",
                "Internet of Things",
                "Distributed databases",
                "Accuracy",
                "Training",
                "Mathematical models",
                "Servers",
                "Adaptation models",
                "Federated learning"
            ],
            "Author Keywords": [
                "Data-entropy",
                "Fairness FL",
                "Federated Learning",
                "non-IID"
            ]
        },
        "Field": "data",
        "title": "Enhancing Federated Learning Convergence with Dynamic Data Queue and Data Entropy-driven Participant Selection",
        "link": "https://ieeexplore.ieee.org/document/10742416/"
    },
    {
        "authors": [
            "Tao Li",
            "Yuhua Qian",
            "Feijiang Li",
            "Xinyan Liang",
            "Zhi-hui Zhan"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "19 March 2024",
        "doi": "10.1109/TBDATA.2024.3378090",
        "publisher": "IEEE",
        "abstract": "It is a challenging task to select the informative features that can maintain the manifold structure in the original feature space. Many unsupervised feature selection methods still suffer the poor cluster performance in the selected feature subset. To tackle this problem, a feature subspace learning-based binary differential evolution algorithm is proposed for unsupervised feature selection. Firstly, a new unsupervised feature selection framework based on evolutionary computation is designed, in which the feature subspace learning and the population search mechanism are combined into a unified unsupervised feature selection. Secondly, a local manifold structure learning strategy and a sample pseudo-label learning strategy are presented to calculate the importance of the selected feature subspace. Thirdly, the binary differential evolution algorithm is developed to optimize the selected feature subspace, in which the binary information migration mutation operator and the adaptive crossover operator are designed to promote the searching for the global optimal feature subspace. Experimental results on various types of realworld datasets demonstrate that the proposed algorithm can obtain more informative feature subset and competitive cluster performance compared with eight state-of-the-art unsupervised feature selection methods.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Manifolds",
                "Optimization",
                "Clustering algorithms",
                "Sociology",
                "Search problems",
                "Big Data"
            ],
            "Author Keywords": [
                "Evolutionary computation",
                "unsupervised feature selection",
                "local manifold structure",
                "pseudo-label"
            ]
        },
        "Field": "data",
        "title": "Feature Subspace Learning-based Binary Differential Evolution Algorithm for Unsupervised Feature Selection",
        "link": "https://ieeexplore.ieee.org/document/10473134/"
    },
    {
        "authors": [
            "Tariku Sinshaw Tamir",
            "Gang Xiong",
            "Zhen Shen",
            "Jiewu Leng"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Computational Social Systems ( Early Access )",
        "date_of_publication": "28 June 2024",
        "doi": "10.1109/TCSS.2024.3407823",
        "publisher": "IEEE",
        "abstract": "Additive manufacturing (AM), also called 3-D printing, is a supporting technology in social manufacturing that has gained significant attention recently. As the AM industry grows, collecting and analyzing data are essential to ensure product quality, process efficiency, and cost-effectiveness. However, obtaining experimental data is challenging owing to cost and time constraints. Therefore, cost-effective and time-efficient strategies for collecting AM data are urgently required. This study proposes a novel data-collection approach that integrates the concept of finite element analysis (FEA) and physics-informed machine learning (PIML). We begin by discussing the importance of data collection in AM and the associated challenges. We then present various types of data that can be collected in AM, including the 3-D models and end-to-end data. End-to-end data comprise experimental data (i.e., sensors and images) and simulation data. Moreover, we present a case study that demonstrates the generation of simulation data and provides a detailed analysis of warpage. The STereoLithography (STL) file format of the BeltClip object from the Thingiverse possesses slicing through the Ultimaker© Cura software. The resulting G-code file is input to the Digimat-AM platform for virtual simulation of the BeltClip printing process. Digimat-AM, as a FEA simulation tool, then generates observational sample data. These data function as a roadmap for understanding the application of physical information for learning, which constitutes the observational bias aspect of PIML. The observational data obtained from the Digimat-AM is suggested for building a machine-learning model. Finally, we conclude with a discussion of inductive and learning biases in the prediction, control, and optimization aspects of AM.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Printing",
                "Manufacturing",
                "Prediction algorithms",
                "Industries",
                "Optimization",
                "Data collection",
                "Process control"
            ],
            "Author Keywords": [
                "3-D printing",
                "experimental data",
                "physicsinformed machine learning (PIML)",
                "simulation data",
                "social manufacturing",
                "warpage analysis."
            ]
        },
        "Field": "data",
        "title": "Physics-Driven Data Collection in 3-D Printing: Traversing the Realm of Social Manufacturing",
        "link": "https://ieeexplore.ieee.org/document/10577439/"
    },
    {
        "authors": [
            "Bo-Wei Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "04 November 2024",
        "doi": "10.1109/JIOT.2024.3490252",
        "publisher": "IEEE",
        "abstract": "Visual Internet of Things (VIoT) empowers intelligent sensing by equipping terminal devices with the capability to preliminarily screen and tag sensing data for further processing. However, sensing environments are often imperfect, and partially observed data may be collected at the terminals. This causes several challenges. Firstly, the model fitting process may become oversensitive owing to the presence of varying corrupted data, e.g., continuous occlusion, therefore compromising robustness because of fitting biases. Secondly, model fitting relies on label information, which consists of fixed and equally spaced categorical variables. Such information cannot adequately reflect the underlying distribution of collected data, as it assumes that each categorical variable is uniformly distributed. This deepens the difficulty of data fitting. To solve the aforementioned problems, this study proposes robust data sensing based on ℓ2,p norms, where data collected by VIoT terminals can be converted into resilient perceptual data signatures while label information is embedded inside. To deal with the problem stemming from rigid label marginal space, this study introduces an adaptive slack variable to the proposed model. Such a slack variable can automatically adapt itself to sensing data during model fitting while adjusting label marginal space by providing flexible labels. Moreover, a new adaptive regulating mechanism is developed to control the slack variables, such that they can consider multiple coeffects from different loss terms and penalties during optimization, creating error-tolerant soft margins. This is conducive to model fitting, especially for partially observed data. In addition to label slack variables, this study also derives slack variables for ℓ2,p-norm loss that is used to capture the nuances of the data, thereby providing flexible Hamming marginal space for resilient signature generation. Experiments on open datasets show that the proposed method yields be...",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Sensors",
                "Fitting",
                "Aerospace electronics",
                "Synchronous digital hierarchy",
                "Data models",
                "Internet of Things",
                "Adaptation models",
                "Kernel",
                "Covariance matrices",
                "Visualization"
            ],
            "Author Keywords": [
                "Robust data sensing",
                "partially observed data",
                "adaptive label marginal space",
                "adaptive Hamming marginal space",
                "discriminative least squares regression",
                "Visual Internet of Things"
            ]
        },
        "Field": "data",
        "title": "Robust Partially-Observed Data Sensing via ℓ2,p Norms with Flexible Adaptive Label Marginal Space for Visual IoT",
        "link": "https://ieeexplore.ieee.org/document/10742289/"
    },
    {
        "authors": [
            "Jinguo Li",
            "Yun Ni",
            "Jin Zhang",
            "Jie Yu",
            "Yin He"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "09 September 2024",
        "doi": "10.1109/JIOT.2024.3456134",
        "publisher": "IEEE",
        "abstract": "Internet of Things (IoT) devices generate vast amounts of real-time data across diverse sectors, offering lucrative opportunities in the data trading market. This facilitates the conversion of raw data into valuable products and services, resulting in significant economic and social benefits. To issue data security problems in trading mechanisms, several solutions based on local differential privacy (LDP) provide lightweight methods for privacy preservation and efficient data exchange. However, most solutions lack effective mechanisms for longitudinal data. Moreover, LDP needs to address the data quality problem in IoT. At last, the pricing of privacy-preserving longitudinal data remains unresolved. To address these problems, we propose a Privacy-Preserving Data Trading (PPDT) scheme for IoT in this paper. Specifically, to guarantee the security of longitudinal data, we utilize two perturbation techniques to accommodate data owners with varying privacy preferences. To enhance data availability, we devise a binary tree-based aggregation algorithm combined with a weighted average strategy and maximum likelihood estimation. Additionally, we derive an optimal contract that considers different levels of privacy preservation and data trading prices. In scenarios with incomplete information, the contract can provide appropriate incentives to the involved parties. Finally, we demonstrate the efficiency and effectiveness of the proposed data trading scheme through theoretical analysis and extensive experiments.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Pricing",
                "Data models",
                "Internet of Things",
                "Differential privacy",
                "Security",
                "Blockchains",
                "Sensors"
            ],
            "Author Keywords": [
                "Internet of Things",
                "Privacy-preserving",
                "Data trading",
                "Local differential privacy",
                "Longitudinal data"
            ]
        },
        "Field": "data",
        "title": "A Contract-Based Privacy-Preserving Longitudinal Data Trading Mechanism for IoT",
        "link": "https://ieeexplore.ieee.org/document/10669375/"
    },
    {
        "authors": [
            "Haitao Wang",
            "Xiyang Dai",
            "Lichen Shi",
            "Yide Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Sensors Journal ( Early Access )",
        "date_of_publication": "16 October 2024",
        "doi": "10.1109/JSEN.2024.3477929",
        "publisher": "IEEE",
        "abstract": "In the actual working environment, mechanical equipment is in normal operation for a long time, which leads to unbalanced sample data collected and will be accompanied by problems such as changes in working conditions. All these issues contribute to problems such as the low accuracy of intelligent fault diagnosis models. In this regard, this paper proposes a new method for fault diagnosis based on hybrid data-assisted multi-source domain transfer learning under unbalanced conditions. First, fault signals simulated and real vibration signals are converted into two-dimensional images using the gram angle product field (GAPF), and the Wasserstein distance conditional gradient penalized generative adversarial network (CWGAN-GP) is used to augment the real data of the source domain to get high-quality, usable samples. Second, the mixed data consisting of these three are input into a Residual Network with Receptive Field Attention - Graph Convolutional Network (ResRFA-GCN) common feature extractor as source domain samples and target domain samples to train the model and the extraction of common features. Next, the features extracted from each pair of sources and target domains are mapped into a specific space, and the local maximum mean discrepancy (LMMD) is employed to minimize the difference in the distribution of the domains, and the module allows it to learn the domain invariant properties between each pair of source and target domain subclasses. Finally, after realizing the classification in a specific classifier. The model is tested on two datasets, and satisfactory results are achieved, thus reducing the dependence of the intelligent fault diagnosis model on measured data of fault samples.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Fault diagnosis",
                "Finite element analysis",
                "Vibrations",
                "Data models",
                "Data mining",
                "Sensors",
                "Adaptation models",
                "Vectors",
                "Transfer learning"
            ],
            "Author Keywords": [
                "Fault diagnosis",
                "finite element simulation",
                "gram angle field",
                "generative adversarial network",
                "graph convolutional network (GCN)"
            ]
        },
        "Field": "data",
        "title": "Gearbox Fault Diagnosis Based on Mixed Data-Assisted Multi-Source Domain Transfer Learning under Unbalanced Data",
        "link": "https://ieeexplore.ieee.org/document/10720710/"
    },
    {
        "authors": [
            "Mohammad Ali",
            "Ximeng Liu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "11 September 2024",
        "doi": "10.1109/JIOT.2024.3457988",
        "publisher": "IEEE",
        "abstract": "Ensuring data integrity and confidentiality is critical in communication systems. Traditional methods, such as separate encryption and signature schemes, often lead to inefficiencies. While signcryption methods address both needs simultaneously, they are inadequate for data outsourcing systems like cloud computing due to the requirement for original files during data verification. Conversely, remote data integrity checking (RDIC) methods eliminate the need for original files but lack confidentiality. This paper fills the gap in cloud security by introducing remote signcryption (RSC) and presenting the first concrete RSC scheme. We demonstrate the application of this novel approach in cloud-assisted Internet of Things (IoT) networks. Our work includes defining the security for an RSC scheme and proving its security under the Bilinear Diffie-Hellman (BDH) hardness assumption. Implementing our proposed scheme on real data from trending YouTube video statistics, we found that RSC significantly outperforms existing methods, achieving 100 times faster speed and reducing communication costs by half compared to RDIC methods. Notably, even with 5MB of outsourced data, RSC keeps the communication cost under 8KB during data recovery, a substantial improvement over classical signcryption methods that require over 5MB.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Cloud computing",
                "Encryption",
                "Costs",
                "Internet of Things",
                "Security",
                "Data integrity",
                "Public key"
            ],
            "Author Keywords": [
                "Data integrity",
                "data confidentiality",
                "remote data integrity checking",
                "signcryption",
                "remote signcryption",
                "provable security"
            ]
        },
        "Field": "data",
        "title": "A Novel Framework in Cloud Security: Remote Signcryption",
        "link": "https://ieeexplore.ieee.org/document/10677432/"
    },
    {
        "authors": [
            "Mostafa M. Fouda",
            "Zubair Md Fadlullah",
            "Mohamed I. Ibrahem",
            "Nei Kato"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Communications Surveys & Tutorials ( Early Access )",
        "date_of_publication": "28 October 2024",
        "doi": "10.1109/COMST.2024.3486690",
        "publisher": "IEEE",
        "abstract": "With the proliferation of Beyond 5G (B5G) communication systems and heterogeneous networks, mobile broadband users are generating massive volumes of data that undergo fast processing and computing to obtain actionable insights. While analyzing this huge amount of data typically involves machine and deep learning-based data-driven Artificial Intelligence (AI) models, a key challenge arises in terms of providing privacy assurances for user-generated data. Even though data-driven techniques have been widely utilized for network traffic analysis and other network management tasks, researchers have also identified that applying AI techniques may often lead to severe privacy concerns. Therefore, the concept of privacy-preserving data-driven learning models has recently emerged as a hot area of research to facilitate model training on large-scale datasets while guaranteeing privacy along with the security of the data. In this paper, we first demonstrate the research gap in this domain, followed by a tutorial-oriented review of data-driven models, which can be potentially mapped to privacy-preserving techniques. Then, we provide preliminaries of a number of privacy-preserving techniques (e.g., differential privacy, functional encryption, Homomorphic encryption, secure multi-party computation, and federated learning) that can be potentially adopted for emerging communication networks. The provided preliminaries enable us to showcase the subset of data-driven privacy-preserving models, which are gaining traction in emerging communication network systems. We provide a number of relevant networking use cases, ranging from the B5G core and Radio Access Networks (RANs) to semantic communications, adopting privacy-preserving data-driven models. Based on the lessons learned from the pertinent use cases, we also identify several open research challenges and hint toward possible solutions.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Communication networks",
                "Computational modeling",
                "Surveys",
                "Data privacy",
                "Tutorials",
                "Quality of service",
                "Analytical models",
                "Taxonomy",
                "Reviews"
            ],
            "Author Keywords": [
                "Privacy preservation",
                "machine learning",
                "deep learning",
                "data-driven models",
                "communication networks",
                "federated learning"
            ]
        },
        "Field": "data",
        "title": "Privacy-Preserving Data-Driven Learning Models for Emerging Communication Networks: A Comprehensive Survey",
        "link": "https://ieeexplore.ieee.org/document/10736556/"
    },
    {
        "authors": [
            "Khalid Usman",
            "Fangping Wan",
            "Dan Zhao",
            "Jian Peng",
            "Jianyang Zeng"
        ],
        "locations": [],
        "published_in": "Published in: IEEE/ACM Transactions on Computational Biology and Bioinformatics ( Early Access )",
        "date_of_publication": "24 June 2024",
        "doi": "10.1109/TCBB.2024.3418078",
        "publisher": "IEEE",
        "abstract": "The recent boom in single-cell sequencing technologies provides valuable insights into the transcriptomes of individual cells. Through single-cell data analyses, a number of biological discoveries, such as novel cell types, developmental cell lineage trajectories, and gene regulatory networks, have been uncovered. However, the massive and increasingly accumulated single-cell datasets have also posed a seriously computational and analytical challenge for researchers. To address this issue, one typically applies dimensionality reduction approaches to reduce the large-scale datasets. However, these approaches are generally computationally infeasible for tall matrices. In addition, the downstream data analysis tasks such as clustering still take a large time complexity even on the dimension-reduced datasets. We present single-cell Coreset (scCoreset), a data summarization framework that extracts a small weighted subset of cells from a huge sparse single-cell RNA-seq data to facilitate the downstream data analysis tasks. Single-cell data analyses run on the extracted subset yield similar results to those derived from the original uncompressed data. Tests on various single-cell datasets show that scCoreset outperforms the existing data summarization approaches for common downstream tasks such as visualization and clustering. We believe that scCoreset can serve as a useful plug-in tool to improve the efficiency of current single-cell RNA-seq data analyses.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data analysis",
                "Cells (biology)",
                "Task analysis",
                "Computer science",
                "Biology",
                "Data mining",
                "Clustering algorithms"
            ],
            "Author Keywords": [
                "Coreset",
                "large-scale datasets",
                "ScCoreset",
                "single - cell RNA-seq data"
            ]
        },
        "Field": "data",
        "title": "Analyzing Large-Scale Single-Cell RNA-Seq Data Using Coreset",
        "link": "https://ieeexplore.ieee.org/document/10569081/"
    },
    {
        "authors": [
            "Zhao Zhang",
            "Suiyi Zhao",
            "Xiaojie Jin",
            "Mingliang Xu",
            "Yi Yang",
            "Shuicheng Yan",
            "Meng Wang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Pattern Analysis and Machine Intelligence ( Early Access )",
        "date_of_publication": "28 October 2024",
        "doi": "10.1109/TPAMI.2024.3487361",
        "publisher": "IEEE",
        "abstract": "Deep learning-based low-light image enhancement (LLIE) is a task of leveraging deep neural networks to enhance the image illumination while keeping the image content unchanged. From the perspective of training data, existing methods complete the LLIE task driven by one of the following three data types: paired data, unpaired data and zero-reference data. Each type of these data-driven methods has its own advantages, e.g., zero-reference data-based methods have very low requirements on training data and can meet the human needs in many scenarios. In this paper, we leverage pure Gaussian noise to complete the LLIE task, which further reduces the requirements for training data in LLIE tasks and can be used as another alternative in practical use. Specifically, we propose Noise SElf-Regression (NoiSER) without access to any task-related data, simply learns a convolutional neural network equipped with an instance-normalization layer by taking a random noise image, $\\mathcal {N}(0,\\sigma ^{2})$ for each pixel, as both input and output for each training pair, and then the low-light image is fed to the trained network for predicting the normal-light image. Technically, an intuitive explanation for its effectiveness is as follows: 1) the self-regression reconstructs the contrast between adjacent pixels of the input image, 2) the instance-normalization layer may naturally remediate the overall magnitude/lighting of the input image, and 3) the $\\mathcal {N}(0,\\sigma ^{2})$ assumption for each pixel enforces the output image to follow the well-known gray-world hypothesis [1] when the image size is big enough. Compared to current state-of-the-art LLIE methods with access to different task-related data, NoiSER is highly competitive in enhancement quality, yet with a much smaller model size, and much lower training and inference cost. In addition, the experiments also demonstrate that NoiSER has great potential in overexposure suppression and joint processing with other restor...",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Noise",
                "Training",
                "Data models",
                "Training data",
                "Image reconstruction",
                "Lighting",
                "Image color analysis",
                "Costs",
                "Image enhancement",
                "Colored noise"
            ],
            "Author Keywords": [
                "Learning without task-related data",
                "low-light image enhancement",
                "new learning paradigm",
                "noise self-regression"
            ]
        },
        "Field": "data",
        "title": "Noise Self-Regression: A New Learning Paradigm to Enhance Low-Light Images Without Task-Related Data",
        "link": "https://ieeexplore.ieee.org/document/10737245/"
    },
    {
        "authors": [
            "Tian Yang",
            "Fansong Yan",
            "Fengcai Qiao",
            "Jieting Wang",
            "Yuhua Qian"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Knowledge and Data Engineering ( Early Access )",
        "date_of_publication": "29 October 2024",
        "doi": "10.1109/TKDE.2024.3487641",
        "publisher": "IEEE",
        "abstract": "Monotonic classification is a special ordinal classification task that involves monotonicity constraints between features and the decision. Monotonic feature selection can reduce dimensionality while preserving the monotonicity constraints, ultimately improving the efficiency and performance of monotonic classifiers. However, existing feature selection algorithms cannot handle large-scale monotonic data sets due to their lack of consideration for monotonic constraints or their high computational complexities. To address these issues, building on our team's previous research, we define the monotonic related family method with lower time complexity to select informative features and obtain multi-reducts carrying complementary information from multi-view for raw feature space. Using bi-directional rank mutual information, we build two trees for each feature subset and fuse all trees using the corresponding decision support level (BFMDT). Compared with six representative algorithms for monotonic feature selection, BFMDT's average classification accuracy increased by4.06% (FFREMT), 6.77% (FCMT), 5.61% (FPRS up), 6.05% (FPRS down), 5.86%(FPRS global), 4.41% (Bagging), 7.65% (REMT) and 21.89% (FMKNN), the average execution time compared to tree-based algorithms decreased by 83.41% (FFREMT), 96.96% (FCMT), 75.64% (FPRS up), 59.43% (FPRS down), 84.65%(FPRS global), 81.50% (Bagging) and 63.41% (REMT), while most of comparing algorithms were unable to complete computation on six high-dimensional datasets.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Decision trees",
                "Classification algorithms",
                "Bagging",
                "Accuracy",
                "Rough sets",
                "Mutual information",
                "Prediction algorithms",
                "Entropy",
                "Data processing"
            ],
            "Author Keywords": [
                "Rough set",
                "Granular computing",
                "Related family",
                "Monotonic classification",
                "Decision tree",
                "Feature selection"
            ]
        },
        "Field": "data",
        "title": "Fusing Monotonic Decision Tree Based on Related Family",
        "link": "https://ieeexplore.ieee.org/document/10737677/"
    },
    {
        "authors": [
            "Yunkai Lou",
            "Chaokun Wang",
            "Songyao Wang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "05 September 2024",
        "doi": "10.1109/TBDATA.2024.3455172",
        "publisher": "IEEE",
        "abstract": "With the wide application of graphs in various fields, graph query languages have attracted more and more attention. Existing graph query languages, such as GraphQL and SoQL, mostly have similar expressive power as the first-order logic or its extended versions, and are limited when used to express various queries. In this paper, since the graph data model is the base of the graph query language, we propose a new graph data model with the expressive power of monadic second-order logic (abbr. MSOL), and then present a more expressive SQL- like declarative graph query language named\nSOGQL\nto support more common queries efficiently. Specifically, a new graph calculus is firstly proposed based on MSOL for attributed graphs. Then, the new graph data model is proposed. Its graph algebra, which operates on graph sets, has seven fundamental operators such as union, filter, map, and reduce. Next, the graph query language\nSOGQL\nis proposed based on the graph data model. Since the graph algebra has the same expressive power as the graph calculus,\nSOGQL\nhas the expressive power of MSOL, and can express queries with constraints on subgraphs. Moreover, applied with\nSOGQL\n, a prototype system named\nSOGDB\nis implemented.\nSOGDB\nis applied with\nSOGQL\n, and the experimental results show its efficiency.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Chaos",
                "Database languages",
                "Logic",
                "Data models",
                "Algebra",
                "Software",
                "Ciphers"
            ],
            "Author Keywords": [
                "Graph algebra",
                "graph calculus",
                "graph data model",
                "graph query language"
            ]
        },
        "Field": "data",
        "title": "Graph Data Model and Graph Query Language Based on the Monadic Second-Order Logic",
        "link": "https://ieeexplore.ieee.org/document/10666265/"
    },
    {
        "authors": [
            "Bo Hu",
            "Xin Cheng",
            "Changzheng Shao",
            "Tao Niu",
            "Chunyan Li",
            "Yue Sun",
            "Wei Huang",
            "Kaigui Xie"
        ],
        "locations": [],
        "published_in": "Published in: CSEE Journal of Power and Energy Systems ( Early Access )",
        "date_of_publication": "06 May 2022",
        "doi": "10.17775/CSEEJPES.2021.01690",
        "publisher": "CSEE",
        "abstract": "Recently, the heat and electricity integrated energy system(HE-IES) has become a hot topic in both industry and academia. In the HE-IES, the potential flexibility of buildings' thermal loads can be exploited to relax the heat power balance constraints and consequently allows a more flexible operation of the combined heat and power units. In this paper, model-driven and data-driven techniques are combined to quantify the demand flexibility of buildings' thermal loads in a non-instructive way. First, the explicit analytical equivalent thermal parameter (ETP) model of the aggregated buildings is developed. The heat transfer coefficient^) and thermal inertia coefficient(C) of the ETP model are designated to measure the potential demand flexibility. Second, the Particle Swarm Optimization optimized Radial Basis Function neural network (PSO-RBF) is used to identify the relationship between the values of к and C and the meteorological factors. To obtain the training data, an innovative two-stage regression method based on the adaptive temporal resolution is proposed to extract к and C values from the historical thermal load data. Last, the flexible thermal load model is built based on the predictions of the meteorological factors, which can be incorporated conveniently into the online dispatch of the HE-IES. A comprehensive simulation environment is designed to verify the accuracy and availability of the proposed technique.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Buildings",
                "Thermal loading",
                "Load modeling",
                "Heat transfer",
                "Meteorological factors",
                "Thermal factors",
                "Cogeneration"
            ],
            "Author Keywords": [
                "Flexibility of buildings' thermal loads",
                "Heat and electricity integrated energy system",
                "Model and data hybrid driven",
                "Meteorological factors"
            ]
        },
        "Field": "data",
        "title": "A model and data hybrid driven approach for quantifying the meteorology-dependent demand flexibility of building thermal loads",
        "link": "https://ieeexplore.ieee.org/document/9770524/"
    },
    {
        "authors": [
            "Wenjie Liu",
            "Gang Wang",
            "Jian Sun",
            "Francesco Bullo",
            "Jie Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Automatic Control ( Early Access )",
        "date_of_publication": "05 June 2024",
        "doi": "10.1109/TAC.2024.3409749",
        "publisher": "IEEE",
        "abstract": "This paper addresses the joint state estimation and control problems for unknown linear time-invariant systems subject to both process and measurement noise. The aim is to redesign the linear quadratic Gaussian (LQG) controller based solely on data. The LQG controller comprises a linear quadratic regulator (LQR) and a steady-state Kalman observer; while the data-based LQR design problem has been previously studied, constructing the Kalman gain and the LQG controller from noisy data presents a novel challenge. In this work, a data-based formulation for computing the steady-state Kalman gain is proposed based on semi-definite programming (SDP) using some noise-free input-state-output data. To compensate for the offline noise, a relaxed SDP is proposed, upon solving which, a robust observer gain is constructed. Additionally, a robust LQG controller is designed based on the observer gain and a data-based LQR gain. The proposed controller is proven to achieve robust global exponential stability (RGES) for the observer and input-to-state stability (ISS) for the resultant closed-loop systems under standard conditions. Finally, numerical tests are conducted to validate the proposed controllers' correctness and effectiveness.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Noise",
                "Noise measurement",
                "Kalman filters",
                "Estimation",
                "Observers",
                "Trajectory",
                "Linear systems"
            ],
            "Author Keywords": [
                "Data-driven control",
                "linear quadratic gaussian",
                "noisy data",
                "semi-definite program",
                "state estimation"
            ]
        },
        "Field": "data",
        "title": "Learning Robust Data-Based LQG Controllers From Noisy Data",
        "link": "https://ieeexplore.ieee.org/document/10549788/"
    },
    {
        "authors": [
            "Yang Tan",
            "Enming Zhang",
            "Yang Li",
            "Shao-Lun Huang",
            "Xiao-Ping Zhang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )",
        "date_of_publication": "05 February 2024",
        "doi": "10.1109/TNNLS.2024.3358094",
        "publisher": "IEEE",
        "abstract": "We propose two novel transferability metrics fast optimal transport-based conditional entropy (F-OTCE) and joint correspondence OTCE (JC-OTCE) to evaluate how much the source model (task) can benefit the learning of the target task and to learn more generalizable representations for cross-domain cross-task transfer learning. Unlike the original OTCE metric that requires evaluating the empirical transferability on auxiliary tasks, our metrics are auxiliary-free such that they can be computed much more efficiently. Specifically, F-OTCE estimates transferability by first solving an optimal transport (OT) problem between source and target distributions and then uses the optimal coupling to compute the negative conditional entropy (NCE) between the source and target labels. It can also serve as an objective function to enhance downstream transfer learning tasks including model finetuning and domain generalization (DG). Meanwhile, JC-OTCE improves the transferability accuracy of F-OTCE by including label distances in the OT problem, though it incurs additional computation costs. Extensive experiments demonstrate that F-OTCE and JC-OTCE outperform state-of-the-art auxiliary-free metrics by\n21.1%\nand\n25.8%\n, respectively, in correlation coefficient with the ground-truth transfer accuracy. By eliminating the training cost of auxiliary tasks, the two metrics reduce the total computation time of the previous method from 43 min to 9.32 and 10.78 s, respectively, for a pair of tasks. When applied in the model finetuning and DG tasks, F-OTCE shows significant improvements in the transfer accuracy in few-shot classification experiments, with up to\n4.41%\nand\n2.34%\naccuracy gains, respectively.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Measurement",
                "Transfer learning",
                "Computational modeling",
                "Data models",
                "Feature extraction",
                "Couplings"
            ],
            "Author Keywords": [
                "Cross-domain",
                "cross-task",
                "few-shot learning",
                "source selection",
                "task relatedness",
                "transfer learning",
                "transferability estimation"
            ]
        },
        "Field": "data",
        "title": "Transferability-Guided Cross-Domain Cross-Task Transfer Learning",
        "link": "https://ieeexplore.ieee.org/document/10420486/"
    },
    {
        "authors": [
            "Chunyu Pu",
            "Yingxu Liu",
            "Shuai Lin",
            "Xu Shi",
            "Zhengying Li",
            "Hong Huang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "25 July 2024",
        "doi": "10.1109/TBDATA.2024.3433494",
        "publisher": "IEEE",
        "abstract": "Deep learning (DL) has emerged as a competitive method in single-modality-dominated remote sensing (RS) data classification tasks, but its classification performance inevitably encounters a bottleneck due to the lack of representation diversity in complicated spatial structures with various land cover types. Therefore, the RS community has been actively researching multimodal feature learning techniques for the same scene. However, expert annotation of multisource data consumes a significant amount of time and cost. This article proposes an end-to-end method called semisupervised multimodal dual-path network (SMDN). This method simultaneously explore spatial-spectral features contained in hyperspectral images (HSI) and elevation information provided by light detection and ranging (LiDAR). SMDN exploits an unsupervised novel encoder-decoder structure as the backbone network to construct a multimodal DL architecture by jointly training with a data-specific branch. To obtain discriminative multimodal representations, SMDN is able to guide the collaborative training of two different unsupervised features mapped in the latent subspace with limited labeled training samples. Furthermore, after a simple modification of the fusion strategy in SMDN, it can be applied to unsupervised classification problems. Experimental results on benchmark RS datasets validate the effectiveness of the developed SMDN compared over many state-of-the-art methods.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Laser radar",
                "Transformers",
                "Training",
                "Hyperspectral imaging",
                "Big Data",
                "Data mining"
            ],
            "Author Keywords": [
                "Multimodality",
                "hyperspectral image",
                "light detection and ranging (LiDAR)",
                "semisupervised classification",
                "feature fusion"
            ]
        },
        "Field": "data",
        "title": "Multimodal Deep Learning for Semisupervised Classification of Hyperspectral and LiDAR Data",
        "link": "https://ieeexplore.ieee.org/document/10609507/"
    },
    {
        "authors": [
            "Pio Calderon",
            "Alexander Soen",
            "Marian-Andrei Rizoiu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Computational Social Systems ( Early Access )",
        "date_of_publication": "12 November 2024",
        "doi": "10.1109/TCSS.2024.3486117",
        "publisher": "IEEE",
        "abstract": "The multivariate Hawkes process (MHP) is widely used for analyzing data streams that interact with each other, where events generate new events within their own dimension (via self-excitation) or across different dimensions (via cross excitation). However, in certain applications, the timestamps of individual events in some dimensions are unobservable, and only event counts within intervals are known, referred to as partially interval-censored data. The MHP is unsuitable for handling such data since its estimation requires event timestamps. In this study, we introduce the partially censored multivariate Hawkes process (PCMHP), a novel point process that shares parameter equivalence with the MHP and can effectively model both timestamped and interval-censored data. We demonstrate the capabilities of the PCMHP using synthetic and real-world datasets. First, we illustrate that the PCMHP can approximate MHP parameters and recover the spectral radius using synthetic event histories. Next, we assess the performance of the PCMHP in predicting YouTube popularity and find that the PCMHP outperforms the popularity estimation algorithm Hawkes intensity process (HIP) [1]. Comparing with the fully interval-censored HIP, we show that the PCMHP improves prediction performance by accounting for point process dimensions, particularly when there exist significant cross-dimension interactions. Last, we leverage the PCMHP to gain qualitative insights from a dataset comprising daily COVID-19 case counts from multiple countries and COVID-19- related news articles. By clustering the PCMHP-modeled countries, we unveil hidden interaction patterns between occurrences of COVID-19 cases and news reporting.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Web sites",
                "Video on demand",
                "Social networking (online)",
                "COVID-19",
                "Maximum likelihood estimation",
                "Data models",
                "Hip",
                "Kernel",
                "Correlation",
                "Blogs"
            ],
            "Author Keywords": [
                "Partially observed data",
                "popularity prediction",
                "temporal point process"
            ]
        },
        "Field": "data",
        "title": "Linking Across Data Granularity: Fitting Multivariate Hawkes Processes to Partially Interval-Censored Data",
        "link": "https://ieeexplore.ieee.org/document/10750824/"
    },
    {
        "authors": [
            "Shengwen Li",
            "Suzhen Huang",
            "Xuyang Cheng",
            "Renyao Chen",
            "Yi Zhou",
            "Shunping Zhou",
            "Hong Yao",
            "Junfang Gong"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Emerging Topics in Computational Intelligence ( Early Access )",
        "date_of_publication": "12 June 2024",
        "doi": "10.1109/TETCI.2024.3406734",
        "publisher": "IEEE",
        "abstract": "Region statistical data is widely utilized as fundamental spatial information for urban status observation, urban planning, and the formulation of urban policies. In practice, the collected region statistical data is usually incomplete due to insufficient sensors, recording errors or privacy restrictions. Transfer learning-based methods make great advancement on completing missing region statistical data in the data-sparse city by training model on the data-rich city. However, these methods employ all available attributes of regions in their dataset to learn transferred knowledge, even if the values of some attributes in the source and target cities differ significantly. To address this issue, this paper proposes a double graph neural network model to improve completion of the region statistical data on insufficient data cities. The model first introduces spatial distribution of attributes to identify transferable attributes, then utilizes hierarchical graph structure to characterize the spatial relationships of regions, finally designs a double graph network to transfer knowledge for completing the missing values of insufficient data cities. Experiments on two datasets show that the proposed model outperforms the baseline models and is robust. This study presents a promising method for spatial data completion, and provides a method reference for spatial applications with insufficient data.",
        "issn": {
            "Electronic ISSN": "2471-285X"
        },
        "keywords": {
            "IEEE Keywords": [
                "Urban areas",
                "Data models",
                "Training",
                "Transfer learning",
                "Roads",
                "Feature extraction",
                "Task analysis"
            ],
            "Author Keywords": [
                "Data-sparse",
                "transfer learning",
                "graph neural networks",
                "attribute decoupling",
                "region statistical data completion"
            ]
        },
        "Field": "data",
        "title": "Transfer Learning-Based Region Statistical Data Completion via Double Graphs",
        "link": "https://ieeexplore.ieee.org/document/10555386/"
    },
    {
        "authors": [
            "Song Yang",
            "Keming Qiu",
            "Fei Zhang",
            "Lu Cao",
            "Fan Li",
            "Min Tang",
            "Liehuang Zhu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Open Journal of the Communications Society ( Early Access )",
        "date_of_publication": "06 November 2024",
        "doi": "10.1109/OJCOMS.2024.3492914",
        "publisher": "IEEE",
        "abstract": "Edge devices (e.g., smartphones, tablelet PC, IoT devices) are becoming more prevalent in people’s daily lives. With advanced sensors and processors, these devices can create massive data. These data can be used for predictive maintenance, enhancing user experience, increasing productivity, etc. These valuable data allow data producers to sell to consumers directly to generate income. Blockchain and smart-contract technology can be used to ensure transactions to be unmodifiable and undeniable. This paper first proposes a blockchain-based data relay and transaction model for the data producer, relay and consumer in edge computing. We then present a new consensus mechanism Proof-of-Data-Trading (PoDT) by combining Proof-of-Work (PoW) mechanism with Proof-of-Stake (PoS) consensus mechanism, which enables the proposed blockchain system to reach consensus with low energy consumption for edge devices. Moreover, we develop an approximation algorithm to store encrypted copies of data items on relays with smaller costs. Extensive simulations show that our proposed blockchain system works efficiently in edge computing. It achieves up to 8.19% higher profit for the data producer with the help of relays and consumers using 84.6% less time to get the data item. In addition, the new consensus mechanism consumes 87% less time when compared with the traditional PoW consensus mechanism.",
        "issn": {
            "Electronic ISSN": "2644-125X"
        },
        "keywords": {
            "IEEE Keywords": [
                "Blockchains",
                "Relays",
                "Edge computing",
                "Consensus protocol",
                "Smart contracts",
                "Data models",
                "Costs",
                "Computational modeling",
                "Peer-to-peer computing",
                "Internet of Things"
            ],
            "Author Keywords": [
                "Blockchain",
                "edge computing",
                "data trading",
                "data placement"
            ]
        },
        "Field": "data",
        "title": "Efficient Data Trading and Placement in Blockchain-based Edge Computing Systems",
        "link": "https://ieeexplore.ieee.org/document/10745747/"
    },
    {
        "authors": [
            "Dawei Sun",
            "Guangyan Zhang",
            "Shang Gao"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Industrial Informatics ( Early Access )",
        "date_of_publication": "20 August 2019",
        "doi": "10.1109/TII.2019.2936298",
        "publisher": "IEEE",
        "abstract": "Supporting efficient geographically-distributed autonomous data management is one of the critical obstacles for opening up a big data era. It creates the need for investigating such kind of systems in big data environments. In this paper, a distributed autonomous data management system is put forward, exhibiting the following features. (1) A distributed architecture designed to meet the requirements of autonomous data management by allowing interconnection, intercommunication, and interoperation of multiple sites over the Internet. (2) An autonomous, multi-level, unstructured data storage system to meet high-efficiency storage needs, with reference to the distributed heterogeneous data storage theories. (3) A distributed autonomous data indexing and retrieval system to support metadata search & full-text searching, fast loading, remote access, and unified view. Experimental and industrial application results demonstrate that the proposed system has high potential to reduce access time and improve storage efficiency, while maintaining satisfactory availability and scalability.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Distributed databases",
                "Memory",
                "Metadata",
                "Big Data",
                "Servers",
                "Indexing"
            ],
            "Author Keywords": [
                "big data",
                "autonomous system",
                "distributed cloud infrastructure",
                "data management system",
                "system architecture"
            ]
        },
        "Field": "data",
        "title": "Data Management across Geographically-Distributed Autonomous Systems: Architecture, Implementation, and Performance Evaluation",
        "link": "https://ieeexplore.ieee.org/document/8807217/"
    },
    {
        "authors": [
            "Junming Zhang",
            "Jingru Wang",
            "Shigong Long",
            "Yanen Li",
            "Lun Wang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Network and Service Management ( Early Access )",
        "date_of_publication": "04 November 2024",
        "doi": "10.1109/TNSM.2024.3490555",
        "publisher": "IEEE",
        "abstract": "Local differential privacy (LDP) techniques obviate the need for trust in the data collector, as they provide robust privacy guarantees against untrusted data managers while simultaneously preserving the accuracy of statistical information derived from the privatized data. As a result, these methods have garnered considerable interest and research efforts. In particular, (ε,δ)-LDP schemes have been utilized across a range of statistical tasks. Nonetheless, existing (ε,δ)-LDP mechanisms for mean estimation suffer from challenges such as elevated estimation errors and diminished data utility. To address this problem, we propose two novel (ε,δ)-LDP algorithms for mean estimation. Specifically, we design a one-dimensional piecewise mean estimation algorithm, which perturbs the input data into intervals, thereby reducing noise addition and enhancing both accuracy and efficiency. Building on this foundation, we extend our approach to multi-dimensional data, resulting in a multi-dimensional piecewise mean estimation algorithm. Furthermore, we conduct a theoretical analysis to derive both the variance and error bounds for the proposed algorithms. Extensive experiments conducted on real datasets demonstrate the high practicality of our algorithms for data statistical tasks, showing significant improvements in data utility.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Privacy",
                "Protection",
                "Differential privacy",
                "Accuracy",
                "Perturbation methods",
                "Noise",
                "Estimation error",
                "Probabilistic logic",
                "Big Data",
                "Software algorithms"
            ],
            "Author Keywords": [
                "Privacy protection",
                "local differential privacy",
                "mean estimation",
                "data utility"
            ]
        },
        "Field": "data",
        "title": "Interval Mean Estimation Under (ε,δ)-Local Differential Privacy",
        "link": "https://ieeexplore.ieee.org/document/10742109/"
    },
    {
        "authors": [
            "Zisang Xu",
            "Ruirui Zhang",
            "Wei Liang",
            "Kuan-Ching Li",
            "Ke Gu",
            "Xiong Li",
            "Jialun Huang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Intelligent Vehicles ( Early Access )",
        "date_of_publication": "07 June 2024",
        "doi": "10.1109/TIV.2024.3411313",
        "publisher": "IEEE",
        "abstract": "Federated learning (FL) is widely used in various fields because it can guarantee the privacy of the original data source. However, in data-sensitive fields such as Internet of Vehicles (IoV), insecure communication channels, semi-trusted RoadSide Unit (RSU), and collusion between vehicles and the RSU may lead to leakage of model parameters. Moreover, when aggregating data, since different vehicles usually have different computing resources, vehicles with relatively insufficient computing resources will affect the data aggregation efficiency. Therefore, in order to solve the privacy leakage problem and improve the data aggregation efficiency, this paper proposes a privacy-preserving data aggregation protocol for IoV with FL. Firstly, the protocol is designed based on methods such as shamir secret sharing scheme, pallier homomorphic encryption scheme and blinding factor protection, which can guarantee the privacy of model parameters. Secondly, the protocol improves the data aggregation efficiency by setting dynamic training time windows. Thirdly, the protocol reduces the frequent participations of Trusted Authority (TA) by optimizing the fault-tolerance mechanism. Finally, the security analysis proves that the proposed protocol is secure, and the performance analysis results also show that the proposed protocol has high computation and communication efficiency.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Protocols",
                "Training",
                "Computational modeling",
                "Data models",
                "Data aggregation",
                "Privacy",
                "Fault tolerant systems"
            ],
            "Author Keywords": [
                "Internet of Vehicles",
                "Authentication",
                "Federated Learning",
                "Data Aggregation",
                "Privacy-Preserving"
            ]
        },
        "Field": "data",
        "title": "A Privacy-Preserving Data Aggregation Protocol for Internet of Vehicles with Federated Learning",
        "link": "https://ieeexplore.ieee.org/document/10552081/"
    },
    {
        "authors": [
            "Yourun Zhang",
            "Maoguo Gong",
            "Jianzhao Li",
            "Kaiyuan Feng",
            "Mingyang Zhang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )",
        "date_of_publication": "04 June 2024",
        "doi": "10.1109/TNNLS.2024.3400592",
        "publisher": "IEEE",
        "abstract": "The few-shot image classification task is to enable a model to identify novel classes by using only a few labeled samples as references. In general, the more knowledge a model has, the more robust it is when facing novel situations. Although directly introducing large amounts of new training data to acquire more knowledge is an attractive solution, it violates the purpose of few-shot learning with respect to reducing dependence on big data. Another viable option is to enable the model to accumulate knowledge more effectively from existing data, i.e., improve the utilization of existing data. In this article, we propose a new data augmentation method called self-mixup (SM) to assemble different augmented instances of the same image, which facilitates the model to more effectively accumulate knowledge from limited training data. In addition to the utilization of data, few-shot learning faces another challenge related to feature extraction. Specifically, existing metric-based few-shot classification methods rely on comparing the extracted features of the novel classes, but the widely adopted downsampling structures in various networks can lead to feature degradation due to the violation of the sampling theorem, and the degraded features are not conducive to robust classification. To alleviate this problem, we propose a calibration-adaptive downsampling (CADS) that calibrates and utilizes the characteristics of different features, which can facilitate robust feature extraction and benefit classification. By improving data utilization and feature extraction, our method shows superior performance on four widely adopted few-shot classification datasets.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Training",
                "Data models",
                "Testing",
                "Manifolds",
                "Data augmentation",
                "Task analysis"
            ],
            "Author Keywords": [
                "Data augmentation",
                "feature extraction",
                "few-shot learning",
                "image classification"
            ]
        },
        "Field": "data",
        "title": "Few-Shot Learning With Enhancements to Data Augmentation and Feature Extraction",
        "link": "https://ieeexplore.ieee.org/document/10547346/"
    },
    {
        "authors": [
            "Hoda Nemat",
            "Heydar Khadem",
            "Jackie Elliott",
            "Mohammed Benaissa"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Journal of Biomedical and Health Informatics ( Early Access )",
        "date_of_publication": "21 October 2024",
        "doi": "10.1109/JBHI.2024.3483999",
        "publisher": "IEEE",
        "abstract": "Blood glucose level (BGL) prediction contributes to more effective management of type 1 diabetes. Physical activity (PA) is a crucial factor in diabetes management. It affects BGL, and it is imperative to effectively deploy PA in BGL prediction to support diabetes management systems by incorporating this crucial factor. Due to the erratic nature of PA's impact on BGL inter- and intra-patients and insufficient knowledge, deploying PA in BGL prediction is challenging. Hence, optimal approaches for PA fusion with BGL are demanded to improve the performance of BGL prediction. To address this gap, we propose novel methodologies for extracting and integrating information from PA data into BGL prediction. This paper proposes several novel PA-informed prediction models by developing different approaches for extracting information from PA data and fusing this information with BGL data in signal, feature, and decision levels to find the optimal approach for deploying PA in BGL prediction models. For signal-level fusion, different automatically-recorded PA data are fused with BGL data. Also, three feature engineering approaches are developed for feature-level fusion: subjective assessments of PA, objective assessments of PA, and statistics of PA. Furthermore, in decision-level fusion, ensemble learning is used to combine predictions from models trained with different inputs. Then, a comparative investigation is performed between the developed PA-informed approaches and the no-fusion approach, as well as between themselves. The analyses are performed on the publicly available Ohio dataset with rigorous evaluation. The results show that deploying PA can statistically significantly improve BGL prediction performance. The results show that deploying PA can statistically significantly improve BGL prediction performance. Also, among the developed approaches to leveraging PA in BGL prediction, fusing heart rate data at the signal-level and PA intensity categories at the feature-level...",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Predictive models",
                "Data models",
                "Diabetes",
                "Autoregressive processes",
                "Heart rate",
                "Glucose",
                "Data integration",
                "Testing",
                "Blood",
                "Training"
            ],
            "Author Keywords": [
                "Data fusion",
                "Deep learning",
                "Diabetes management",
                "Ensemble learning",
                "Time series forecasting"
            ]
        },
        "Field": "data",
        "title": "Physical Activity Integration in Blood Glucose Level Prediction: Different Levels of Data Fusion",
        "link": "https://ieeexplore.ieee.org/document/10723305/"
    },
    {
        "authors": [
            "Xinyan Li",
            "Huimin Zhao",
            "Junjie Xu",
            "Guangtian Zhu",
            "Wu Deng"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Wireless Communications ( Early Access )",
        "date_of_publication": "18 October 2024",
        "doi": "10.1109/TWC.2024.3479149",
        "publisher": "IEEE",
        "abstract": "The sharing of flight operation data brings huge benefits to all participants, but for the privacy protection and data security, it is difficult to directly share flight operation data. Federated learning (FL) enables participants to jointly train machine learning models without exposing local data. However, due to the centralization of FL and the unreliability of FL participants, FL is vulnerable to malicious client and server attacks. In this paper, an anti-poisoning attack decentralized privacy enhanced federated learning (APDPFL) scheme is designed to mitigate the impact of server and malicious clients. Specifically, a local Rényi differential privacy is designed to protect client data privacy. Then, a verification method based on K-Means clustering is proposed to select models to participate in aggregation, which improves the anti-poisoning attack performance. Finally, a federated grouping practical Byzantine fault tolerance (FGPBFT) consensus algorithm based on consortium blockchain is proposed to dynamically change server and consensus clients, to decentralize server and improve the consensus efficiency. The theoretical analysis proves that the APDPFL achieves better convergence and provides data privacy protection and security protection. The experimental results on public datasets and flight operation datasets show that the APDPFL is robust and effective for sharing flight operation data.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Protection",
                "Blockchains",
                "Federated learning",
                "Differential privacy",
                "Servers",
                "Privacy",
                "Noise",
                "Data models",
                "Training",
                "Data security"
            ],
            "Author Keywords": [
                "Federated Learning",
                "Consortium Blockchain",
                "PBFT",
                "Rényi Differential Privacy",
                "Poisoning Attack",
                "Data Sharing"
            ]
        },
        "Field": "data",
        "title": "APDPFL: Anti-Poisoning Attack Decentralized Privacy Enhanced Federated Learning Scheme for Flight Operation Data Sharing",
        "link": "https://ieeexplore.ieee.org/document/10723242/"
    },
    {
        "authors": [
            "Kongyang Chen",
            "Wenfeng Wang",
            "Zixin Wang",
            "Yao Huang",
            "Yatie Xiao",
            "Wangjun Zhang",
            "Zhipeng Li",
            "Zhefei Guo",
            "Zhucheng Luo",
            "Lin Yin",
            "Haiyan Mai",
            "Xiaoying Wang",
            "Qintai Yang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Open Journal of the Communications Society ( Early Access )",
        "date_of_publication": "04 September 2024",
        "doi": "10.1109/OJCOMS.2024.3454247",
        "publisher": "IEEE",
        "abstract": "In next-generation wireless networks, distributed clients collaborate to achieve data perception, knowledge discovery, and model reasoning. Generally, Federated Contrastive Learning (FCL) represents an emerging approach for learning from decentralized unlabeled data while upholding data privacy. In FCL, participant clients collaborate in learning a global encoder using unlabeled data, which can serve as a versatile feature extractor for diverse downstream tasks. Nonetheless, FCL is susceptible to local data leakage risks, such as membership information leakage, stemming from its distributed nature, an aspect often overlooked in current solutions. This study delves into the feasibility of executing a membership information leakage on FCL and proposes a robust membership inference methodology. Our objective is to determine if the data signifies training member data by accessing the model’s inference output. Specifically, we concentrate on attackers situated within a client framework, lacking the capability to manipulate server-side aggregation methods or discern the training status of other clients. We introduce two membership inference attacks tailored for FCL: the passive membership inference attack and the active membership inference attack, contingent on the attacker’s involvement in local model training. Experimental findings across diverse datasets validate the effectiveness of our method and underscore the inherent local data risks associated with the FCL paradigm.",
        "issn": {
            "Electronic ISSN": "2644-125X"
        },
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Training",
                "Contrastive learning",
                "Distributed databases",
                "Data privacy",
                "Federated learning",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Unsupervised Learning",
                "Contrastive Learning",
                "Federated Learning",
                "Private Data Leakage"
            ]
        },
        "Field": "data",
        "title": "Private Data Leakage in Federated Contrastive Learning Networks",
        "link": "https://ieeexplore.ieee.org/document/10664466/"
    },
    {
        "authors": [
            "Shuihan Zhang",
            "Xiaolu Ji",
            "Wenxi Pei",
            "Yinhui Wu",
            "Chao Chen",
            "Fei Li",
            "Kejun Zhu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Nuclear Science ( Early Access )",
        "date_of_publication": "11 November 2024",
        "doi": "10.1109/TNS.2024.3495676",
        "publisher": "IEEE",
        "abstract": "The online data visualization system serves as a crucial component of the data acquisition system, providing swift, efficient, and comprehensive real-time monitoring of the readout chain. Simultaneously, ROOT, an open-source software framework widely used in high-energy physics, provides a variety of analytical tools. Using ROOT-based online histogram monitoring, researchers can efficiently analyze data in real time and detect potential anomalies promptly. To minimize development costs and enhance deployment efficiency, a general online data visualization system based on ROOT has been designed and implemented. This system consists of three main modules: a configuration module, a readout and decoding module, and a data display module. Each module features specific interfaces for seamless integration and expansion. Additionally, the system employs file-based configuration management for minimal modifications when adapting to different experiments. Currently, it supports data source interfaces for Redis and Kafka, as well as display interfaces for one-dimensional and two-dimensional histograms. The system has been successfully utilized in integration tests across various experiments, thereby enabling efficient and convenient data monitoring.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Monitoring",
                "Histograms",
                "Robots",
                "Soft sensors",
                "Decoding",
                "Data visualization",
                "Real-time systems",
                "Data acquisition",
                "System implementation",
                "Detectors"
            ],
            "Author Keywords": [
                "Data monitoring",
                "histogram",
                "real-time",
                "ROOT"
            ]
        },
        "Field": "data",
        "title": "A ROOT-based General Online Data Visualization System",
        "link": "https://ieeexplore.ieee.org/document/10750236/"
    },
    {
        "authors": [
            "Abubakar Sadiq Sani",
            "Dong Yuan",
            "George Loukas",
            "Zhao Yang Dong"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "11 November 2024",
        "doi": "10.1109/ACCESS.2024.3496258",
        "publisher": "IEEE",
        "abstract": "Recent findings show that many energy nodes rely on energy operators for inputs on energy operations. In this paper, we introduce UReum, a universally composable blockchain-enabled secure and privacy-preserving data awareness solution by which energy nodes can provide visibility into energy operations without involving or relying on energy operators and leaking sensitive information in the Energy Internet. In the energy ecosystem, Energy Internet represents an advanced internet-based energy system that aims to enable complex interconnection and interaction amongst energy nodes. UReum consists of a registration protocol ( RPro ) for assigning a cryptographic identity to an energy node and a data-aware protocol ( DAPro ) for executing data awareness with the support of a shared secret session key and UReum smart contracts, which facilitate data awareness consensus amongst energy nodes. UReum satisfies Energy Internet’s data awareness security and privacy requirements. The security requirements include correctness of data, assurance of energy node identity, and fairness of data awareness transactions such as energy node registration, while the privacy requirements include anonymity of energy node identity, the confidentiality of data, and unlinkability of data awareness transactions. We evaluate our model with respect to security, privacy, and performance, and the results show that our model is suitable for the Energy Internet. As a proof of concept, we apply our model to mitigate the loss of State Estimator (SE) and loss of Energy Management System (EMS) issues in real-world energy grids.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Energy Internet",
                "Data privacy",
                "Privacy",
                "Data models",
                "Smart grids",
                "Internet",
                "Elliptic curve cryptography",
                "Computational modeling",
                "Solid modeling",
                "Smart contracts"
            ],
            "Author Keywords": [
                "Data awareness",
                "energy internet",
                "privacy",
                "security",
                "universal composability"
            ]
        },
        "Field": "data",
        "title": "UReum: A Universally Composable Blockchain-enabled Model for Secure and Privacy-Preserving Data Awareness in Energy Internet",
        "link": "https://ieeexplore.ieee.org/document/10750173/"
    },
    {
        "authors": [
            "Mingwei Lin",
            "Jiaqi Liu",
            "Hong Chen",
            "Xiuqin Xu",
            "Xin Luo",
            "Zeshui Xu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Intelligent Transportation Systems ( Early Access )",
        "date_of_publication": "06 November 2024",
        "doi": "10.1109/TITS.2024.3486963",
        "publisher": "IEEE",
        "abstract": "Traffic data prediction is a crucial component of Intelligent Transport Systems (ITS) as it contributes significantly to real-time navigation and congestion management. However, due to incomplete deployment of sensor and instability of data transmission, the traffic data that we collect is usually a high-dimensional and incomplete (HDI) matrix or tensor. Currently, there are two challenges with traffic data prediction as follows: a) Most of the existing models are designed for a full set of data, but traffic data are unavoidably missing. b) Most of the existing models often suffer from excessive complexity due to long sequences. To address these issues, we propose a novel 3D C onvolution- I ncorporated D imension P reserved Decomposition (3DCIDP) model for traffic data prediction with three main fold ideas: a) enhancing the low-rank property of traffic data to accurately capture its structure, b) learning the constraints of historical sequences to predict sequences through representation modelling and c) capturing spatio-temporal interaction information in traffic data through multidimensional interaction features. To evaluate the performance of the proposed 3DCIDP, we conduct extensive experiments using five publicly available datasets with three different missing rates. When the proposed 3DCIDP is compared to state-of-the-art models, experimental results show that the Root Mean Square Error (RMSE) is reduced by an average of 4.22% and the training time is reduced by an average of 89.76% on the large-scale traffic datasets.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Predictive models",
                "Feature extraction",
                "Roads",
                "Three-dimensional displays",
                "Solid modeling",
                "Data mining",
                "Accuracy",
                "Complexity theory",
                "Tensors"
            ],
            "Author Keywords": [
                "Traffic tensor representation",
                "high-dimensional and incomplete data",
                "dimension preserved decomposition",
                "low rank approximation",
                "3D convolution"
            ]
        },
        "Field": "data",
        "title": "A 3D Convolution-Incorporated Dimension Preserved Decomposition Model for Traffic Data Prediction",
        "link": "https://ieeexplore.ieee.org/document/10745874/"
    },
    {
        "authors": [
            "Yifan Hong",
            "Chuanqi Shi",
            "Junyang Chen",
            "Huan Wang",
            "Di Wang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Computational Social Systems ( Early Access )",
        "date_of_publication": "04 September 2024",
        "doi": "10.1109/TCSS.2024.3442238",
        "publisher": "IEEE",
        "abstract": "Few-shot anomalous node detection in dynamic networks has been extensively investigated in the field of research. In this few-shot scenario, the detection of these anomalous nodes is particularly challenging due to the continuously evolving network topology and data distribution over time, which is known as concept drift. Concept drift refers to the phenomenon where the underlying concepts or patterns in the data generation process change over time, leading to varying data distributions across different periods. Due to these changes in data distribution, the patterns learned during training may become invalid under the new data distribution. Existing models primarily aim to enhance the representation of evolving node attributes and relationships to mitigate the impact of concept drift in few-shot scenarios. However, the scarcity of anomalous samples further limits the model’s ability to learn new patterns, thereby reducing its effectiveness in addressing concept drift in few-shot scenarios. To address this challenge, we propose the multitask asynchronous metalearning framework (MAMF), which aims to mitigate bias induced by concept drift in few-shot anomalous node detection. Our framework consists of four main components: a feature extractor, an anomaly simulator, an asynchronous learner, and a type detector. The feature extractor captures the relative variations of each node in an evolving graph stream. The anomaly simulator uses generative adversarial models to learn anomaly distributions and generate samples at different time intervals. The asynchronous learner samples from various time distributions to create metatasks for anomalous node detection, allowing it to adapt to changes between these distributions. To aid in few-shot anomalous node detection, the type detector is used for anomaly type recognition. Our framework achieves AUC improvements of 5.12%, 6.87%, and 1.91% over the best existing methods on Wikipedia, Reddit, and Mooc datasets, respectively, demon...",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Concept drift",
                "Adaptation models",
                "Metalearning",
                "Data models",
                "Feature extraction",
                "Anomaly detection",
                "Training data"
            ],
            "Author Keywords": [
                "Anomalous node detection",
                "concept drift",
                "graph neural networks",
                "metalearning",
                "multitask learning"
            ]
        },
        "Field": "data",
        "title": "Multitask Asynchronous Metalearning for Few-Shot Anomalous Node Detection in Dynamic Networks",
        "link": "https://ieeexplore.ieee.org/document/10664616/"
    },
    {
        "authors": [
            "Yuhang Zhang",
            "Yongfu Li",
            "Stephen Makonin",
            "Rakesh Kumar"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Data Descriptions ( Early Access )",
        "date_of_publication": "15 October 2024",
        "doi": "10.1109/IEEEDATA.2024.3480012",
        "publisher": "IEEE",
        "abstract": "The IEEE Xplore database is vital in democratizing access to high-quality research datasets, fostering global collaboration, and promoting interdisciplinary studies. Insights from the IEEE Xplore database support applications in academic collaboration networks, predictive research trends, recommendation systems, and the evolution of scientific discourse. It is downloaded using web data mining methods, such as HTTP requests, web scraping with Selenium, and LXML parsing with BeautifulSoup. These various methods are discussed for their efficiency and complexity. As a means of ensuring the quality of these datasets, we propose the use of cross-repository validation. Source codes and scripts for data collection are provided to promote transparency and reproducibility.",
        "issn": {
            "Electronic ISSN": "2995-4274"
        },
        "keywords": {
            "IEEE Keywords": [
                "Libraries",
                "HTTP",
                "Databases",
                "Data mining",
                "Data collection",
                "Selenium",
                "Metadata",
                "Collaboration",
                "Browsers",
                "Crawlers"
            ],
            "Author Keywords": [
                "IEEExplorer",
                "Open-Source",
                "Electrical Engineering",
                "Computer Science",
                "Academic Research"
            ]
        },
        "Field": "data",
        "title": "Descriptor: Comprehensive IEEE Research Data Collections (CIRDC)",
        "link": "https://ieeexplore.ieee.org/document/10716731/"
    },
    {
        "authors": [
            "Qiyang Chen",
            "Han Li",
            "Linlin You",
            "Haohao Qu",
            "Ahmed M. Abdelmoniem",
            "Chau Yuen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Big Data ( Early Access )",
        "date_of_publication": "22 October 2024",
        "doi": "10.1109/TBDATA.2024.3484651",
        "publisher": "IEEE",
        "abstract": "Electric vehicles (EVs) are driving green and low-carbon transport in modern cities. It makes charging station occupancy prediction (CSOP) critual for intelligent transportation systems (ITS) to achieve a balance between the supply and demand in resolving the dynamics between EVs and changing stations. Even though several big data-based solutions have been discussed, they are still struggling to collaboratively utilize heterogeneous data and distributed computing resources located at both physically and logicially isolated charging stations to better support context-driven CSOP. To addres this challenge, we propose an Asynchronous Federated Meta-learning Mechanism (AFML) for CSOP, which can train a meta-model with strong adaptation ability in an asynchronous and collaborative manner. In general, it incorporates an adaptive reptile algorithm (AR) and an weighted aggregation strategy (WA) to jointly ensure the training efficiency and model adaptivity. Evaluations on real-world CSOP datasets demonstrate that compared to the second best method, AFML can significantly improve forecasting accuracy by 14%, accelerate model convergence by 9% and enhance model generalizability by 10%, illustrating its merits in support CSOP to embrace a smart and sustainable city.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Adaptation models",
                "Charging stations",
                "Training",
                "Data models",
                "Metalearning",
                "Predictive models",
                "Computational modeling",
                "Distributed databases",
                "Federated learning",
                "Big Data"
            ],
            "Author Keywords": [
                "Asynchronous Federated Learning",
                "Charging Station Occupancy Prediction",
                "Federated Meta-learning",
                "Intelligent Transportation System"
            ]
        },
        "Field": "data",
        "title": "AFML: An Asynchronous Federated Meta-Learning Mechanism for Charging Station Occupancy Prediction with Biased and Isolated Data",
        "link": "https://ieeexplore.ieee.org/document/10726793/"
    },
    {
        "authors": [
            "Peng Fang",
            "Zhenli Li",
            "Arijit Khan",
            "Siqiang Luo",
            "Fang Wang",
            "Zhan Shi",
            "Dan Feng"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Knowledge and Data Engineering ( Early Access )",
        "date_of_publication": "05 July 2024",
        "doi": "10.1109/TKDE.2024.3424333",
        "publisher": "IEEE",
        "abstract": "Graph embedding maps graph nodes to low-dimensional vectors and is widely used in machine learning tasks. The increasing availability of billion-edge graphs underscores the importance of learning efficient and effective embeddings on large graphs, such as link prediction on Twitter with over one billion edges. Most existing graph embedding methods fall short of reaching high data scalability. In this paper, we present a general-purpose, distributed, information-centric random walk-based, and pipeline-optimized graph embedding framework, {\\sf DistGER-Pipe}\n, which scales to embed billion-edge graphs. {\\sf DistGER-Pipe}\nincrementally computes information-centric random walks to reduce redundant computations for more effective and efficient graph embedding. It further leverages a multi-proximity-aware, streaming, parallel graph partitioning strategy, simultaneously achieving high local partition quality and excellent workload balancing across machines. {\\sf DistGER-Pipe}\nalso improves the distributed {\\sf Skip-Gram}\nlearning model to generate node embeddings by optimizing access locality, CPU throughput, and synchronization efficiency. Finally, {\\sf DistGER-Pipe}\ndesigns pipelined execution that decouples the operators in sampling and training procedures with an inter-round serial and intra-round parallel processing, attaining optimal utilization of computing resources. Experiments on real-world graphs demonstrate that compared to state-of-the-art distributed graph embedding frameworks, including {\\sf KnightKing}\n, {\\sf DistDGL}\n, {\\sf Pytorch-BigGraph}\n, and {\\sf DistGER}\n, {\\sf DistGER-Pipe}\nexhibits 3.15×–1053× acceleration, 45% reduction in cross-machines communication, \\gt\n10% effectiveness improvement in downstream tasks, and 38% enhancement in CPU utilization.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Scalability",
                "Computational modeling",
                "Vectors",
                "Synchronization",
                "Servers",
                "Pipelines"
            ],
            "Author Keywords": [
                "Distributed graph embedding",
                "Information-centric",
                "Pipeline execution"
            ]
        },
        "Field": "data",
        "title": "Information-Oriented Random Walks and Pipeline Optimization for Distributed Graph Embedding",
        "link": "https://ieeexplore.ieee.org/document/10587087/"
    },
    {
        "authors": [
            "Xiangrui Xu",
            "Wei Wang",
            "Zheng Chen",
            "Bin Wang",
            "Chao Li",
            "Li Duan",
            "Zhen Han",
            "Yufei Han"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Dependable and Secure Computing ( Early Access )",
        "date_of_publication": "19 August 2024",
        "doi": "10.1109/TDSC.2024.3445600",
        "publisher": "IEEE",
        "abstract": "Vertical Federated Learning (VFL) is a collaborative learning paradigm where participants share the same sample space while splitting the feature space. In VFL, local participants host their bottom models for feature extraction and collaboratively train a classifier by exchanging intermediate results with the server owning the labels. Both local training data and bottom models contain privacy-sensitive information and are considered the intellectual property of each participant, and thus should be protected by the design of VFL. Our study exposes the fundamental susceptibility of VFL systems to privacy leaks, which arise from the collaboration between the server and clients during both training and testing. Based on our findings, we propose PISTE , a model-agnostic framework of privacy stealing attacks against VFL. PISTE delivers three privacy inference attacks, i.e., model stealing, data reconstruction, and property inference attacks on five benchmark datasets and four different model architectures. We further discuss four potential countermeasures. Experimental results show that all of them cannot prevent all three privacy stealing attacks in PISTE. In summary, our study demonstrates the inherent yet rarely uncovered vulnerability of VFL on leaking data and model privacy.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Training",
                "Training data",
                "Servers",
                "Data privacy",
                "Testing",
                "Privacy"
            ],
            "Author Keywords": [
                "Vertical Federated Learning",
                "Model Stealing",
                "Data Reconstruction",
                "Property Inference"
            ]
        },
        "Field": "data",
        "title": "Finding the PISTE: Towards Understanding Privacy Leaks in Vertical Federated Learning Systems",
        "link": "https://ieeexplore.ieee.org/document/10639355/"
    },
    {
        "authors": [
            "Ikram Ud Din",
            "Ahmad Almogren",
            "Joel J. P. C. Rodrigues",
            "Ayman Altameem"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Consumer Electronics ( Early Access )",
        "date_of_publication": "03 July 2024",
        "doi": "10.1109/TCE.2024.3422788",
        "publisher": "IEEE",
        "abstract": "This study investigates the integration and utilization of diverse data forms within consumer electronics, with a particular emphasis on Internet of Things (IoT) technologies. We introduce innovative data fusion techniques designed to enhance decision-making precision in IoT-enabled consumer electronics. While our findings are relevant not only for assessing consumer electronics for commercial purposes but also for individual use, the present study focuses on the commercial aspect of consumption. In this paper, we discuss and demonstrate how these techniques can be employed in wearables, smart home systems and in other IoT deployments and draw out their implications on user engagement and more specific services. Our findings show a substantial increase in accuracy when using video data posts to perform sentimental analysis with an average of 83% followed by the text with an average of 78 % and by audio with an average of 65 %. Emotion recognition accuracy also varied, with the model performing best for surprise (85%) and happiness (80%). In addition, it found that the CNN model is slightly superior to the LSTM model in terms of accuracy (68% vs. 78%), F1-score (0. 62 vs. 0. 77). These results prove that composite data analysis is efficient in improving decision-making processes. Finally, the study looks at the ethical concerns that could be relevant to the recommended site, especially with regard to data privacy and protection. From our analysis, we clearly see great improvements in decision making phases, the areas that could be explored in future concerning the prospects of multimodal data in consumer electronics.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Consumer electronics",
                "Feature extraction",
                "Decision making",
                "Data integration",
                "Complexity theory",
                "Internet of Things",
                "Ethics"
            ],
            "Author Keywords": [
                "Integrative Multimodal Data",
                "Consumer Electronics",
                "Advanced Data Fusion",
                "Machine Learning Applications",
                "Decision-Making"
            ]
        },
        "Field": "data",
        "title": "Advancing Secure and Privacy-Preserved Decision-Making in IoT-Enabled Consumer Electronics via Multimodal Data Fusion",
        "link": "https://ieeexplore.ieee.org/document/10584094/"
    },
    {
        "authors": [
            "Mayank V. Golhar",
            "Taylor L. Bobrow",
            "Saowanee Ngamruengphong",
            "Nicholas J. Durr"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Journal of Biomedical and Health Informatics ( Early Access )",
        "date_of_publication": "07 May 2024",
        "doi": "10.1109/JBHI.2024.3397611",
        "publisher": "IEEE",
        "abstract": "A major challenge in applying deep learning to medical imaging is the paucity of annotated data. This study explores the use of synthetic images for data augmentation to address the challenge of limited annotated data in colonoscopy lesion classification. We demonstrate that synthetic colonoscopy images generated by Generative Adversarial Network (GAN) inversion can be used as training data to improve polyp classification performance by deep learning models. We invert pairs of images with the same label to a semantically rich and disentangled latent space and manipulate latent representations to produce new synthetic images. These synthetic images maintain the same label as the input pairs. We perform image modality translation (style transfer) between white light and narrow-band imaging (NBI). We also generate realistic synthetic lesion images by interpolating between original training images to increase the variety of lesion shapes in the training dataset. Our experiments show that GAN inversion can produce multiple colonoscopy data augmentations that improve the downstream polyp classification performance by 2.7% in F1-score and 4.9% in sensitivity over other methods, including state-of-the-art data augmentation. Testing on unseen out-of-domain data also showcased an improvement of 2.9% in F1-score and 2.7% in sensitivity. This approach outperforms other colonoscopy data augmentation techniques and does not require re-training multiple generative models. It also effectively uses information from diverse public datasets, even those not specifically designed for the targeted downstream task, resulting in strong domain generalizability. Project code and model: https://github.com/DurrLab/GAN-Inversion .",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Colonoscopy",
                "Codes",
                "Generative adversarial networks",
                "Training",
                "Lesions",
                "Imaging",
                "Data augmentation"
            ],
            "Author Keywords": [
                "GAN inversion",
                "Data Augmentation",
                "Colonoscopy",
                "Domain Generalization",
                "Synthetic Data",
                "Polyp Classification",
                "Generative Models"
            ]
        },
        "Field": "data",
        "title": "GAN Inversion for Data Augmentation to Improve Colonoscopy Lesion Classification",
        "link": "https://ieeexplore.ieee.org/document/10521726/"
    },
    {
        "authors": [
            "Mohammad Manzurul Islam",
            "Gour Karmakar",
            "Joarder Kamruzzaman",
            "Manzur Murshed",
            "Abdullahi Chowdhury"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "12 September 2024",
        "doi": "10.1109/JIOT.2024.3459477",
        "publisher": "IEEE",
        "abstract": "Image sensors deployed in the Internet of Things (IoT) generate vast volumes of digital images. These images may be subject to deliberate alteration, compromising their trustworthiness. Estimating the trustworthiness of this image data is crucial for many applications; however, this aspect has not been adequately explored in the existing literature. In this paper, we propose a robust and real-time trust estimation framework for IoT image data, leveraging numeric data generated from other types of sensors deployed in the same area of interest (AoI). The theoretical model was developed using statistical approaches, and Shannons entropy was employed to measure the uncertainty associated with sensor readings during a specific event. Later, we applied Dempster-Shafer theory (DST) of combination to fuse information collected from image as well as numeric data-generating sensors where both types of sensors were observing the same event in the same AoI concomitantly. To evaluate the proposed framework, we implemented an IoT testbed using LoRa sensor nodes, edge devices, a LoRaWAN gateway, the Things Network (TTN), and a data analytics server. The testbed was used to collect observation data of a fire event using image and temperature sensors in an indoor residential setup in different conditions. Consequently, eight datasets (four authentic and four hacked) were built, each containing both image and temperature data readings under various scenarios. The proposed trust framework accurately estimated the trust score of images (91% overall accuracy) across all datasets and outperformed existing trust models.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Sensors",
                "Internet of Things",
                "Image sensors",
                "Data models",
                "Correlation",
                "Uncertainty",
                "Temperature sensors"
            ],
            "Author Keywords": [
                "Internet of Things",
                "trust",
                "trustworthiness",
                "image sensor data",
                "temperature sensor data",
                "multimodal fusion"
            ]
        },
        "Field": "data",
        "title": "Trustworthiness of IoT Images Leveraging With Other Modal Sensor’s Data",
        "link": "https://ieeexplore.ieee.org/document/10679141/"
    },
    {
        "authors": [
            "Chen Xu",
            "Qiang Wang",
            "Wenqi Zhang",
            "Chen Sun"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Intelligent Transportation Systems ( Early Access )",
        "date_of_publication": "29 August 2024",
        "doi": "10.1109/TITS.2024.3447549",
        "publisher": "IEEE",
        "abstract": "As an important research field in time series processing, traffic prediction has a profound impact on people’s daily lives and social development. Conventional traffic prediction relies on complete observation data. However, data missing is common in cities due to equipment failure, network interruption, etc., which poses a huge obstacle to traffic prediction. In this paper, we design a novel Spatiotemporal Ego-graph Domain Adaptation framework (SEDA) to predict traffic state in data missing scenarios. Based on the multi-dimensional topological information of local network (ego-graph), isomorphic ego-graphs are aligned across the missing data in target domain and the external data in source domain to obtain alternative data. Furthermore, a Dual-branch Cross reCoupling method (DCC) is proposed to reconstruct missing features according to the alternative data. Experimental results on real public datasets with 10%-40% missing show that SEDA averagely outperforms both the state-of-the-art knowledge transfer-based prediction baselines and the incomplete data prediction baselines by more than 0.45% and 0.86%. Ablation experiments and visualization analysis further demonstrate the effectiveness of SEDA components.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Adaptation models",
                "Predictive models",
                "Data models",
                "Tensors",
                "Spatiotemporal phenomena",
                "Roads",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Traffic prediction",
                "spatiotemporal data modeling",
                "traffic data missing",
                "domain adaptation"
            ]
        },
        "Field": "data",
        "title": "Spatiotemporal Ego-Graph Domain Adaptation for Traffic Prediction With Data Missing",
        "link": "https://ieeexplore.ieee.org/document/10659139/"
    },
    {
        "authors": [
            "Murtadha D. Hssayeni",
            "Behnaz Ghoraani"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Emerging Topics in Computational Intelligence ( Early Access )",
        "date_of_publication": "19 March 2024",
        "doi": "10.1109/TETCI.2024.3372435",
        "publisher": "IEEE",
        "abstract": "During the collection of time-series data, many reasons lead to imbalanced and incomplete datasets. Consequently, it becomes challenging to develop deep convolutional models without suffering from overfitting. Our objective in this paper was to investigate an emerging but rather underutilized framework of Conditional Generative Adversarial Networks (cGANs) for improving deep regression models for time-series data with an imbalanced and incomplete distribution. First, we investigated the potential of using a vanilla cGAN as a data imputation to improve the generalizability of the developed models to unseen data in such datasets. Next, we proposed a modified cGAN architecture with improved extrapolation and generalizability of the regression models. Our investigations used an imbalanced synthetic non-stationary dataset, a real-world dataset in Parkinson's disease (PD) application domain, and one publicly-available dataset for Negative Affect (NA) estimation. We found that vanilla cGAN failed to generate realistic time-series data due to severe mode collapse, limiting its application as a data imputation for imbalanced and incomplete data. Importantly, the proposed cGAN framework significantly improved extrapolation and generalizability for the prediction of regression scores with an average improvement of 56%, 34%, and 18%, respectively, in mean absolute error for the synthetic, PD, and NA datasets when compared with traditional Convolutional Neural Networks. The codes are publicly available on Github.",
        "issn": {
            "Electronic ISSN": "2471-285X"
        },
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Generators",
                "Training",
                "Convolution",
                "Convolutional neural networks",
                "Testing",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Deep regression modeling",
                "time-series data",
                "generative adversarial networks",
                "imbalanced and incomplete data",
                "extrapolation"
            ]
        },
        "Field": "data",
        "title": "Deep Regression Modeling for Imbalanced and Incomplete Time-Series Data",
        "link": "https://ieeexplore.ieee.org/document/10475374/"
    },
    {
        "authors": [
            "Liang Zhou",
            "Zhongqi Li",
            "Hui Yang",
            "Chang Tan",
            "Yating Fu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Automation Science and Engineering ( Early Access )",
        "date_of_publication": "20 March 2024",
        "doi": "10.1109/TASE.2024.3373037",
        "publisher": "IEEE",
        "abstract": "In this study, a novel data-driven discrete-time sliding mode control (DSMC) approach is designed for an electric multiple unit (EMU) velocity tracking control system. First, the input/output (I/O) data of the EMU are equivalently modeled as a full-format dynamic linearized (FFDL) data model to facilitate the generation of a data-driven control scheme. Subsequently, a discrete terminal sliding mode function and a new hyperbolic reaching-law are introduced to simultaneously achieve fast convergence and alleviate chattering. Based on the designed sliding mode function and reaching-law, an improved discrete-time terminal sliding mode control (iDTSMC) approach is derived using the FFDL model. The proposed approach considers the error feedback, parameter estimation errors, and total uncertainties for compensation, to achieve better control performance. The key advantages of this approach include its sole utilization of input-output data from the EMU system, low controller order, robust parameter adaptability, and anti-interference capabilities. After providing the stability analysis of the proposed method, the iDTSMC scheme is compared and tested on a simulated CRH380A high-speed train experimental platform in a laboratory. The simulation results show that the velocity tracking errors of each power unit of the EMU under the proposed control scheme are within $-$ 0.112 km/h, 0.118 km/h, and the control forces and accelerations are within $-$ 51 kN, 43 kN and $-$ 0.952 m/s $^2$ , 0.827 m/s $^2$ , respectively, with stable fluctuations. Comparative experimental results demonstrate the effectiveness and superiority of the proposed strategy, which remains robust in the presence of disturbances. Note to Practitioners —This study is inspired by the problem of EMU operation control, however, it is also applicable to other systems with trajectory tracking characteristics. Existing automatic train driving control methods are usually based on a dynamics model of the t...",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Sliding mode control",
                "Adaptation models",
                "Force",
                "Mathematical models",
                "Uncertainty",
                "Safety"
            ],
            "Author Keywords": [
                "Electric multiple unit",
                "discrete terminal sliding mode control",
                "quasi-sliding mode",
                "data driven control",
                "full-format data model"
            ]
        },
        "Field": "data",
        "title": "Adaptive Terminal Sliding Mode Control for High-Speed EMU: A MIMO Data-Driven Approach",
        "link": "https://ieeexplore.ieee.org/document/10477325/"
    },
    {
        "authors": [
            "Xinhua Cui",
            "Youliang Tian",
            "Xinyu Zhang",
            "HongWei Lin",
            "Mengqian Li"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "28 October 2024",
        "doi": "10.1109/JIOT.2024.3479219",
        "publisher": "IEEE",
        "abstract": "In edge computing environments, the rapid growth of Internet of Things (IoT) devices presents significant challenges for data processing. These devices are often resource-constrained, eading to a trade-off between achieving efficiency and ensuring security. On one hand, traditional certificateless encryption methods are computationally expensive; on the other hand, offloading the computational load to third-party entities can enhance efficiency but still introduces security risks. To address these issues, this paper proposes a novel lightweight certificateless edge-assisted encryption scheme (CL-EAED). Ours scheme offloads computationally intensive tasks to edge servers, ensuring that edge-assisted processing does not expose sensitive information and only needs to be performed once. This approach effectively prevents data leakage and enhances both the efficiency and security of task offloading. Moreover, the CL-EAED scheme achieves IND-CCA security in standard model (SM) and has been validated using the ProVerif tool. Experimental evaluations demonstrate that CL-EAED eliminates the dependency on computationally intensive pairing operations, significantly reducing computational and communication costs. It outperforms existing solutions in terms of energy consumption, latency, and scalability, fully meeting the requirements of practical applications.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Encryption",
                "Internet of Things",
                "Data processing",
                "Performance evaluation",
                "Cryptography",
                "Computational modeling",
                "Edge computing",
                "Servers",
                "Scalability",
                "Real-time systems"
            ],
            "Author Keywords": [
                "Certificateless cryptography",
                "Internet of Thing (IoT)",
                "edge-assisted",
                "lightweight",
                "resource-constrained",
                "IoT Devices",
                "standard model"
            ]
        },
        "Field": "data",
        "title": "A Lightweight Certificateless Edge-Assisted Encryption for IoT Devices: Enhancing Security and Performance",
        "link": "https://ieeexplore.ieee.org/document/10736996/"
    },
    {
        "authors": [
            "Somayye Rostami",
            "Douglas G. Down",
            "George Karakostas"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Automation Science and Engineering ( Early Access )",
        "date_of_publication": "06 May 2024",
        "doi": "10.1109/TASE.2024.3395471",
        "publisher": "IEEE",
        "abstract": "With the current high levels of energy consumption of data centers, reducing power consumption by even a small percentage is beneficial. We propose a framework for thermal-aware workload distribution in a data center to reduce cooling power consumption. The framework includes linearization of the general optimization problem and proposing a heuristic to approximate the solution for the resulting Mixed Integer Linear Programming (MILP) problems. We first define a general nonlinear power optimization problem including several cooling parameters, heat recirculation effects, and constraints on server temperatures. We propose to study a linearized version of the problem, which is easier to analyze. As an energy saving scenario and as a proof of concept for our approach, we also consider the possibility that the red-line temperature for idle servers is higher than that for busy servers. For the resulting MILP problem, we propose a heuristic for intelligent rounding of the fractional solution. Through numerical simulations, we compare our heuristics with several existing algorithms. In addition, we evaluate the performance of the solution of the linearized system on the original system. Finally, the results show that the proposed approach can reduce the cooling power consumption by more than 10 percent compared to the case of continuous utilizations and a single red-line temperature. Note to Practitioners —We present a holistic approach for thermal-aware workload distribution for power consumption reduction in data centers. We suggest that when thermal and power consumption models can be linearized, a model-independent approach can be used for optimization purposes. The standard linear problem that results presents some technical challenges to solve, for which we present intuitive and effective solution heuristics. The heuristics are simple enough that they could be used for real-time calculations. The result is that customized models and problems can be avoided (a linear...",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Servers",
                "Power demand",
                "Data centers",
                "Cooling",
                "Optimization",
                "Data models",
                "Temperature distribution"
            ],
            "Author Keywords": [
                "Data center",
                "thermal-aware workload distribution",
                "integer programming",
                "linearization",
                "cooling power consumption",
                "red-line temperatures"
            ]
        },
        "Field": "data",
        "title": "Linearized Data Center Workload and Cooling Management",
        "link": "https://ieeexplore.ieee.org/document/10520293/"
    },
    {
        "authors": [
            "Jiwon Jung",
            "Dyan Puspita Apsari",
            "Dong-Choon Lee"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Power Electronics ( Early Access )",
        "date_of_publication": "31 October 2024",
        "doi": "10.1109/TPEL.2024.3488094",
        "publisher": "IEEE",
        "abstract": "This paper proposes a novel real-time fault diagnosis approach for three-level neutral-clamped inverters based on a 1-D convolutional neural network (CNN). The proposed method incorporates data augmentation into simulation data, enhancing the generalization capabilities of deep learning models. This allows fault diagnostic models to have high robustness even in untrained system conditions. In such scenarios, the application of 1-D CNN models with data augmentation surpasses the performance of the same models without the incorporation of white noise, resulting in accuracy improvements of up to 1.71%. Furthermore, deep learning models trained on simulation data with data augmentation give a better performance when compared to those trained using experiment data. The proposed method has been verified through simulation with offline testing and experimentation with real-time deep learning algorithms.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Inverters",
                "Switches",
                "Fault diagnosis",
                "Circuit faults",
                "Convolutional neural networks",
                "Data models",
                "Data augmentation",
                "White noise",
                "Real-time systems",
                "Accuracy"
            ],
            "Author Keywords": [
                "CNN",
                "Data augmentation",
                "Fault diagnosis",
                "Three-level NPC inverter",
                "White noise injection"
            ]
        },
        "Field": "data",
        "title": "Robust Open-Switch Fault Diagnosis of Three-Level NPC Inverters Based on Data Augmentation with White Noise Injection",
        "link": "https://ieeexplore.ieee.org/document/10740557/"
    },
    {
        "authors": [
            "Lin Hu",
            "Feifan Yang",
            "Xinghua Wang",
            "Ziwei Wang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Intelligent Vehicles ( Early Access )",
        "date_of_publication": "18 October 2024",
        "doi": "10.1109/TIV.2024.3483847",
        "publisher": "IEEE",
        "abstract": "In the Chinese traffic system, a crucial role is played by two-wheelers (TWs), yet significant road safety challenges are posed by them, with many TW drivers being killed or injured in traffic accidents annually. With the rapid advancement of autonomous driving technology, it is becoming feasible to reduce such accidents and minimize the number of casualties. Understanding accident scenarios is pivotal for developing and testing autonomous driving technologies. To ensure the reliability of these technologies, especially in the Chinese traffic environment, a method combining textual and numerical multimodal data is proposed based on the China In-Depth Accident Study (CIDAS) database. The total of 2,463 cases of vehicle-to-TW crashes are selected from the CIDAS database, and thorough extraction and analysis of textual and numerical data are conducted. The use of a Latent Dirichlet Allocation (LDA) topic analysis model based on Term Frequency Inverse Document Frequency (TF-IDF) effectively mines and understands driver behavior information from textual data. This information not only provides robust data support for understanding accident causes but also integrates subjective driver behaviors with objective road environment information in accident scenario generation for the first time. Finally, the integrated textual and numerical data undergo cluster analysis using spectral clustering algorithms, identifying six typical pre-crash scenarios between vehicles and TWs. Compared to traditional studies on generating traffic accident scenarios, this research not only offers deeper insights into driver behavior but also provides essential foundations for selecting typical scenarios and diversifying sources of scenario information for testing autonomous vehicles.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Accidents",
                "Safety",
                "Autonomous vehicles",
                "Data models",
                "Data mining",
                "Databases",
                "Accuracy",
                "Testing",
                "Scenario generation",
                "Encoding"
            ],
            "Author Keywords": [
                "two-wheelers",
                "accident scenarios",
                "multimodal data",
                "driver behavior",
                "cluster analysis"
            ]
        },
        "Field": "data",
        "title": "Generation of two-wheeler accident pre-crash scenarios based on multimodal data",
        "link": "https://ieeexplore.ieee.org/document/10723257/"
    },
    {
        "authors": [
            "Kavitha Dhanushkodi",
            "Akila Bala",
            "Nithin Kodipyaka",
            "V Shreyas"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "30 May 2024",
        "doi": "10.1109/ACCESS.2024.3407151",
        "publisher": "IEEE",
        "abstract": "In the dynamic landscape of supermarket retail, understanding customer behavior is paramount for optimizing business strategies and enhancing profitability. This paper presents a comprehensive data mining approach to analyze customer behavior and build predictive models within the supermarket retail domain. Leveraging advanced data analytics techniques, our methodology encompasses data preprocessing, exploratory data analysis, feature engineering, model selection, and evaluation. This paper presents a comprehensive approach to customer behavior analysis and predictive modelling within the context of supermarket retail. We delve into the intricacies of data mining methodologies, exploring how retailers can leverage diverse datasets to uncover valuable insights and build predictive models that drive business growth and customer satisfaction. From data preprocessing to model evaluation, each step in the process is meticulously examined, highlighting best practices and key considerations for effective implementation.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Data mining",
                "Data models",
                "Analytical models",
                "Predictive models",
                "Business",
                "Banking",
                "Industries",
                "Sequential analysis",
                "Consumer behavior",
                "Behavioral sciences",
                "Market research"
            ],
            "Author Keywords": [
                "Customer behavior analysis",
                "Data mining",
                "Predictive modelling",
                "Retail",
                "Sequential pattern mining"
            ]
        },
        "Field": "data",
        "title": "Customer Behaviour Analysis and Predictive Modelling in Supermarket Retail: A Comprehensive Data Mining Approach",
        "link": "https://ieeexplore.ieee.org/document/10542125/"
    },
    {
        "authors": [
            "Junhao Feng",
            "Boyang Huang",
            "Xiaodong Zhou",
            "Xin Jin"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Consumer Electronics ( Early Access )",
        "date_of_publication": "02 April 2024",
        "doi": "10.1109/TCE.2024.3384438",
        "publisher": "IEEE",
        "abstract": "To ensure the large-scale integration of distributed photovoltaic (PV) into power system, it is imperative to collect and aggregate real-time operational data. However, the substantial volume of data imposes significant stress on cloud-edge collaborative framework and multimodal networking integrated with power line communication (PLC) and high-speed radio frequency (HRF) communication, resulting in large delay and poor transmission reliability. In this paper, we formulate an optimization problem to minimize the weighted sum of information aggregation delay and packet error rate by jointly optimizing data compression and routing selection. We propose a large-scale multi-agent learning-based two-stage service priority and compression speed-aware data compression and information aggregation joint optimization algorithm to address the problem. The proposed algorithm augments conventional ant colony method with Q-learning to enhance the learning capability under large-scale complex dynamic systems. Furthermore, the incorporation of service priority and data compression speed awareness leads to improved convergence speed. Finally, through simulation verification, we demonstrate that the proposed algorithm outperforms existing methods.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data compression",
                "Delays",
                "Routing",
                "Power systems",
                "Data communication",
                "Consumer electronics",
                "Reliability"
            ],
            "Author Keywords": [
                "distributed PV",
                "cloud-edge collaboration",
                "data compression",
                "information aggregation",
                "large-scale multi-agent reinforcement learning",
                "multimodal network"
            ]
        },
        "Field": "data",
        "title": "Large-Scale Multi-Agent Learning-Based Cloud-Edge Collaborative Distributed PV Data Compression and Information Aggregation for Multimodal Network in Power Systems",
        "link": "https://ieeexplore.ieee.org/document/10488475/"
    },
    {
        "authors": [
            "Licheng Liu",
            "Junhao Chen",
            "Tingyun Liu",
            "C. L. Philip Chen",
            "Bin Yang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Cybernetics ( Early Access )",
        "date_of_publication": "15 October 2024",
        "doi": "10.1109/TCYB.2024.3471919",
        "publisher": "IEEE",
        "abstract": "Broad learning system (BLS) is an effective neural network requiring no deep architecture, however it is somehow fragile to noisy data. The previous robust broad models directly map features from the raw data, which inevitably learn useless or even harmful features for data representation when the inputs are corrupted by noise and outliers. To address this concern, a discriminative and robust network named as dynamic graph regularized broad learning (DGBL) with marginal fisher representation is proposed for noisy data classification. Different from the previous works, DGBL eliminates the effect of noise before the random feature mapping by the proposed robust and dynamic marginal fisher analysis (RDMFA) algorithm. The RDMFA is able to extract more robust and informative representations for classification from the latent clean data space with dynamically generated graphs. Furthermore, the dynamic graphs learned from RDMFA are incorporated as regularization terms into the objective of DGBL to enhance the discrimination capacity of the proposed network. Extensive quantitative and qualitative experiments conducted on numerous benchmark datasets demonstrate the superiority of the proposed model compared to several state-of-the-art methods.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Noise measurement",
                "Noise",
                "Data models",
                "Manifolds",
                "Training",
                "Learning systems",
                "Heuristic algorithms",
                "Data mining",
                "Stacking"
            ],
            "Author Keywords": [
                "Graph broad learning",
                "graph embedding",
                "marginal fisher representation",
                "noisy data classification",
                "robust feature extraction"
            ]
        },
        "Field": "data",
        "title": "Dynamic Graph Regularized Broad Learning With Marginal Fisher Representation for Noisy Data Classification",
        "link": "https://ieeexplore.ieee.org/document/10717435/"
    },
    {
        "authors": [
            "Yuan Liang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Computational Social Systems ( Early Access )",
        "date_of_publication": "27 May 2024",
        "doi": "10.1109/TCSS.2024.3385672",
        "publisher": "IEEE",
        "abstract": "In real-world network scenarios, modal absence may be caused by various factors, such as sensor damage, data corruption, and human errors in recording. Effectively integrating multimodal missing data still poses significant challenges. Different combinations of missing modes can form feature sets of inconsistent dimensions and quantities. Additionally, effectively merging multimodal data requires a thorough understanding of specific modal information and intermodal interactions. The abundance of missing data can significantly reduce the sample set size, leading to learning interaction features from only a few samples. Moreover, there is a lack of clear correspondence between heterogeneous data from different sources. To address these issues, we focus our research on multimodal knowledge graph scenarios with different types of structures and content and develop a new knowledge graph embedding method. First, we use three embedding components to automatically extract feature vector representations of items from the structural content, textual content, and visual content of the knowledge graph. Then, we divide the dataset into several modal groups and model these modal groups using a multilayer network structure, with each multilayer network corresponding to a specific multimodal combination. Subsequently, we construct corresponding multilayer network projection layers and propose a two-stage GAT-based transfer learning framework for the projection layers, in which the extracted incomplete multimodal information and intermodal interaction information are integrated and mapped to a low-dimensional space. Finally, we not only theoretically prove the feasibility of the proposed method but also validate its effectiveness through extensive comparative experiments on multiple datasets.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Knowledge graphs",
                "Data integration",
                "Feature extraction",
                "Nonhomogeneous media",
                "Data models",
                "Visualization",
                "Knowledge based systems"
            ],
            "Author Keywords": [
                "Embedding",
                "missing data integration (MDI)",
                "multimodal knowledge graph (MKG)",
                "two-stage graph attention network"
            ]
        },
        "Field": "data",
        "title": "Multimodal Knowledge Graph Embedding With Missing Data Integration",
        "link": "https://ieeexplore.ieee.org/document/10539319/"
    },
    {
        "authors": [
            "Yan- Fang Liu",
            "Li-Ye Xiao",
            "Wei Shao",
            "Lin Peng",
            "Qing Huo Liu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Antennas and Wireless Propagation Letters ( Early Access )",
        "date_of_publication": "10 September 2024",
        "doi": "10.1109/LAWP.2024.3456838",
        "publisher": "IEEE",
        "abstract": "To enhance the efficiency of the training dataset construction and improve the machine learning (ML) model performance for electromagnetic (EM) devices modeling and design, an efficient training data collection method based on the evolutionary algorithm is proposed. By setting an appropriate objective function for EM response, the evolutionary algorithm guides the training samples to contain more helpful and useful information for design in each optimization iteration. Consequently, with this higher-quality dataset, ML model achieves better performance more readily. To fully demonstrate the validity of this proposed evolutionary algorithm-based training data collection method, a topological design example for frequency selective surface (FSS) with different incident angles is presented. Results indicate that, with the same number of samples, when compared with traditional random data collection method, the proposed method improves testing accuracy by maximum value of 29.6%. Furthermore, if the traditional random training data collection method is used to achieve the same testing error level as the proposed training data collection method, it would require more than twice the number of full-wave EM simulations.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Training data",
                "Evolutionary computation",
                "Optimization",
                "Computational modeling",
                "Linear programming",
                "Data models"
            ],
            "Author Keywords": [
                "Evolutionary algorithm",
                "frequency selective surface",
                "machine learning",
                "training data collection method"
            ]
        },
        "Field": "data",
        "title": "An Efficient Training Data Collection Method for Machine Learning-Based Frequency Selective Surface Design",
        "link": "https://ieeexplore.ieee.org/document/10670280/"
    },
    {
        "authors": [
            "Qing Zhang",
            "Changyan Chen",
            "Shuhua Yuan",
            "Jing Zhang",
            "Jiajun Yuan",
            "Huajie Huang",
            "Yuhang Zhang",
            "Rui Pan",
            "Xuya Jiang",
            "Jian Zhao",
            "Yongfu Li",
            "Yong Yin",
            "Liebin Zhao",
            "Guoxing Wang",
            "Yong Lian"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Data Descriptions ( Early Access )",
        "date_of_publication": "10 October 2024",
        "doi": "10.1109/IEEEDATA.2024.3477390",
        "publisher": "IEEE",
        "abstract": "The development of digital stethoscopes and automatic respiratory sound algorithms is crucial for accelerating diagnosis, reducing physician workload, and lowering mortality rates from respiratory diseases. However, transmitting data from digital stethoscopes to cloud or other storage devices requires substantial storage and transmission capacities, especially for wearable devices used for long-term monitoring. Besides, current automatic algorithms often predict labels for segmented sound events, lacking precision in detecting the onsets and offsets of respiratory sound events. To address these challenges, we organized a Grand Challenge inviting the community to develop data compression and event detection algorithms to reduce the storage and transmission burden and event segmentation workload. A new testing set was prepared to evaluate the performance of the submissions. The top teams presented their work at the 20th IEEE Biomedical Circuits and Systems Conference (BioCAS) 2024.",
        "issn": {
            "Electronic ISSN": "2995-4274"
        },
        "keywords": {
            "IEEE Keywords": [
                "Event detection",
                "Medical diagnostic imaging",
                "Predictive models",
                "Data compression",
                "Training",
                "Stethoscope",
                "Pulmonary diseases",
                "Pediatrics",
                "Error analysis",
                "Circuits and systems"
            ],
            "Author Keywords": [
                "Open-Source",
                "Respiratory Sound",
                "Grand Challenge",
                "Data Compression",
                "Event Detection"
            ]
        },
        "Field": "data",
        "title": "Meta: Data Compression and Event Detection Grand Challenge 2024 With SPRSound Dataset",
        "link": "https://ieeexplore.ieee.org/document/10713224/"
    },
    {
        "authors": [
            "Ruoyu Wang",
            "Yingjian Liu",
            "Jinhui Liu",
            "Haoyu Yin",
            "Zhongwen Guo"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "27 August 2024",
        "doi": "10.1109/JIOT.2024.3450683",
        "publisher": "IEEE",
        "abstract": "Internet of Underwater Things (IoUT) is applied to ocean research by connecting underwater sensing devices. It has ability to maintain efficient communication even in challenging environments and with limited power resources. However, it hinders the efficient storage and forwarding of huge amounts of underwater data due to the traditional IP architecture. As a future network architecture, Underwater Named Data Networking (UNDN) is considered an effective architecture of IoUT. While naive UNDN cannot support active forwarding when dangers occur in underwater environments, which may cause severe consequences. In this paper, we propose an event-based communication architecture called push-hybrid UNDN, which can achieve active and timely forwarding when critical events occur. To realize critical data forwarding without waiting for user requests, passively accepted interest is replaced by actively forwarded beacon during the critical events. The push-hybrid UNDN is analyzed and compared with the naive one in transmission performance to highlight the advantages of incorporating push mechanism. Energy consumption of push-hybrid UNDN, naive UNDN, and push-based UNDN is compared in different scenarios to demonstrate the advantages of hybrid design. Simulation results verify that our scheme achieves shorter transmission delay, more stable and higher packet delivery ratio, less traffics, and lower energy consumption than existing UNDN architectures.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Internet of Things",
                "Network architecture",
                "Energy consumption",
                "Monitoring",
                "Delays",
                "Internet",
                "Simulation"
            ],
            "Author Keywords": [
                "Internet of Things",
                "Underwater Named Data Networking",
                "Critical Data Forwarding",
                "Push Mechanism"
            ]
        },
        "Field": "data",
        "title": "Push-Hybrid Data Forwarding in Underwater Named Data Networking",
        "link": "https://ieeexplore.ieee.org/document/10648996/"
    },
    {
        "authors": [
            "Ouwen Huan",
            "Yang Yang",
            "Tao Luo",
            "Mingzhe Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Communications ( Early Access )",
        "date_of_publication": "16 September 2024",
        "doi": "10.1109/TCOMM.2024.3459848",
        "publisher": "IEEE",
        "abstract": "In this paper, a multi-modal data based semi-supervised learning (SSL) framework that jointly use channel state information (CSI) data and RGB images for vehicle positioning is designed. In particular, an outdoor positioning system where the vehicle locations are determined by a base station (BS) is considered. The BS equipped with several cameras can collect a large amount of unlabeled CSI data and a small number of labeled CSI data of vehicles, and the images taken by cameras. Although the collected images contain partial information of vehicles (i.e. azimuth angles of vehicles), the relationship between the unlabeled CSI data and its azimuth angle, and the distances between the BS and the vehicles captured by images are both unknown. Therefore, the images cannot be directly used as the labels of unlabeled CSI data to train a positioning model. To exploit unlabeled CSI data and images, a SSL framework that consists of a pretraining stage and a downstream training stage is proposed. In the pretraining stage, the azimuth angles obtained from the images are considered as the labels of unlabeled CSI data to pretrain the positioning model. In the downstream training stage, a small sized labeled dataset in which the accurate vehicle positions are considered as labels is used to retrain the model. Simulation results show that the proposed method can reduce the positioning error by up to 30% compared to a baseline where the model is not pretrained.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Cameras",
                "Radio frequency",
                "Data models",
                "Azimuth",
                "Vectors",
                "Fingerprint recognition",
                "Training"
            ],
            "Author Keywords": [
                "Semi-supervised learning",
                "vehicle positioning",
                "multi-modal data"
            ]
        },
        "Field": "data",
        "title": "Multi-modal Data based Semi-Supervised Learning for Vehicle Positioning",
        "link": "https://ieeexplore.ieee.org/document/10681279/"
    },
    {
        "authors": [
            "Mohammad Bany Taha",
            "Fawaz A. Khasawneh",
            "Ahmad Nahar Quttoum",
            "Muteb Alshammari",
            "Zakaria Alomari"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "05 November 2024",
        "doi": "10.1109/ACCESS.2024.3491951",
        "publisher": "IEEE",
        "abstract": "As the adoption of Internet of Things (IoT) systems, particularly those integrated with cloud technology, continues to expand, ensuring data security and privacy while maintaining optimal performance becomes increasingly challenging. Complex encryption algorithms, when run on IoT devices with limited resources, can significantly hinder processing speed and resource efficiency. This paper introduces an innovative Attribute-Based Encryption (ABE) framework that offloads computationally intensive cryptographic operations to a proxy server. This approach alleviates the computational strain on resource-constrained IoT devices, allowing them to efficiently handle encryption and decryption tasks despite their limited processing power, memory, and battery life. Additionally, we present a robust security model that ensures the privacy and integrity of data in IoT environments, in line with the requirements of ABE. We conduct an extensive performance analysis, evaluating key metrics such as execution time, ciphertext size, and memory usage, demonstrating that our proposed scheme surpasses existing state-of-the-art methods in efficiency. The primary contributions of this work include the development of a lightweight ABE offloading framework, the creation of a strong security model, and a thorough performance assessment that highlights the scheme’s efficiency and practicality for real-world IoT applications.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Internet of Things",
                "Encryption",
                "Cryptography",
                "Security",
                "Servers",
                "Data privacy",
                "Protocols",
                "Logic gates",
                "Information technology",
                "Data processing",
                "Data security"
            ],
            "Author Keywords": [
                "Access Policy Attributes",
                "Attribute-Based Encryption (ABE)",
                "Cloud",
                "Computational Overhead",
                "Data Security",
                "Internet of Things (IoT)"
            ]
        },
        "Field": "data",
        "title": "Outsourcing Attribute-Based Encryption to Enhance IoT Security and Performance",
        "link": "https://ieeexplore.ieee.org/document/10743181/"
    },
    {
        "authors": [
            "Guangning Xu",
            "Michael K. Ng",
            "Yunming Ye",
            "Bowen Zhang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Geoscience and Remote Sensing ( Early Access )",
        "date_of_publication": "01 November 2024",
        "doi": "10.1109/TGRS.2024.3489674",
        "publisher": "IEEE",
        "abstract": "A tropical cyclone is a highly destructive extreme weather phenomenon. Estimating the intensity of a tropical cyclone can help provide early warnings, guiding specific disaster defense measures. However, two main challenges hinder performance improvement. The first challenge is how to combine heterogeneous tropical cyclone data into a latent space so that the model can leverage the cloud structure of satellite imagery and the comprehensive meteorological information from reanalysis or forecast data for intensity estimation. The second challenge lies in detecting multiple pseudo fine-grained areas for the final estimation since tropical cyclones are highly diverse extreme weather phenomena. Neglecting any pseudo fine-grained areas or relying solely on a single one can potentially result in subpar estimation performance. To address the challenges mentioned above, a fine-grained heterogeneous data fusion framework named FHDTIE is proposed. Two key components in this framework can address the aforementioned challenges. One component is the Heterogeneous Data Fuser (HDF), which offers shape matching and channel fusing strategies for heterogeneous data fusion. The other component is called the Fine-grained Cluster Features Integrator (FCFI). It utilizes a clustering method to identify multiple pseudo fine-grained areas. Within these areas, the U-Net is used to automatically learn pseudo-fine-grained area representations, and then the Graph Neural Network handles information interaction across these representations. Extensive experiments were conducted to demonstrate the robustness and superiority of the proposed fine-grained heterogeneous data fusion framework. The code is available at GitHub: https://github.com/xuguangning1218/FHDTIE.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Tropical cyclones",
                "Estimation",
                "Satellite images",
                "Statistical analysis",
                "Deep learning",
                "Data models",
                "Feature extraction",
                "Shape",
                "Data integration",
                "Clustering methods"
            ],
            "Author Keywords": [
                "intensity estimation",
                "tropical cyclone intensity",
                "typhoon",
                "fine-grained"
            ]
        },
        "Field": "data",
        "title": "FHDTIE: Fine-grained Heterogeneous Data Fusion for Tropical Cyclone Intensity Estimation",
        "link": "https://ieeexplore.ieee.org/document/10741185/"
    },
    {
        "authors": [
            "Yongxian Wei",
            "Zixuan Hu",
            "Li Shen",
            "Zhenyi Wang",
            "Lei Li",
            "Yu Li",
            "Chun Yuan"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Circuits and Systems for Video Technology ( Early Access )",
        "date_of_publication": "08 July 2024",
        "doi": "10.1109/TCSVT.2024.3424572",
        "publisher": "IEEE",
        "abstract": "Although few-shot learning aims to address data scarcity, it still requires large, annotated datasets for training, which are often unavailable due to cost and privacy concerns. Previous studies have utilized pre-trained diffusion models, either to synthesize auxiliary data besides limited labeled samples, or to employ diffusion models as zero-shot classifiers. However, they are limited to conditional diffusion models needing class prior information ( e.g ., carefully crafted text prompts) about unseen tasks. To overcome this, we leverage unconditional diffusion models without needs for class information to train a meta-model capable of generalizing to unseen tasks. The framework contains (1) a meta-learning without data approach that uses synthetic data during training; and (2) a diffusion model-based data augmentation to calibrate the distribution shift during testing. During meta-training, we implement a self-taught class-learner to gradually capture class concepts, guiding unconditional diffusion models to generate a labeled pseudo dataset. This pseudo dataset is then used to jointly train the class-learner and the meta-model, allowing for iterative refinement and clear differentiation between classes. During meta-testing, we introduce a data augmentation that employs the diffusion models used in meta-training, to narrow the gap between meta-training and meta-testing task distribution. This enables the meta-model trained on synthetic images to effectively classify real images in unseen tasks. Comprehensive experiments showcase the superiority and adaptability of our approach in four real-world scenarios. Code available at https://github.com/WalkerWorldPeace/MLWDUDM.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Diffusion models",
                "Task analysis",
                "Data models",
                "Training",
                "Testing",
                "Metalearning",
                "Few shot learning"
            ],
            "Author Keywords": [
                "Meta-learning without data",
                "application of diffusion models",
                "few-shot learning",
                "AI-generated content",
                "privacy-preserving data mining"
            ]
        },
        "Field": "data",
        "title": "Meta-Learning without Data via Unconditional Diffusion Models",
        "link": "https://ieeexplore.ieee.org/document/10587268/"
    },
    {
        "authors": [
            "Haishuai Wang",
            "Jianjun Yang",
            "Guangyu Tao",
            "Jiali Ma",
            "Lianhua Chi",
            "Jun Wu",
            "Ziping Zhao"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Journal of Biomedical and Health Informatics ( Early Access )",
        "date_of_publication": "21 November 2022",
        "doi": "10.1109/JBHI.2022.3223798",
        "publisher": "IEEE",
        "abstract": "In healthcare, training examples are usually hard to obtain (e.g., cases of a rare disease), or the cost of labelling data is high. With a large number of features ( $p$ ) be measured in a relatively small number of samples ( $N$ ), the “big $p$ , small $N$ ” problem is an important subject in healthcare studies, especially on the genomic data. Another major challenge of effectively analyzing medical data is the skewed class distribution caused by the imbalance between different class labels. In addition, feature importance and interpretability play a crucial role in the success of solving medical problems. Therefore, in this paper, we present an interpretable deep embedding model (IDEM) to classify new data having seen only a few training examples with highly skewed class distribution. IDEM model consists of a feature attention layer to learn the informative features, a feature embedding layer to directly deal with both numerical and categorical features, a siamese network with contrastive loss to compare the similarity between learned embeddings of two input samples. Experiments on both synthetic data and real-world medical data demonstrate that our IDEM model has better generalization power than conventional approaches with few and imbalanced training medical samples, and it is able to identify which features contribute to the classifier in distinguishing case and control.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Deep learning",
                "Medical diagnostic imaging",
                "Data models",
                "Feature extraction",
                "Medical services",
                "Diseases",
                "Training"
            ],
            "Author Keywords": [
                "Interpretable AI",
                "Deep Embedding Model",
                "Few Medical Data",
                "Imbalanced Medical Data",
                "Siamese Network"
            ]
        },
        "Field": "data",
        "title": "An Interpretable Deep Embedding Model for Few and Imbalanced Biomedical Data",
        "link": "https://ieeexplore.ieee.org/document/9956894/"
    },
    {
        "authors": [
            "Lin Chen",
            "Yuxiang Chen",
            "Wei Liang",
            "Xiong Li",
            "Kuan-Ching Li",
            "Jin Wang",
            "Naixue Xiong"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Internet of Things Journal ( Early Access )",
        "date_of_publication": "26 September 2024",
        "doi": "10.1109/JIOT.2024.3468733",
        "publisher": "IEEE",
        "abstract": "With the swift advancement of the Internet of Things (IoT) and Artificial Intelligence (AI), various technologies have been integrated into wearable medical health devices, improving users’ awareness of their physical states and enabling the analysis of a greater amount of human data. However, these sensitive pieces of information are prone to tampering or theft during storage and transmission, posing security risks. In this article, we propose a multi-attribute sketch secure data sharing scheme for IoT wearable medical devices based on blockchain (MASS). We introduce a multi-attribute sketch storage method that stores the encrypted hash of health data transmitted by medical wearable devices on the blockchain. This work also designs a Ciphertext-Policy Attribute-Based Encryption (CPABE) access control mechanism that effectively addresses the secure sharing of data from wearable medical devices among healthcare professionals. Experimental findings indicate that with the rise in the number of medical health data documents, the costs associated with index generation and search time decrease by 55.3% and 10.83%, respectively. Additionally, as the frequency of data access increases, there is a 13.5% reduction in encryption time, and the implementation of multi-attribute sketches results in a 24.8% and 11.3% reduction in index generation and search times, respectively.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Medical diagnostic imaging",
                "Blockchains",
                "Medical devices",
                "Wearable devices",
                "Access control",
                "Data privacy",
                "Cryptography"
            ],
            "Author Keywords": [
                "Blockchain",
                "Health Data",
                "Multi-Attribute Sketch",
                "CP-ABE",
                "Secure Data Sharing"
            ]
        },
        "Field": "data",
        "title": "MASS: A Multi-Attribute Sketch Secure Data Sharing Scheme for IoT Wearable Medical Devices Based on Blockchain",
        "link": "https://ieeexplore.ieee.org/document/10695741/"
    },
    {
        "authors": [
            "Joonho Seon",
            "Seongwoo Lee",
            "Young Ghyu Sun",
            "Soo Hyun Kim",
            "Dong In Kim",
            "Jin Young Kim"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Emerging Topics in Computational Intelligence ( Early Access )",
        "date_of_publication": "04 June 2024",
        "doi": "10.1109/TETCI.2024.3406719",
        "publisher": "IEEE",
        "abstract": "In industrial Internet of Things (IIoT) systems, imbalanced datasets are prevalent because of the relative ease of acquiring normal operational data compared to abnormal or faulty data. An unbalanced distribution of data may lead to a biased learning problem, resulting in performance degradation of deep learning models. Data augmentation approaches based on generative adversarial networks (GAN) have been proposed to mitigate biased learning problems. However, GAN-based approaches constructed solely with convolutional neural networks may be incapable of extracting temporal properties from data. To utilize the temporal properties of data, a novel GAN structure consisting of an embedding network and recurrent neural networks is proposed in this paper. Additionally, in the novel GAN model based on mean-squared error, modified loss and mutual information terms are employed to improve training stability. From simulation results, it is confirmed that classification accuracy can be significantly improved by up to 54% based on the proposed method when compared with conventional fault diagnosis methods.",
        "issn": {
            "Electronic ISSN": "2471-285X"
        },
        "keywords": {
            "IEEE Keywords": [
                "Generative adversarial networks",
                "Data models",
                "Generators",
                "Training",
                "Industrial Internet of Things",
                "Computational modeling",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Data augmentation",
                "fault diagnosis",
                "generative adversarial networks",
                "time-series data"
            ]
        },
        "Field": "data",
        "title": "Least Information Spectral GAN With Time-Series Data Augmentation for Industrial IoT",
        "link": "https://ieeexplore.ieee.org/document/10547492/"
    },
    {
        "authors": [
            "Seoyoon Shin",
            "Jiwon Kim",
            "Seokhee Lee",
            "Tae Ho Shin",
            "Ga-Ae Ryu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "03 October 2024",
        "doi": "10.1109/ACCESS.2024.3472849",
        "publisher": "IEEE",
        "abstract": "The proton-exchange membrane fuel cell (PEMFC) is one of the important technologies advancing sustainable energy. However, predicting its performance and optimizing processes is challenging due to the complexity of integrating various types of data with interdependent variables. This study introduces a novel deep learning model using multimodal data that integrated convolutional neural networks (CNN) and deep neural networks (DNN) to address these challenges. The proposed model predicts the performance through the CNN model using cell images taken from the optical microscope, and based on this, generates multimodal data to predict the optimal process conditions for each performance through the DNN model. Trained on a diverse array of experimental data under various conditions, our model significantly enhances the reliability of performance predictions and optimal process determinations, evidenced by an R² value of 0.83. Unique to this research, the AI model utilizes both PEMFC cell images and performance data, enabling automatic performance prediction and substantially reducing the need for individual cell measurements. By analyzing both morphological images and experimental data, our model accurately predicts optimal process conditions, overcoming previous integration challenges. This method not only facilitates the performance assessment process but also optimizes manufacturing operations, thereby increasing efficiency and production rates in PEMFC manufacturing.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Catalysts",
                "Ink",
                "Predictive models",
                "Artificial intelligence",
                "Fuel cells",
                "Data models",
                "Manufacturing",
                "Deep learning",
                "Convolutional neural networks",
                "Temperature measurement",
                "Multimodal sensors"
            ],
            "Author Keywords": [
                "Manufacturing optimization",
                "Proton-exchange membrane fuel cell",
                "Multimodal data",
                "Data-driven prediction",
                "Artificial intelligence"
            ]
        },
        "Field": "data",
        "title": "Multimodal Data-driven Prediction of PEMFC Performance and Process Conditions using Deep Learning",
        "link": "https://ieeexplore.ieee.org/document/10704654/"
    },
    {
        "authors": [
            "Jiwei Wang",
            "Simone Baldi",
            "Henk J. van Waarde"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Automatic Control ( Early Access )",
        "date_of_publication": "04 November 2024",
        "doi": "10.1109/TAC.2024.3490669",
        "publisher": "IEEE",
        "abstract": "The objective of model reference control is to design a controller that regulates the system's behavior so as to match a specified reference model. This paper investigates necessary and sufficient conditions for model reference control from a data-driven perspective, when only a set of data generated by the system is utilized to directly accomplish the matching. Noiseless and noisy data settings are both considered. Notably, all methods we propose build on the concept of data informativity and do not rely on persistently exciting data.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Linear matrix inequalities",
                "Noise measurement",
                "Symmetric matrices",
                "Stability analysis",
                "Closed loop systems",
                "Vectors",
                "Numerical stability",
                "Convergence",
                "Computer science"
            ],
            "Author Keywords": [
                "Data informativity",
                "data-driven control",
                "model reference control",
                "quadratic matrix inequalities"
            ]
        },
        "Field": "data",
        "title": "Necessary and Sufficient Conditions for Data-Driven Model Reference Control",
        "link": "https://ieeexplore.ieee.org/document/10741589/"
    },
    {
        "authors": [
            "Chuanrong Wu",
            "Veronika Lee",
            "Xiaoming Yang",
            "Yingwu Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "29 May 2019",
        "doi": "10.1109/ACCESS.2019.2919772",
        "publisher": "IEEE",
        "abstract": "Firms need to continuously carry out product innovation to survive in dynamic market. In the big data environment, most firms, especially internet firms, realize new product innovation by taking imitation innovation as a stepping stone leading to independent innovation. Knowledge transfer, one of the main methods that firms acquire knowledge from external environment for imitation innovation, is a complex process of multiple knowledge transfer among different organizations and subject to various risks. Thus, it is necessary to understand knowledge transfer risks in the big data environment and help firms to carry out effective knowledge transfer in the process of new product innovation. Based on the influence factors of knowledge transfer risks and development process of innovation, a theoretical framework for risk control of knowledge transfer in the big data environment is proposed and a risk control model of knowledge transfer is presented. The model can be used to determine the maximum profit of a new product, the optimal time of knowledge transfer, and the update time of independent innovation knowledge in the big data environment. The results of simulation experiments are in line with the actual economic situation, and the model is valid.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Knowledge transfer",
                "Big Data",
                "Technological innovation",
                "Data models",
                "Organizations",
                "Economics",
                "Uncertainty"
            ],
            "Author Keywords": [
                "Big data",
                "knowledge transfer",
                "risk control",
                "independent innovation",
                "imitation innovation"
            ]
        },
        "Field": "data",
        "title": "Risk Control for Knowledge Transfer in the Big Data Environment",
        "link": "https://ieeexplore.ieee.org/document/8725521/"
    },
    {
        "authors": [
            "Chi Zhang",
            "Qizhi Yang",
            "Linyu Fan",
            "Shaocong Yu",
            "Liyan Sun",
            "Congbo Cai",
            "Xinghao Ding"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Medical Imaging ( Early Access )",
        "date_of_publication": "28 November 2023",
        "doi": "10.1109/TMI.2023.3335212",
        "publisher": "IEEE",
        "abstract": "The generation of synthetic data using physics-based modeling provides a solution to limited or lacking real-world training samples in deep learning methods for rapid quantitative magnetic resonance imaging (qMRI). However, synthetic data distribution differs from real-world data, especially under complex imaging conditions, resulting in gaps between domains and limited generalization performance in real scenarios. Recently, a single-shot qMRI method, multiple overlapping-echo detachment imaging (MOLED), was proposed, quantifying tissue transverse relaxation time (T 2 ) in the order of milliseconds with the help of a trained network. Previous works leveraged a Bloch-based simulator to generate synthetic data for network training, which leaves the domain gap between synthetic and real-world scenarios and results in limited generalization. In this study, we proposed a T 2 mapping method via MOLED from the perspective of domain adaptation, which obtained accurate mapping performance without real-label training and reduced the cost of sequence research at the same time. Experiments demonstrate that our method outshined in the restoration of MR anatomical structures.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Synthetic data",
                "Training",
                "Signal to noise ratio",
                "Feature extraction",
                "Task analysis",
                "Image reconstruction",
                "Data models"
            ],
            "Author Keywords": [
                "Rapid quantitative magnetic resonance imaging",
                "Synthetic data",
                "Domain gap",
                "Domain adaptation"
            ]
        },
        "Field": "data",
        "title": "Towards Better Generalization Using Synthetic Data: A Domain Adaptation Framework for T2 Mapping via Multiple Overlapping-Echo Acquisition",
        "link": "https://ieeexplore.ieee.org/document/10330700/"
    },
    {
        "authors": [
            "Kai Shu",
            "Le Wu",
            "Yuchang Zhao",
            "Aiping Liu",
            "Ruobing Qian",
            "Xun Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Cognitive and Developmental Systems ( Early Access )",
        "date_of_publication": "31 October 2024",
        "doi": "10.1109/TCDS.2024.3489357",
        "publisher": "IEEE",
        "abstract": "Data augmentation (DA) can significantly strengthen the electroencephalogram (EEG)-based seizure prediction methods. However, existing DA approaches are just the linear transformations of original data and cannot explore the feature space to increase diversity effectively. Therefore, we propose a novel diffusion-based DA method called DiffEEG. DiffEEG can fully explore data distribution and generate samples with high diversity, offering extra information to classifiers. It involves two processes: the diffusion process and the denoised process. In the diffusion process, the model incrementally adds noise with different scales to EEG input and converts it into random noise. In this way, the representation of data can be learned. In the denoised process, the model utilizes learned knowledge to sample synthetic data from random noise input by gradually removing noise. The randomness of input noise and the precise representation enable the synthetic samples to possess diversity while ensuring the consistency of feature space. We compared DiffEEG with original, down-sampling, sliding windows and recombination methods, and integrated them into five representative classifiers. The experiments demonstrate the effectiveness and generality of our method. With the contribution of DiffEEG, the Multi-scale CNN achieves state-of-the-art performance, with an average sensitivity, FPR, AUC of 95.4%, 0.051/h, 0.932 on the CHB-MIT database and 93.6%, 0.121/h, 0.822 on the Kaggle database.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Noise",
                "Feature extraction",
                "Brain modeling",
                "Electroencephalography",
                "Training",
                "Diffusion models",
                "Data models",
                "Epilepsy",
                "Diffusion processes",
                "Synthetic data"
            ],
            "Author Keywords": [
                "Seizure prediction",
                "deep learning",
                "diffusion model",
                "data augmentation"
            ]
        },
        "Field": "data",
        "title": "Data Augmentation for Seizure Prediction with Generative Diffusion Model",
        "link": "https://ieeexplore.ieee.org/document/10740033/"
    },
    {
        "authors": [
            "Klaus Eckelt",
            "Kiran Gadhave",
            "Alexander Lex",
            "Marc Streit"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "23 September 2024",
        "doi": "10.1109/TVCG.2024.3456186",
        "publisher": "IEEE",
        "abstract": "Exploratory data science is an iterative process of obtaining, cleaning, profiling, analyzing, and interpreting data. This cyclical way of working creates challenges within the linear structure of computational notebooks, leading to issues with code quality, recall, and reproducibility. To remedy this, we present Loops, a set of visual support techniques for iterative and exploratory data analysis in computational notebooks. Loops leverages provenance information to visualize the impact of changes made within a notebook. In visualizations of the notebook provenance, we trace the evolution of the notebook over time and highlight differences between versions. Loops visualizes the provenance of code, markdown, tables, visualizations, and images and their respective differences. Analysts can explore these differences in detail in a separate view. Loops not only makes the analysis process transparent but also supports analysts in their data science work by showing the effects of changes and facilitating comparison of multiple versions. We demonstrate our approach's utility and potential impact in two use cases and feedback from notebook users from various backgrounds. This paper and all supplemental materials are available at https://osf.io/79eyn.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Codes",
                "History",
                "Visualization",
                "Iterative methods",
                "Data science",
                "Reproducibility of results"
            ],
            "Author Keywords": [
                "Comparative visualization",
                "computational notebooks",
                "provenance",
                "data science"
            ]
        },
        "Field": "data",
        "title": "Loops: Leveraging Provenance and Visualization to Support Exploratory Data Analysis in Notebooks",
        "link": "https://ieeexplore.ieee.org/document/10689475/"
    },
    {
        "authors": [
            "Yuqi Wu",
            "Kaining Mao",
            "Yanbo Zhang",
            "Jie Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Journal of Biomedical and Health Informatics ( Early Access )",
        "date_of_publication": "29 July 2024",
        "doi": "10.1109/JBHI.2024.3435085",
        "publisher": "IEEE",
        "abstract": "The global prevalence of mental health disorders is increasing, leading to a significant economic burden estimated in trillions of dollars. In automated mental health diagnosis, the scarcity and imbalance of clinical data pose considerable challenges for researchers, limiting the effectiveness of machine learning algorithms. To cope with this issue, this paper aims to introduce a novel clinical transcript data augmentation framework by leveraging large language models (CALLM). The framework follows a “patient-doctor role-playing” intuition to generate realistic synthetic data. In addition, our study introduces a unique “Textbook-Assignment-Application” (T-A-A) partitioning approach to offer a systematic means of crafting synthetic clinical interview datasets. Concurrently, we have also developed a “Response-Reason” prompt engineering paradigm to generate highly authentic and diagnostically valuable transcripts. By leveraging a fine-tuned DistilBERT model on the E-DAIC PTSD dataset, we achieved a balanced accuracy of 0.77, an F1-score of 0.70, and an AUC of 0.78 during test set evaluations, which showcase robust adaptability in both Zero-Shot Learning (ZSL) and Few-Shot Learning (FSL) scenarios. We further compare the CALLM framework with other data augmentation methods and PTSD diagnostic works and demonstrates consistent improvements. Compared to conventional data collection methods, our synthetic dataset not only demonstrates superior performance but also incurs less than 1% of the associated costs.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Interviews",
                "Mental health",
                "Data augmentation",
                "Data models",
                "Large language models",
                "Medical diagnostic imaging",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Affective Computing",
                "Post-Traumatic Stress Disorders",
                "Transformer",
                "Large Language Models",
                "Data Augmentation"
            ]
        },
        "Field": "data",
        "title": "CALLM: Enhancing Clinical Interview Analysis through Data Augmentation with Large Language Models",
        "link": "https://ieeexplore.ieee.org/document/10614318/"
    },
    {
        "authors": [
            "Rui Wang",
            "Deshi Li",
            "Qingqing Wu",
            "Kaitao Meng",
            "Boning Feng",
            "Lele Cong"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Communications ( Early Access )",
        "date_of_publication": "07 November 2024",
        "doi": "10.1109/TCOMM.2024.3493812",
        "publisher": "IEEE",
        "abstract": "Unmanned aerial vehicles (UAVs) have received plenty of attention due to their high flexibility and enhanced communication ability, nonetheless, the limited onboard energy restricts UAVs’ application on persistent data collection missions in large areas. In this paper, we propose a rechargeable UAV-assisted periodic data collection scheme, where a UAV is dispatched to periodically collect data from sensor nodes (SNs) in the mission area and charged by a wireless charging platform. Specifically, the periodic data collection completion time is minimized by optimizing the UAV trajectory to reach the optimal balance among the collection time, flight time, and recharging time. The formulated problem is non-convex and difficult to solve directly. To tackle this problem, we divide the main problem into two sub-problems and address them by leveraging successive convex approximation (SCA), bisection search, and heuristic methods. Then, we propose a periodic trajectory optimization algorithm to iteratively solve the two sub-problems to minimize the completion time. Furthermore, to deal with the dynamics of SNs, we propose a low-complexity trajectory adjustment strategy, where the trajectory can be maintained or adjusted locally at the SNs change, which significantly mitigates the computation cost of re-optimization. The simulation results show the superiority and robustness of the proposed scheme and the completion time is on average 39% and 33% lower than the two benchmarks, respectively.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Autonomous aerial vehicles",
                "Data collection",
                "Heuristic algorithms",
                "Wireless sensor networks",
                "Trajectory optimization",
                "Minimization",
                "Inductive charging",
                "Laser beams",
                "Vehicle dynamics",
                "Data communication"
            ],
            "Author Keywords": [
                "UAVs",
                "data collection",
                "energy limitation",
                "wireless charging",
                "time minimization",
                "trajectory optimization"
            ]
        },
        "Field": "data",
        "title": "Rechargeable UAV Trajectory Optimization for Real-Time Persistent Data Collection of Large-Scale Sensor Networks",
        "link": "https://ieeexplore.ieee.org/document/10746547/"
    },
    {
        "authors": [
            "Young Jae Lee",
            "Jaehoon Kim",
            "Young Joon Park",
            "Mingu Kwak",
            "Seoung Bum Kim"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )",
        "date_of_publication": "14 August 2024",
        "doi": "10.1109/TNNLS.2024.3439261",
        "publisher": "IEEE",
        "abstract": "In pixel-based deep reinforcement learning (DRL), learning representations of states that change because of an agent’s action or interaction with the environment poses a critical challenge in improving data efficiency. Recent data-efficient DRL studies have integrated DRL with self-supervised learning (SSL) and data augmentation to learn state representations from given interactions. However, some methods have difficulties in explicitly capturing evolving state representations or in selecting data augmentations for appropriate reward signals. Our goal is to explicitly learn the inherent dynamics that change with an agent’s intervention and interaction with the environment. We propose masked and inverse dynamics modeling (MIND), which uses masking augmentation and fewer hyperparameters to learn agent-controllable representations in changing states. Our method is comprised of a self-supervised multitask learning that leverages a transformer architecture, which captures the spatiotemporal information underlying in the highly correlated consecutive frames. MIND uses two tasks to perform self-supervised multitask learning: masked modeling and inverse dynamics modeling. Masked modeling learns the static visual representation required for control in the state, and inverse dynamics modeling learns the rapidly evolving state representation with agent intervention. By integrating inverse dynamics modeling as a complementary component to masked modeling, our method effectively learns evolving state representations. We evaluate our method by using discrete and continuous control environments with limited interactions. MIND outperforms previous methods across benchmarks and significantly improves data efficiency. The code is available at https://github.com/dudwojae/MIND.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Data augmentation",
                "Transformers",
                "Task analysis",
                "Representation learning",
                "Predictive models",
                "Inverse problems"
            ],
            "Author Keywords": [
                "Data-efficient reinforcement learning",
                "inverse dynamics modeling",
                "masked modeling",
                "self-supervised multitask learning",
                "transformer"
            ]
        },
        "Field": "data",
        "title": "Masked and Inverse Dynamics Modeling for Data-Efficient Reinforcement Learning",
        "link": "https://ieeexplore.ieee.org/document/10636769/"
    },
    {
        "authors": [
            "Shuo Shi",
            "Chengyu Gong",
            "Qian Xu",
            "Ao Wang",
            "Xingtao Tang",
            "Sifu Bi",
            "Wei Gong"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing ( Early Access )",
        "date_of_publication": "11 November 2024",
        "doi": "10.1109/JSTARS.2024.3495039",
        "publisher": "IEEE",
        "abstract": "Hyperspectral lidar (HSL) has high-precision geometric information and high-resolution spectral information, and its advantageous detection capability has been recognized by scientists at home and abroad. However, how to extract massive and complex HSL data effectively and accurately is an important issue in the current development of HSL. A methodological system that caters to HSL data features is required to achieve high-precision spatial–spectral integrated data interpretation. This requirement represents a significant scientific challenge, for which research on appropriate HSL waveform data processing methods remains scarce. This study aims to address the challenges posed by the massive data and complex waveform situations associated with HSL. Based on an experimental verification, the single-channel algorithm suggested in this paper proves to be advantageous over Gaussian decomposition, specifically for asymmetric and overlapping echoes. This algorithm produces an average R² increase of 0.023 and reduces the standard deviation by 63%. It also accurately extracts hidden overlapping echoes. Furthermore, this study proposes a multi-channel-assisted optimization algorithm that can precisely extract faint and overlapping echoes that a single-channel algorithm cannot extract. Its accuracy is remarkably high, with the ranging accuracy boosted by 98% compared with that of the single-channel algorithm.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Laser radar",
                "Data acquisition",
                "Data mining",
                "Accuracy",
                "Hyperspectral imaging",
                "Feature extraction",
                "Vegetation mapping",
                "Indexes",
                "Signal to noise ratio",
                "Detectors"
            ],
            "Author Keywords": [
                "hyperspectral lidar",
                "massive raw data",
                "complex waveform",
                "waveform decomposition",
                "multi-channel assist"
            ]
        },
        "Field": "data",
        "title": "Waveform Information Accurate Extraction for Massive and Complex Waveform Data of Hyperspectral Lidar",
        "link": "https://ieeexplore.ieee.org/document/10748379/"
    },
    {
        "authors": [
            "Yuhan Kang",
            "Samira Zare",
            "Alex Lin",
            "Zhu Han",
            "Stanley Osher",
            "Hien Nguyen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Artificial Intelligence ( Early Access )",
        "date_of_publication": "02 April 2024",
        "doi": "10.1109/TAI.2024.3384129",
        "publisher": "IEEE",
        "abstract": "Data augmentation is a critical component in building modern deep-learning systems. In this paper, we propose MFG Augment , a novel data augmentation method based on the Mean-Field-Game (MFG) theory, that can synthesize a sequence of data between every two images or features. The central idea is to consider every image as a distribution over its pixel or feature space. Using Mean-field Game theory, we can generate a time-continuous “path” from one distribution to another so that the points along the “path” are augmented images or features. Empirically, the experiment results on MNIST, CIFAR-10, and ImageNet demonstrate that the proposed technology has better generalization ability and higher classification accuracy as compared to several benchmark methods. More importantly, our MFG Augment improves the test accuracy significantly when the dataset size is small. MFG Augment consistently shows better affinity and diversity scores, two important empirical metrics for evaluating the gen...",
        "issn": {
            "Electronic ISSN": "2691-4581"
        },
        "keywords": {
            "IEEE Keywords": [
                "Data augmentation",
                "Task analysis",
                "Transforms",
                "Training",
                "Data models",
                "Game theory",
                "Artificial intelligence"
            ],
            "Author Keywords": [
                "Data Augmentation",
                "Game Theory",
                "Mean-field Game",
                "Deep Learning",
                "Image Classification"
            ]
        },
        "Field": "data",
        "title": "Game Theory Meets Data Augmentation",
        "link": "https://ieeexplore.ieee.org/document/10488756/"
    },
    {
        "authors": [
            "Xiaohong Lyu",
            "Shalli Rani",
            "S. Manimurugan",
            "Carsten Maple",
            "Yanhong Feng"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Fuzzy Systems ( Early Access )",
        "date_of_publication": "18 June 2024",
        "doi": "10.1109/TFUZZ.2024.3416217",
        "publisher": "IEEE",
        "abstract": "In the realm of medical data processing, particularly in the diagnosis and monitoring of cardiac diseases, the analysis of Electrocardiogram (ECG) signals represents a critical challenge, especially with the burgeoning volume of ECG big data. Traditional methods and existing research often fall short in effectively analyzing this data, limited by their inability to fully capture the complex and nonlinear patterns inherent in ECG signals. Addressing these limitations, in this paper, we introduce a novel deep neuro-fuzzy model augmented with multimodal feature fusion. Our method ingeniously combines the power of neurofuzzy systems with the robust feature extraction capabilities of deep learning, specifically leveraging a Transformer-based architecture, to analyze both ECG signals and their corresponding spectral images. This multimodal fusion not only enriches the model's input data, providing a comprehensive understanding of cardiac signals, but also enhances the adaptability and accuracy of cardiac arrhythmia detection. We rigorously validate our approach on the MIT-BIH Arrhythmia Database, conducting a series of experiments, including performance evaluations and ablation studies, to highlight the significant contributions of the multimodal feature fusion and neuro-fuzzy module. The results achieve significant improvements in classification metrics: an accuracy of 98.46% and an F1 score of 99.1%. Moreover, we benchmark the Transformer's feature extraction performance against other architectures like ResNet. The results unequivocally demonstrate our model's superiority and illustrate the potential of integrated neuro-fuzzy and deep learning approaches in overcoming the current limitations of ECG signal analysis.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Electrocardiography",
                "Feature extraction",
                "Data models",
                "Deep learning",
                "Analytical models",
                "Accuracy",
                "Data analysis"
            ],
            "Author Keywords": [
                "Medical data analysis",
                "deep neuro-fuzzy network",
                "multimodal feature",
                "ECG analysis"
            ]
        },
        "Field": "data",
        "title": "A Deep Neuro-Fuzzy Method for ECG Big Data Analysis via Exploring Multimodal Feature Fusion",
        "link": "https://ieeexplore.ieee.org/document/10561584/"
    },
    {
        "authors": [
            "Lüeshi Li",
            "Huafeng Zhang",
            "Ruizhuo Song"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Access ( Early Access )",
        "date_of_publication": "10 September 2024",
        "doi": "10.1109/ACCESS.2024.3456908",
        "publisher": "IEEE",
        "abstract": "Objective: Diabetes patients are closely related to blood glucose levels. Predicting blood glucose levels through routine blood test data can provide auxiliary diagnosis for diabetes risk prediction in the medical field. However, physical examination datasets are often accompanied by problems such as high feature dimensions and uneven blood glucose distribution, which significantly affect the effect of machine learning models. Methods: This paper proposes a GA-KDE-GAN stacking model combined with feature engineering technology, referred to as the GKN framework. GKN integrates genetic algorithm and random forest (GA-RF) for feature selection, kernel density estimation (KDE) for data smoothing and small sample oversampling, and generative adversarial network (GAN) for expanding the training set. The framework uses GA-RF to select feature subsets and obtain the global optimal solution based on LightGBM evaluation, and applies KDE and GAN to balance the dataset. The final model adopts a stacking strategy to enhance the accuracy of blood glucose prediction. Results: By combining GKN feature engineering, the proposed model showed significant performance improvement. Under the challenging data high dimensionality and complexity, the model achieved a mean square error (MSE) of 1.529 and the highest R-square. More importantly, it significantly improved the accuracy of diabetes classification, with accuracy (Acc) and precision (Pre) exceeding 97%. Conclusion: This study addressed the problem of high feature dimension and uneven sample distribution in the physical examination dataset. The GKN framework proved to be effective in improving the prediction performance by integrating GA-RF, KDE and GAN. These findings are promising for glucose-assisted diagnosis of diabetes, as they can predict blood glucose levels based on routine blood test data and help in diabetes risk assessment.",
        "issn": {
            "Electronic ISSN": "2169-3536"
        },
        "keywords": {
            "IEEE Keywords": [
                "Diabetes",
                "Blood",
                "Glucose",
                "Predictive models",
                "Feature extraction",
                "Accuracy",
                "Data models",
                "Machine learning",
                "Data augmentation",
                "Predictive models"
            ],
            "Author Keywords": [
                "Blood glucose estimate",
                "feature engineering",
                "machine learning",
                "stacking",
                "data augmentation"
            ]
        },
        "Field": "data",
        "title": "GKN-Stack: An ensemble deep learning framework for blood glucose forecasting based on medical examination data",
        "link": "https://ieeexplore.ieee.org/document/10670390/"
    },
    {
        "authors": [
            "Chen Chen",
            "Lankai Wang",
            "Quan Shi"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Vehicular Technology ( Early Access )",
        "date_of_publication": "26 September 2024",
        "doi": "10.1109/TVT.2024.3469385",
        "publisher": "IEEE",
        "abstract": "Improved advancements in 5G communication and intelligent connected vehicle technologies have accelerated the implementation of intelligent transportation systems. Intelligent vehicles, roadside devices, and open wireless communication networks collectively expand the vulnerability landscape of intelligent transportation system (ITS) security, thereby increasing the potential exposure to security risks. Nonetheless, mobile vehicles require frequent authentication with Roadside Units (RSUs), which in turn results in substantial computational and communication overhead. Consequently, this approach leads to performance bottlenecks in resource-constrained On-Board Units (OBUs). In this paper, we are concerned with a lattice-based certificateless secure data transmission scheme for the Internet of Vehicles (IoV) based on Blockchain. The proposed protocol incorporates identity authentication functionality and effectively integrates the cross-domain authentication characteristics of the Blockchain. Initially, the Trusted Authority (TA) uploads the registration information of vehicles onto the Blockchain to verify the authenticity of a vehicle's identity by examining the data stored in the Blockchain. When Roadside Units securely collect authenticated transactions and message transmission traffic, the integrity of the messages is ensured through the utilization of the lattice-based signcryption algorithm as part of a block. Subsequently, according to the data transmission algorithm, these partial blocks are transformed into complete blocks and disseminated across the entire network. The complete blocks were subsequently mined using a consensus algorithm that incorporated a voting mechanism. Furthermore, the security of the proposed protocol is rigorously proven by employing a random oracle model. Finally, the efficiency of the data transmission algorithm was rigorously evaluated under the Barabasi-Albert BA (3) and Erdos-Renyi ER (0,1) models, ensuring its effectiveness in ...",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Authentication",
                "Blockchains",
                "Security",
                "Internet of Vehicles",
                "Data communication",
                "Lattices",
                "Vehicle dynamics",
                "Privacy",
                "Data models",
                "Computer architecture"
            ],
            "Author Keywords": [
                "Blockchain",
                "IoV",
                "Distributed Identity Authentication",
                "Message Integrity Verification",
                "Data Transmission Algorithm"
            ]
        },
        "Field": "data",
        "title": "A lattice-based certificateless secure data transmission scheme for Internet of Vehicles Based-Blockchain",
        "link": "https://ieeexplore.ieee.org/document/10696977/"
    },
    {
        "authors": [
            "Xiao Li",
            "Huan Li",
            "Hua Lu",
            "Christian S. Jensen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Knowledge and Data Engineering ( Early Access )",
        "date_of_publication": "01 November 2024",
        "doi": "10.1109/TKDE.2024.3489796",
        "publisher": "IEEE",
        "abstract": "In large venues like shopping malls and airports, knowledge on the indoor populations fuels applications such as business analytics, venue management, and safety control. In this work, we provide means of modeling populations in partitions of indoor space offline and of monitoring indoor populations continuously, by using indoor positioning data. However, the low-sampling rates of indoor positioning render the data temporally and spatially sparse, which in turn renders the offline capture of indoor populations challenging. It is even more challenging to continuously monitor indoor populations, as positioning data may be missing or not ready yet at the current moment. To address these challenges, we first enable probabilistic modeling of populations in indoor space partitions as Normal distributions. Based on that, we propose two learning-based estimators for on-the-fly prediction of population distributions. Leveraging the prediction-based schemes, we provide a unified continuous query processing framework for a type of query that enables continuous monitoring of populated partitions. The framework encompasses caching and result validity mechanisms to reduce cost and maintain monitoring effectiveness. Extensive experiments on two real data sets show that the proposed estimators are able to outperform the state-of-the-art alternatives and that the query processing framework is effective and efficient.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Monitoring",
                "Trajectory",
                "Gaussian distribution",
                "Probabilistic logic",
                "Real-time systems",
                "Query processing",
                "Safety",
                "Global Positioning System",
                "Databases",
                "Data models"
            ],
            "Author Keywords": []
        },
        "Field": "data",
        "title": "Modeling and Monitoring of Indoor Populations using Sparse Positioning Data",
        "link": "https://ieeexplore.ieee.org/document/10740795/"
    },
    {
        "authors": [
            "Shuyin Xia",
            "Xiaoyu Lian",
            "Guoyin Wang",
            "Xinbo Gao",
            "Jiancu Chen",
            "Xiaoli Peng"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )",
        "date_of_publication": "02 July 2024",
        "doi": "10.1109/TNNLS.2024.3417433",
        "publisher": "IEEE",
        "abstract": "Granular-ball support vector machine (GBSVM) is a significant attempt to construct a classifier using the coarse-to-fine granularity of a granular ball as input, rather than a single data point. It is the first classifier whose input contains no points. However, the existing model has some errors, and its dual model has not been derived. As a result, the current algorithm cannot be implemented or applied. To address these problems, we fix the errors of the original model of the existing GBSVM and derive its dual model. Furthermore, a particle swarm optimization (PSO) algorithm is designed to solve the dual problem. The sequential minimal optimization (SMO) algorithm is also carefully designed to solve the dual problem. The latter is faster and more stable. The experimental results on the UCI benchmark datasets demonstrate that GBSVM is more robust and efficient. All codes have been released in the open source library available at: http://www.cquptshuyinxia.com/GBSVM.html or https://github.com/syxiaa/GBSVM.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Support vector machines",
                "Computational modeling",
                "Robustness",
                "Optimization",
                "Classification algorithms",
                "Noise",
                "Cognition"
            ],
            "Author Keywords": [
                "Classification",
                "classifier",
                "granular ball",
                "granular computing",
                "support vector machine (SVM)"
            ]
        },
        "Field": "data",
        "title": "GBSVM: An Efficient and Robust Support Vector Machine Framework via Granular-Ball Computing",
        "link": "https://ieeexplore.ieee.org/document/10580935/"
    },
    {
        "authors": [
            "Xiao-Qi Guo",
            "Feng-Feng Wei",
            "Jun Zhang",
            "Wei-Neng Chen"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Evolutionary Computation ( Early Access )",
        "date_of_publication": "01 February 2024",
        "doi": "10.1109/TEVC.2024.3361000",
        "publisher": "IEEE",
        "abstract": "Surrogate-assisted evolutionary algorithms (SAEAs) have achieved effective performance in solving complex data-driven optimization problems. In the Internet of Things environment, the data of many problems are collected and processed in distributed network nodes and cannot be transmitted. As each local node can only access and build surrogate models based on partial data, local models are usually not accurate and even conflicting. To address these challenges, this paper proposes a classifier-ensemble-based surrogate-assisted evolutionary algorithm (CESAEA) with the following features. First, the local nodes in CESAEA train classifiers as surrogate models based on their own data to classify candidates into several levels according to their fitness quality. The classifiers are less sensitive to the partial and biased data than regression models in local nodes. Second, the central node in CESAEA ensembles the local surrogates to form a global classifier with a relaxation condition to guide the evolutionary optimizer to generate promising candidates. The relaxation condition helps to overcome the problem of local model inconsistency. Overall, CESAEA is composed of local classifier construction, global classifier ensemble, classifier-assisted evolutionary optimization and local regression-assisted selection. As only classifiers are allowed to transmit from local nodes to the central node, the mapping relationship between decision vector and objective is hidden and thus data privacy is protected. The experimental results on benchmark functions as well as distributed feature selection problems verify the effectiveness of CESAEA compared to several state-of-the-art approaches.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Optimization",
                "Data models",
                "Evolutionary computation",
                "Distributed databases",
                "Classification algorithms",
                "Predictive models",
                "Linear programming"
            ],
            "Author Keywords": [
                "Distributed optimization",
                "data-driven",
                "surrogate-assisted evolutionary algorithm",
                "multisurrogate",
                "classification"
            ]
        },
        "Field": "data",
        "title": "A Classifier-Ensemble-Based Surrogate-Assisted Evolutionary Algorithm for Distributed Data-Driven Optimization",
        "link": "https://ieeexplore.ieee.org/document/10418547/"
    },
    {
        "authors": [
            "Mingfeng Huang",
            "Zhetao Li",
            "Anfeng Liu",
            "Xinglin Zhang",
            "Zhemin Yang",
            "Min Yang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Dependable and Secure Computing ( Early Access )",
        "date_of_publication": "08 July 2024",
        "doi": "10.1109/TDSC.2024.3424448",
        "publisher": "IEEE",
        "abstract": "As a collaborative and open network, billions of devices can be free to join the IoT-based data collection network for data perception and transmission. Along with this trend, more and more malicious attackers enter the network, they steal or tamper with data, and hinder data exchange and communication. To address these issues, we propose a Proactive Trust Evaluation System (PTES) for secure data collection by evaluating the trust of mobile data collectors. Specifically, PTES guarantees evaluation accuracy from trust evidence acquisition, trust evidence storage, and trust value calculation. First, PTES obtains trust evidence based on active detection of drones, feedbacks from interacted objects, and recommendations from trusted third parties. Then, these trust evidences are stored according to interaction time by adopting a sliding window mechanism. After that, credible, untrustworthy, and uncertain evidence sequences are extracted from the storage space, and assigned with positive, negative, and tendentious trust values, respectively. Consequently, the final normalized trust is obtained by combining the three trust values. Finally, extensive experiments conducted on a real-world dataset demonstrate PTES is superior to benchmark methods in terms of detection accuracy and profit.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Computational modeling",
                "Accuracy",
                "Predictive models",
                "Cloud computing",
                "Bayes methods",
                "Analytical models"
            ],
            "Author Keywords": [
                "Internet of Things",
                "Trust mechanism",
                "Data security",
                "Sequence extraction",
                "Evaluation accuracy"
            ]
        },
        "Field": "data",
        "title": "A Proactive Trust Evaluation System for Secure Data Collection Based on Sequence Extraction",
        "link": "https://ieeexplore.ieee.org/document/10589359/"
    },
    {
        "authors": [
            "Xin Wang",
            "J. Dinesh Peter",
            "Adam Slowik",
            "Fan Zhang",
            "Xingsi Xue"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Fuzzy Systems ( Early Access )",
        "date_of_publication": "26 June 2024",
        "doi": "10.1109/TFUZZ.2024.3419144",
        "publisher": "IEEE",
        "abstract": "Due its superiority in addressing label ambiguity, Label Distribution Learning (LDL) has received wide attention from the community, such as image classification, emotion recognition, and big data processing. To efficiently process the data with label distribution, researchers have proposed to learn label-specific features (LSFs) that are the discriminative features for each class label. Although the LDL literature has seen many algorithms to learn LSFs, most of them ignore the characteristics of label distribution. Label distribution lies in real-value vector space with specific characteristics. In this paper, we propose to learn label-distribution-specific features (LDSFs) for processing label-distribution data by considering the structures of label distribution. We design a novel LDL method called LDL-LDSF to exploit LDSFs by considering the fuzzy cluster structures of label distribution data. First, LDL-LDSF learns the LDSFs for the whole label distribution by jointly learning the label distribution and fuzzy c-means clustering. Second, it learns the LDSFs for each label in a similar way. Third, it concatenates the learned LDSFs with the original features to deduce an LDL model. Finally, we conduct extensive experiments to justify that LDL-LDSF statistically outperforms several state-of-the-art LDL methods and validate the advantages of LDSFs for processing label-distribution data.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Correlation",
                "Vectors",
                "Training",
                "Fuzzy systems",
                "Feature extraction",
                "Big Data",
                "Manifolds"
            ],
            "Author Keywords": [
                "Label-specific features (LSF)",
                "label distribution learning (LDL)",
                "fuzzy clustering",
                "fuzzy c-means (FCM)",
                "ambiguity",
                "neural network",
                "data processing"
            ]
        },
        "Field": "data",
        "title": "Learning Fuzzy Label-Distribution-Specific Features for Data Processing",
        "link": "https://ieeexplore.ieee.org/document/10572336/"
    },
    {
        "authors": [
            "Yinbin Miao",
            "Guijuan Wang",
            "Xinghua Li",
            "Yanguo Peng",
            "Liang Guo",
            "Hongwei Li",
            "Robert H. Deng"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Services Computing ( Early Access )",
        "date_of_publication": "18 September 2024",
        "doi": "10.1109/TSC.2024.3463397",
        "publisher": "IEEE",
        "abstract": "With the rapid growth of data size, a large number of data providers outsource their private data to cloud servers to reduce the high storage and computation burdens, but it also leads to security issues such as privacy leakage. Therefore, many privacy-preserving range query schemes have been proposed. However, most of existing secure range query schemes suffer from low query efficiency and expensive computation and update overheads. To address these issues, we propose a novel Fast Range Query (FRQ) scheme for large-scale encrypted Key-Value (KV) data. First, we introduce REMIX, a space-efficient KV index data structure based on Log-Structured Merge-trees (LSM-trees), which maintains a global sorted view of KV pairs across multiple table files for efficient range queries. Besides, we exploit the write-efficiency compression strategy of LSM-trees to ensure efficient dynamic data updates. Finally, we use Czech Havas Majewski (CHM) to protect the index structure, which reduces the computation overhead and ensures the retrieval accuracy. Formal security analysis proves that our scheme can achieve an acceptable level of security. Extensive experiments demonstrate that our scheme improves the query efficiency by nearly $8\\times$ and update efficiency by $7\\times$ compared to state-of-the-art solutions over million-level datasets.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Indexes",
                "Encryption",
                "Filters",
                "Data structures",
                "Hash functions",
                "Complexity theory",
                "Nearest neighbor methods"
            ],
            "Author Keywords": [
                "CHM",
                "key-value data range query",
                "LSM-tree",
                "REMIX"
            ]
        },
        "Field": "data",
        "title": "FRQ: Fast Range Query Over Large-Scale Encrypted Key-Value Data",
        "link": "https://ieeexplore.ieee.org/document/10684048/"
    },
    {
        "authors": [
            "Jiale Dun",
            "Jun Wang",
            "Juncheng Li",
            "Qianhui Yang",
            "Wenlong Hang",
            "Xiaofeng Lu",
            "Shihui Ying",
            "Jun Shi"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Journal of Biomedical and Health Informatics ( Early Access )",
        "date_of_publication": "08 October 2024",
        "doi": "10.1109/JBHI.2024.3476076",
        "publisher": "IEEE",
        "abstract": "Domain adaptation has demonstrated success in classification of multi-center autism spectrum disorder (ASD). However, current domain adaptation methods primarily focus on classifying data in a single target domain with the assistance of one or multiple source domains, lacking the capability to address the clinical scenario of identifying ASD in multiple target domains. In response to this limitation, we propose a Trustworthy Curriculum Learning Guided Multi-Target Domain Adaptation (TCL-MTDA) network for identifying ASD in multiple target domains. To effectively handle varying degrees of data shift in multiple target domains, we propose a trustworthy curriculum learning procedure based on the Dempster-Shafer (D-S) Theory of Evidence. Additionally, a domain-contrastive adaptation method is integrated into the TCL-MTDA process to align data distributions between source and target domains, facilitating the learning of domain-invariant features. The proposed TCL-MTDA method is evaluated on 437 subjects (including 220 ASD patients and 217 NCs) from the Autism Brain Imaging Data Exchange (ABIDE). Experimental results validate the effectiveness of our proposed method in multi-target ASD classification, achieving an average accuracy of 71.46% (95% CI: 68.85% - 74.06%) across four target domains, significantly outperforming most baseline methods (p<0.05).",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Adaptation models",
                "Data models",
                "Training",
                "Machine learning",
                "Logic",
                "Testing",
                "Optical fibers",
                "Mutual information",
                "Bioinformatics",
                "Autism"
            ],
            "Author Keywords": [
                "autism spectrum disorder classification",
                "trustworthy curriculum learning",
                "Dempster-Shafer Theory of Evidence",
                "Multi-target domain adaptation"
            ]
        },
        "Field": "data",
        "title": "A Trustworthy Curriculum Learning Guided Multi-Target Domain Adaptation Network for Autism Spectrum Disorder Classification",
        "link": "https://ieeexplore.ieee.org/document/10707298/"
    },
    {
        "authors": [
            "Haoran Qian",
            "Weiguo Zheng",
            "Zhijie Zhang",
            "Bo Fu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Knowledge and Data Engineering ( Early Access )",
        "date_of_publication": "30 October 2024",
        "doi": "10.1109/TKDE.2024.3488095",
        "publisher": "IEEE",
        "abstract": "The constrained shortest path problem is a fundamental and challenging task in applications built on graphs. In this paper, we formalize and study the Min-Max resourceconstrained shortest path (Min-Max RCSP) problem, which generalizes the well-studied Max RCSP problem. The objective is to find a simple path of minimum cost between two query nodes, subject to resource constraints between minimum and maximum limits. This problem has wide applications in fields such as delay networks and transportation. However, we theoretically prove that computing the optimal solution is NP-hard. We propose a two-stage approach that involves resource-based graph reduction followed by cost-guided path generation. To reduce the cost of expensive acyclicity checking, we introduce the technique of ancestor checking based on the shortest path tree. Furthermore, we present an even faster incremental search approach that considers both the path cost and resource constraints while avoiding acyclicity checking. Extensive experiments on twenty real graphs consistently demonstrate the superiority of our proposed methods, achieving up to two orders of magnitude improvement in time efficiency over the baseline algorithms while producing high-quality solutions.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Costs",
                "Delays",
                "Shortest path problem",
                "Vehicle routing",
                "Search problems",
                "Accuracy",
                "Time factors",
                "Intellectual property",
                "Correlation",
                "Valves"
            ],
            "Author Keywords": [
                "Min-Max constraint",
                "ancestor checking",
                "incremental search",
                "shortest path query",
                "graph algorithms"
            ]
        },
        "Field": "data",
        "title": "Answering Min-Max Resource-Constrained Shortest Path Queries over Large Graphs",
        "link": "https://ieeexplore.ieee.org/document/10738427/"
    },
    {
        "authors": [
            "Sherenaz Al-Haj Baddar",
            "Alessandro Languasco",
            "Mauro Migliardi"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Pattern Analysis and Machine Intelligence ( Early Access )",
        "date_of_publication": "31 October 2024",
        "doi": "10.1109/TPAMI.2024.3489645",
        "publisher": "IEEE",
        "abstract": "Modeling count data using suitable statistical distributions has been instrumental for analyzing the patterns it conveys. However, failing to address critical aspects, like overdispersion, jeopardizes the effectiveness of such an analysis. In this paper, overdispersed count data is modeled using the Dirichlet Multinomial (DM) distribution by maximizing its likelihood using a fixed-point iteration algorithm. This is achieved by estimating the DM distribution parameters while comparing the recent Languasco-Migliardi (LM), and the Yu-Shaw (YS) procedures, which address the well-known computational difficulties of evaluating its log-likelihood. Experiments were conducted using multiple datasets from different domains spanning polls, images, and IoT network traffic. They all showed the superiority of the LM procedure as it succeeded at estimating the DM parameters at the designated level of accuracy in all experiments, while the YS procedure failed to produce sufficiently accurate results (or any results at all) in several experiments. Moreover, the LM procedure achieved a speedup that ranged from 2-fold to 20-fold over YS.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Accuracy",
                "Data models",
                "Computational modeling",
                "Polynomials",
                "Convergence",
                "Instruments",
                "Vectors",
                "Telecommunication traffic",
                "Statistical distributions",
                "Reliability"
            ],
            "Author Keywords": [
                "Dirichlet multinomial distribution",
                "fixed-point iteration",
                "log-likelihood function",
                "overdispersed data",
                "Pattern analysis"
            ]
        },
        "Field": "data",
        "title": "Efficient Analysis of Overdispersed Data Using an Accurate Computation of the Dirichlet Multinomial Distribution",
        "link": "https://ieeexplore.ieee.org/document/10740644/"
    },
    {
        "authors": [
            "Yanwen Mao",
            "Deepesh Data",
            "Suhas Diggavi",
            "Paulo Tabuada"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Automatic Control ( Early Access )",
        "date_of_publication": "08 July 2024",
        "doi": "10.1109/TAC.2024.3424693",
        "publisher": "IEEE",
        "abstract": "We study the problem of decentralized optimization in the presence of adversarial attacks. In this problem, we consider a collection of nodes connected through a network, each equipped with a local function. These nodes are asked to collaboratively compute the global optimizer, i.e., the point that minimizes the aggregated local functions, using their local information and messages exchanged with their neighbors. Moreover, each node should agree on the said minimizer despite an adversary that can arbitrarily change the local functions of a fraction of the nodes. We present RAGD, the Resilient Averaging Gradient Descent algorithm, a decentralized, consensus+outlier filtering algorithm that is resilient to such attacks on local functions. We demonstrate that, as long as the portion of attacked nodes does not exceed a given threshold, RAGD guarantees that all nodes will be able to have a good estimate of the said minimizer. We verify the performance of the RAGD algorithm via numerical examples.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Optimization",
                "Peer-to-peer computing",
                "Vectors",
                "Filtering algorithms",
                "Federated learning",
                "Communication networks",
                "Topology"
            ],
            "Author Keywords": []
        },
        "Field": "data",
        "title": "Decentralized Optimization Resilient Against Local Data Poisoning Attacks",
        "link": "https://ieeexplore.ieee.org/document/10588971/"
    },
    {
        "authors": [
            "Mohamed Kissi",
            "Mathieu Pont",
            "Joshua A. Levine",
            "Julien Tierny"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "10 September 2024",
        "doi": "10.1109/TVCG.2024.3456345",
        "publisher": "IEEE",
        "abstract": "This paper presents a practical approach for the optimization of topological simplification, a central pre-processing step for the analysis and visualization of scalar data. Given an input scalar field f and a set of “signal” persistence pairs to maintain, our approaches produces an output field g that is close to f and which optimizes (i) the cancellation of “non-signal” pairs, while (ii) preserving the “signal” pairs. In contrast to pre-existing simplification algorithms, our approach is not restricted to persistence pairs involving extrema and can thus address a larger class of topological features, in particular saddle pairs in three-dimensional scalar data. Our approach leverages recent generic persistence optimization frameworks and extends them with tailored accelerations specific to the problem of topological simplification. Extensive experiments report substantial accelerations over these frameworks, thereby making topological simplification optimization practical for real-life datasets. Our approach enables a direct visualization and analysis of the topologically simplified data, e.g., via isosurfaces of simplified topology (fewer components and handles). We apply our approach to the extraction of prominent filament structures in three-dimensional data. Specifically, we show that our pre-simplification of the data leads to practical improvements over standard topological techniques for removing filament loops. We also show how our approach can be used to repair genus defects in surface processing. Finally, we provide a C++ implementation for reproducibility purposes",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Optimization",
                "Data mining",
                "Surface treatment",
                "Standards",
                "Isosurfaces",
                "Three-dimensional displays",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Topological Data Analysis",
                "scalar data",
                "simplification",
                "feature extraction"
            ]
        },
        "Field": "data",
        "title": "A Practical Solver for Scalar Data Topological Simplification",
        "link": "https://ieeexplore.ieee.org/document/10675436/"
    },
    {
        "authors": [
            "Xujing Li",
            "Sheng Sun",
            "Min Liu",
            "Ju Ren",
            "Xuefeng Jiang",
            "Tianliu He"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Mobile Computing ( Early Access )",
        "date_of_publication": "23 September 2024",
        "doi": "10.1109/TMC.2024.3466208",
        "publisher": "IEEE",
        "abstract": "Federated learning has been a popular distributed training paradigm that enables to train a shared model with data privacy protection. However, non-Independent Identically Distribution and long-tailed data distribution characteristics across mobile devices results in evident performance degradation, especially for classification tasks. Although plenty of research studies devote to alleviating classification performance degradation caused by highly-skewed data distribution, they still cannot improve the distinguishability of model representation on hard-to-learn tail classes, and face obvious divergence of local classifiers in FL setting. To this end, we propose Federated Classifier Representation Adjustment and Calibration to improve the representation distinguishability of tail classes and achieve inter-client representation alignment with acceptable resource consumption on attaching operations. We first design a Class Similarity-Aware Margin matrix to enlarge class representation discrepancy and improve local classifier discriminability on tail classes during client-side local training process. To mitigate the divergence of local classifiers across clients, we further propose the Self Distillation Classifier Calibration to achieve the aggregated global classifier calibration with the assistance of generated pseudo representation samples via self-distillation manner. We conduct various experiments under wide-range long-tailed and heterogeneous data settings. Experimental results show that FedCRAC outperforms state-of-the-art methods in terms of accuracy and resource consumption.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Tail",
                "Data models",
                "Training",
                "Computational modeling",
                "Servers",
                "Accuracy",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Data heterogeneity",
                "federated learning",
                "long-tailed data",
                "representation alignment"
            ]
        },
        "Field": "data",
        "title": "FedCRAC: Improving Federated Classification Performance on Long-Tailed Data Via Classifier Representation Adjustment and Calibration",
        "link": "https://ieeexplore.ieee.org/document/10689340/"
    },
    {
        "authors": [
            "Wandong Zhang",
            "Yimin Yang",
            "Q. M. Jonathan Wu",
            "Tianlong Liu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Cybernetics ( Early Access )",
        "date_of_publication": "15 October 2024",
        "doi": "10.1109/TCYB.2024.3473809",
        "publisher": "IEEE",
        "abstract": "The broad learning system (BLS) is a versatile and effective tool for analyzing tabular data. However, the rapid expansion of big data has resulted in an overwhelming amount of tabular data, necessitating the development of specialized tools for effective management and analysis. This article introduces an optimized BLS (OBLS) specifically tailored for big data analysis. In addition, a deep-optimized BLS (DOBLS) network is developed further to enhance the performance and efficiency of the OBLS. The main contributions of this article are: 1) by retracing the network’s error from the output space to the latent space, the OBLS adjusts parameters in the feature and enhancement node layers. This process aims to achieve more resilient representations, resulting in improved performance; 2) the DOBLS is a multilayered structure consisting of multiple OBLSs, wherein each OBLS connects to the input and output layers, enabling direct data propagation. This design helps reduce information loss between layers, ensuring an efficient flow of information throughout the network; and 3) the proposed methods demonstrate robustness across various applications, including multiview feature embedding, one-class classification (OCC), camera model identification, electroencephalogram (EEG) signal processing, and radar signal analysis. Experimental results validate the effectiveness of the proposed models. To ensure reproducibility, the source code is available at https://github.com/1027051515/OBLS_DOBLS.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Data analysis",
                "Neurons",
                "Decision trees",
                "Representation learning",
                "Feature extraction",
                "Signal processing algorithms",
                "Brain modeling",
                "Backpropagation",
                "Analytical models"
            ],
            "Author Keywords": [
                "Broad learning system (BLS)",
                "deep learning (DL)",
                "large-scale data analysis",
                "tabular data analysis"
            ]
        },
        "Field": "data",
        "title": "Deep Optimized Broad Learning System for Applications in Tabular Data Recognition",
        "link": "https://ieeexplore.ieee.org/document/10717444/"
    },
    {
        "authors": [
            "Zhengming Li",
            "Jiahui Chen",
            "Peifeng Zhang",
            "Huiwu Huang",
            "Guanbin Li"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )",
        "date_of_publication": "26 January 2024",
        "doi": "10.1109/TNNLS.2024.3349400",
        "publisher": "IEEE",
        "abstract": "Federated learning (FL) makes it possible for multiple clients to collaboratively train a machine-learning model through communicating models instead of data, reducing privacy risk. Thus, FL is more suitable for processing data security and privacy for intelligent systems and applications. Unfortunately, there are several challenges in FL, such as the low training accuracy for nonindependent and identically distributed (non-IID) data and the high cost of computation and communication. Considering these, we propose a novel FL framework named dynamic sparse federated contrastive learning ( DSFedCon ). DSFedCon combines FL with dynamic sparse (DSR) training of network pruning and contrastive learning to improve model performance and reduce computation costs and communication costs. We analyze DSFedCon from the perspective of accuracy, communication, and security, demonstrating it is communication-efficient and safe. To give a practical evaluation for non-IID data training, we perform experiments and comparisons on the MNIST, CIFAR-10, and CIFAR-100 datasets with different parameters of Dirichlet distribution. Results indicate that DSFedCon can get higher accuracy and better communication cost than other state-of-the-art methods in these two datasets. More precisely, we show that DSFedCon has a 4.67-time speedup of communication rounds in MNIST, a 7.5-time speedup of communication rounds in CIFAR-10, and an 18.33-time speedup of communication rounds in CIFAR-100 dataset while achieving the same training accuracy.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Computational modeling",
                "Costs",
                "Self-supervised learning",
                "Data models",
                "Servers",
                "Distributed databases"
            ],
            "Author Keywords": [
                "Contrastive learning",
                "data-driven intelligent systems (DISs)",
                "data privacy",
                "federated learning (FL)"
            ]
        },
        "Field": "data",
        "title": "DSFedCon: Dynamic Sparse Federated Contrastive Learning for Data-Driven Intelligent Systems",
        "link": "https://ieeexplore.ieee.org/document/10415051/"
    },
    {
        "authors": [
            "Yuqing Wang",
            "Junwei Zhang",
            "Zhuo Ma",
            "Ning Lu",
            "Teng Li",
            "Jianfeng Ma"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Intelligent Transportation Systems ( Early Access )",
        "date_of_publication": "18 September 2024",
        "doi": "10.1109/TITS.2024.3453340",
        "publisher": "IEEE",
        "abstract": "The widespread use of machine learning in location-related scenarios is propelling the rapid development of intelligent transportation. To assist users in making more informed travel plans, the demand for improving prediction accuracy is growing. Prior to model training, data cleaning is a common method used to eliminate redundant, erroneous and outlier samples. However, in intelligent transportation, there are serious issues with location awareness and privacy protection of existing data cleaning schemes. Therefore, we propose a location-aware and privacy-preserving data cleaning framework (PriSPA) which provides a cleaned dataset consisting of the samples from adopted data suppliers at qualified locations while ensuring the privacy of locations, spatial constraints and sensitive samples. We combine boolean secret sharing with XOR operations to make sure that it is possible to figure out whether a location complies with spatial constraints without leakage. More specifically, we ensure privacy using key agreement, secret sharing, authenticated encryption and random permutation. We seriously analyze the security of PriSPA and conduct comprehensive experiments to prove its security, effectiveness and efficiency. Based on the comparisons with the raw traffic forecasting framework, we observe that PriSPA improves the precision of the model with 17.6% -32.7% error reduction.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Cleaning",
                "Data privacy",
                "Accuracy",
                "Reflective binary codes",
                "Privacy",
                "Predictive models",
                "Forecasting"
            ],
            "Author Keywords": [
                "Data cleaning",
                "location-aware",
                "spatial data",
                "privacy-preserving",
                "traffic forecasting"
            ]
        },
        "Field": "data",
        "title": "Location-Aware and Privacy-Preserving Data Cleaning for Intelligent Transportation",
        "link": "https://ieeexplore.ieee.org/document/10682974/"
    },
    {
        "authors": [
            "Yun Wang",
            "Leixian Shen",
            "Zhengxin You",
            "Xinhuan Shu",
            "Bongshin Lee",
            "John Thompson",
            "Haidong Zhang",
            "Dongmei Zhang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Visualization and Computer Graphics ( Early Access )",
        "date_of_publication": "10 June 2024",
        "doi": "10.1109/TVCG.2024.3411575",
        "publisher": "IEEE",
        "abstract": "Creating an animated data video with audio narration is a time-consuming and complex task that requires expertise. It involves designing complex animations, turning written scripts into audio narrations, and synchronizing visual changes with the narrations. This paper presents WonderFlow, an interactive authoring tool, that facilitates narration-centric design of animated data videos. WonderFlow allows authors to easily specify semantic links between text and the corresponding chart elements. Then it automatically generates audio narration by leveraging text-to-speech techniques and aligns the narration with an animation. WonderFlow provides a structure-aware animation library designed to ease chart animation creation, enabling authors to apply pre-designed animation effects to common visualization components. Additionally, authors can preview and refine their data videos within the same system, without having to switch between different creation tools. A series of evaluation results confirmed that WonderFlow is easy to use and simplifies the creation of data videos with narration-animation interplay.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Videos",
                "Animation",
                "Data visualization",
                "Visualization",
                "Authoring systems",
                "Libraries",
                "Electronic mail"
            ],
            "Author Keywords": [
                "Data video",
                "Data visualization",
                "Narration-animation interplay",
                "Storytelling",
                "Authoring tool"
            ]
        },
        "Field": "data",
        "title": "WonderFlow: Narration-Centric Design of Animated Data Videos",
        "link": "https://ieeexplore.ieee.org/document/10552427/"
    },
    {
        "authors": [
            "Qinglan Fan",
            "Ying Bi",
            "Bing Xue",
            "Mengjie Zhang"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Evolutionary Computation ( Early Access )",
        "date_of_publication": "01 April 2024",
        "doi": "10.1109/TEVC.2024.3384021",
        "publisher": "IEEE",
        "abstract": "Data-efficient image classification, which focuses on achieving accurate classification performance with limited labeled data, has garnered significant attention. Genetic programming (GP) has achieved impressive progress in image classification, particularly in scenarios involving small amounts of labeled data. GP research typically focuses on designing tree-based model representations to learn useful image features for classification. However, most GP methods are proposed for gray-scale images and ignore the color features. Furthermore, the existing GP methods typically learn features on a single scale/resolution, restricting potential accuracy enhancements. To address these issues, this paper proposes a new multi-tree GP In single-tree GP (or simply GP), each individual consists of a single tree. In contrast, in multi-tree GP, each individual comprises multiple trees. representation for image feature learning and classification. In each individual, three trees are included to extract discriminative features from the red, green, and blue channels of the image. With the new image resizing layer in the tree representation, the proposed approach can achieve multi-scale feature extraction, i.e., flexibly learning fine-grained details and coarse-grained structures in the image, improving the classification performance. In addition, since a limitation of GP is premature convergence due to a decline in population diversity, this paper develops a hybrid parent selection method consisting of tournament and lexicase selection to increase population diversity, find the best individual, and improve classification accuracy. The experiments on six image classification datasets indicate that the proposed approach outperforms state-of-the-art neural network-based and GP-based methods in almost all comparisons. Further analyses demonstrate the effectiveness of each component and the potentially high interpretability of the proposed approach.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Training data",
                "Image color analysis",
                "Training",
                "Sociology",
                "Representation learning",
                "Gray-scale"
            ],
            "Author Keywords": [
                "Data-efficient Image Classification",
                "Multi-tree Genetic Programming",
                "Color Features",
                "Multi-scale Feature Extraction",
                "Parent Selection"
            ]
        },
        "Field": "data",
        "title": "Multi-Tree Genetic Programming for Learning Color and Multi-Scale Features in Image Classification",
        "link": "https://ieeexplore.ieee.org/document/10488030/"
    },
    {
        "authors": [
            "Tian Chen",
            "Yu-an Tan",
            "Chunying Li",
            "Zheng Zhang",
            "Weizhi Meng",
            "Yuanzhang Li"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Journal on Emerging and Selected Topics in Circuits and Systems ( Early Access )",
        "date_of_publication": "04 November 2024",
        "doi": "10.1109/JETCAS.2024.3491169",
        "publisher": "IEEE",
        "abstract": "With the increasing popularity of heterogeneous computing systems in Artificial Intelligence (AI) applications, ensuring the confidentiality and integrity of sensitive data transferred between different elements has become a critical challenge. In this paper, we propose an enhanced security framework called SecureComm to protect data transfer between ARM CPU and FPGA through Double Data Rate (DDR) memory on CPU-FPGA heterogeneous platforms. SecureComm extends the SM4 crypto module by incorporating a proposed Message Authentication Code (MAC) to ensure data confidentiality and integrity. It also constructs smart queues in the shared memory of DDR, which work in conjunction with the designed protocols to help schedule data flow and facilitate flexible adaptation to various AI tasks with different data scales. Furthermore, some of the hardware modules of SecureComm are improved and encapsulated as independent IPs to increase their versatility beyond the scope of this paper. We implemented several ARM CPU-FPGA collaborative AI applications to justify the security and evaluate the timing overhead of SecureComm. We also deployed SecureComm to non-AI tasks to demonstrate its versatility, ultimately offering suggestions for its use in tasks of varying data scales.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Field programmable gate arrays",
                "Ciphers",
                "Encryption",
                "Artificial intelligence",
                "Hardware",
                "Central Processing Unit",
                "Circuits and systems",
                "Protocols",
                "Schedules",
                "Optimization"
            ],
            "Author Keywords": [
                "Heterogeneous system",
                "Edge devices",
                "Data transfer",
                "DDR",
                "SM4",
                "Message Authentication Code (MAC)"
            ]
        },
        "Field": "data",
        "title": "SecureComm: A Secure Data Transfer Framework for Neural Network Inference on CPU-FPGA Heterogeneous Edge Devices",
        "link": "https://ieeexplore.ieee.org/document/10742390/"
    },
    {
        "authors": [
            "Ziwei Li",
            "Weiming Xu",
            "Shiyu Yang",
            "Juan Wang",
            "Hua Su",
            "Zhanchao Huang",
            "Sheng Wu"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing ( Early Access )",
        "date_of_publication": "04 November 2024",
        "doi": "10.1109/JSTARS.2024.3491335",
        "publisher": "IEEE",
        "abstract": "Remote sensing scene classification (RSSC) is essential in Earth observation, with applications in land use, environmental status, urban development, and disaster risk assessment. However, redundant background interference, varying feature scales, and high inter-class similarity in remote sensing images present significant challenges for RSSC. To address these challenges, this paper proposes a novel hierarchical graph-enhanced transformer network (HGTNet) for RSSC. Initially, we introduce a dual attention (DA) module, which extracts key feature information from both the channel and spatial domains, effectively suppressing background noise. Subsequently, we meticulously design a three-stage hierarchical transformer extractor, incorporating a DA module at the bottleneck of each stage to facilitate information exchange between different stages, in conjunction with the Swin transformer block (STB) module to capture multi-scale global visual information. Moreover, we develop a fine-grained graph neural network (GNN) extractor that constructs the spatial topological relationships of pixel-level scene images, thereby aiding in the discrimination of similar complex scene categories. Finally, the visual features and spatial structural features are fully integrated and input into the classifier by employing skip connections. HGTNet achieves classification accuracies of 98.47%, 95.75%, and 96.33% on the aerial image, NWPU-RESISC45, and OPTIMAL-31 datasets, respectively, demonstrating superior performance compared to other state-of-the-art models. Extensive experimental results indicate that our proposed method effectively learns critical multi-scale visual features and distinguishes between similar complex scenes, thereby significantly enhancing the accuracy of RSSC.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Transformers",
                "Remote sensing",
                "Visualization",
                "Scene classification",
                "Graph neural networks",
                "Attention mechanisms",
                "Sensors",
                "Earth",
                "Data mining"
            ],
            "Author Keywords": [
                "Attention mechanism",
                "graph neural network",
                "remote sensing scene classification",
                "spatial structural feature",
                "transformer"
            ]
        },
        "Field": "data",
        "title": "A Hierarchical Graph-Enhanced Transformer Network for Remote Sensing Scene Classification",
        "link": "https://ieeexplore.ieee.org/document/10742489/"
    },
    {
        "authors": [
            "Xiuhua Wang",
            "Mengyang Yu",
            "Yaohui Wang",
            "Yinjia Pi",
            "Peng Xu",
            "Shuai Wang",
            "Hai Jin",
            "Min Han"
        ],
        "locations": [],
        "published_in": "Published in: IEEE Transactions on Dependable and Secure Computing ( Early Access )",
        "date_of_publication": "16 October 2024",
        "doi": "10.1109/TDSC.2024.3481497",
        "publisher": "IEEE",
        "abstract": "The burgeoning complexity of communication necessitates a high demand for security. Access control encryption is a promising primitive to meet the security demand but the bulk of its constructions rely on formulating the access control policy with identities. Attribute-based access control policy in attribute-based encryption (ABE) is known to be more expressive without relying on enumerating identities. We propose a generic framework to build attribute-based access control encryption from ciphertext-policy ABE. Our instantiations prioritize different emphases on expressiveness and efficiency. The first instantiation supports multi-valued AND-gate access control structures, while the second supports the linear-secret-sharing access structure. Both are prototyped with efficiency validated empirically.",
        "issn": {},
        "keywords": {
            "IEEE Keywords": [
                "Access control",
                "Encryption",
                "Receivers",
                "Soft sensors",
                "Monitoring",
                "Iron",
                "Digital signatures",
                "Big Data",
                "Service computing",
                "Scalability"
            ],
            "Author Keywords": [
                "Attribute-Based Access Control Encryption",
                "Attribute-Based Encryption",
                "Public-Key Encryption"
            ]
        },
        "Field": "data",
        "title": "Attribute-Based Access Control Encryption",
        "link": "https://ieeexplore.ieee.org/document/10720426/"
    }
]